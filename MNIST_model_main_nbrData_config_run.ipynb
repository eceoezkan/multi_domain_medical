{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders\n",
    "data_path = 'xxx' # todo\n",
    "results_path = 'xxx' # todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55337d05",
   "metadata": {},
   "source": [
    "# Try different distributions - NbrData experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7c1a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_val = 1000*np.ones((10,5))\n",
    "cnt = 0\n",
    "\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "# initialize\n",
    "df_datapoints = pd.DataFrame(columns = ['mean_organ', \n",
    "                                        'std_organ', \n",
    "                                        'mean_modality',\n",
    "                                        'std_modality',\n",
    "                                        'mean_datapoints',\n",
    "                                        'median_datapoints',\n",
    "                                        'total_datapoints'])\n",
    "    \n",
    "for mean_organ in [0]:\n",
    "    for std_organ in [3,5,9,17]:\n",
    "        \n",
    "        # distribution for organ\n",
    "        set_seeds(seed=42)\n",
    "        s_organ = np.random.normal(mean_organ, std_organ, 500000)\n",
    "        \n",
    "        for mean_modality in [0,2]:\n",
    "            for std_modality in [1,3,5]:\n",
    "                \n",
    "                # distribution for modality\n",
    "                set_seeds(seed=42)\n",
    "                s_modality = np.random.normal(mean_modality, std_modality, 100000)\n",
    "                \n",
    "                # initialize\n",
    "                hist_organ_mat = np.empty([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "                hist_modality_mat = np.empty([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "                \n",
    "                # histogram\n",
    "                hist_organ = np.histogram(s_organ, bins=range(0,11), density=True)\n",
    "                hist_modality = np.histogram(s_modality, bins=range(0,6), density=True)\n",
    "                \n",
    "                # normalize\n",
    "                hist_organ = hist_organ[0]/hist_organ[0].max()\n",
    "                hist_modality = hist_modality[0]/hist_modality[0].max()\n",
    "                \n",
    "                # iterate \n",
    "                for i in range(len(CLASS_NAMES[1])):\n",
    "                    hist_organ_mat[:,i] = hist_organ\n",
    "                for i in range(len(CLASS_NAMES[0])):\n",
    "                    hist_modality_mat[i,:] = hist_modality\n",
    "\n",
    "                # number of datapoints\n",
    "                datapoints = train_val*hist_organ_mat*hist_modality_mat\n",
    "                mean_datapoints = datapoints.mean()\n",
    "                median_datapoints = np.median(datapoints)\n",
    "                total_datapoints = datapoints.sum()\n",
    "                print(median_datapoints,mean_datapoints,total_datapoints)\n",
    "                df_datapoints = pd.concat([df_datapoints, pd.DataFrame.from_records([{'mean_organ':mean_organ, \n",
    "                                                     'std_organ': std_organ,\n",
    "                                                     'mean_modality':mean_modality,\n",
    "                                                     'std_modality':std_modality,\n",
    "                                                     'mean_datapoints':mean_datapoints,\n",
    "                                                     'median_datapoints':median_datapoints,\n",
    "                                                     'total_datapoints':total_datapoints}])], ignore_index=True)\n",
    "            \n",
    "                # plot\n",
    "                fig = plt.figure(figsize=(7, 3), dpi=80)\n",
    "                \n",
    "                # plot\n",
    "                plt.subplot(1,3,1)\n",
    "                plt.imshow(hist_organ_mat, vmin=0, vmax=1)\n",
    "                plt.title('Mean: '+str(mean_organ)+ ' Std: '+str(std_organ))\n",
    "                plt.colorbar()\n",
    "                plt.subplot(1,3,2)\n",
    "                plt.imshow(hist_modality_mat, vmin=0, vmax=1)\n",
    "                plt.title('Mean: '+str(mean_modality)+ ' Std: '+str(std_modality))\n",
    "                plt.colorbar()\n",
    "                plt.subplot(1,3,3)\n",
    "                img = plt.imshow(datapoints, vmin=0, vmax=1000)\n",
    "                plt.title('Number of samples')\n",
    "                plt.colorbar()\n",
    "                plt.show()\n",
    "                \n",
    "                cnt = cnt + 1\n",
    "print(cnt)     \n",
    "df_datapoints = df_datapoints.sort_values('median_datapoints',ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import set_seeds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data\n",
    "data_dir = data_path + '/Data/PolyMNIST/' \n",
    "curr_phase = 'train'\n",
    "max_id = 1000\n",
    "train_ratio = 0.75\n",
    "seed = 42\n",
    "mean_organ = 0\n",
    "std_organ = 3\n",
    "mean_modality = 0\n",
    "std_modality = 5\n",
    "\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "annot_dir = data_dir + curr_phase + '_' + str(max_id) + '.csv'\n",
    "df = pd.read_csv(annot_dir,sep=';') \n",
    "imgs_dir = data_dir + curr_phase + '_' + str(max_id) + '.npy'\n",
    "imgs = np.load(imgs_dir)\n",
    "\n",
    "# get img_idx and labels\n",
    "img_idx = np.array(df['Path'])\n",
    "label_vec = np.transpose(np.array([df['Organ'],df['Modality']]))\n",
    "label_vec = label_vec.astype(int)\n",
    "            \n",
    "# get the current distribution\n",
    "set_seeds(seed=seed)\n",
    "s_organ = np.random.normal(mean_organ, std_organ, 500000)\n",
    "set_seeds(seed=seed)\n",
    "s_modality = np.random.normal(mean_modality, std_modality, 100000)\n",
    "            \n",
    "# initialize\n",
    "hist_organ_mat = np.empty([num_classes[0],num_classes[1]])\n",
    "hist_modality_mat = np.empty([num_classes[0],num_classes[1]])\n",
    "                \n",
    "# histogram\n",
    "hist_organ = np.histogram(s_organ, bins=range(0,num_classes[0]+1), density=True)\n",
    "hist_modality = np.histogram(s_modality, bins=range(0,num_classes[1]+1), density=True)\n",
    "                \n",
    "# normalize\n",
    "hist_organ = hist_organ[0]/hist_organ[0].max()\n",
    "hist_modality = hist_modality[0]/hist_modality[0].max()\n",
    "                \n",
    "# iterate \n",
    "for i in range(len(CLASS_NAMES[1])):\n",
    "    hist_organ_mat[:,i] = hist_organ\n",
    "for i in range(len(CLASS_NAMES[0])):\n",
    "    hist_modality_mat[i,:] = hist_modality\n",
    "\n",
    "# number of datapoints\n",
    "train_mat = max_id*train_ratio*np.ones((num_classes[0],num_classes[1]))\n",
    "val_mat =  max_id*(1-train_ratio)*np.ones((num_classes[0],num_classes[1]))\n",
    "datapoints_train = np.round(train_mat*hist_organ_mat*hist_modality_mat)\n",
    "datapoints_val = np.round(val_mat*hist_organ_mat*hist_modality_mat)\n",
    "\n",
    "print('Total number of images for train: '+str(datapoints_train.sum()))\n",
    "print('Total number of images for val: '+str(datapoints_val.sum()))\n",
    "print(datapoints_train)\n",
    "print(datapoints_train.sum(axis=1))\n",
    "print(datapoints_val)\n",
    "print(datapoints_val.sum(axis=1))\n",
    "                                             \n",
    "# get only the relevant images\n",
    "# train\n",
    "check_vec = df['ImgID'] <  datapoints_train[df['Organ'],df['Modality']] \n",
    "train_imgs = imgs[:,:,:,check_vec]\n",
    "train_idx = img_idx[check_vec]\n",
    "train_label = label_vec[check_vec]\n",
    "train_dir = data_dir + curr_phase + '/'\n",
    "            \n",
    "# val\n",
    "check_vec = (df['ImgID'] < (max_id*train_ratio + datapoints_val[df['Organ'],df['Modality']])) & (df['ImgID'] >= (max_id*train_ratio))\n",
    "val_imgs = imgs[:,:,:,check_vec]\n",
    "val_idx = img_idx[check_vec]\n",
    "val_label = label_vec[check_vec]\n",
    "val_dir = data_dir + curr_phase + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b8582",
   "metadata": {},
   "source": [
    "# Number of datapoints experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e7478",
   "metadata": {},
   "source": [
    "## Configs for nbrData experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_nbrData\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_nbrData(results_path + '/MNIST/results/results_NbrData/',True) \n",
    "with open(results_path + '/MNIST/results/results_NbrData/' + 'configs/' + str(0) + '.json') as config_file: \n",
    "        config = json.load(config_file)\n",
    "        print(config)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49976546",
   "metadata": {},
   "source": [
    "## run from terminal - nbrData experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957eebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='NbrData' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139807b8",
   "metadata": {},
   "source": [
    "# NbrData Secondary experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684741c",
   "metadata": {},
   "source": [
    "## Configs for secondary experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75423d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_nbrData_secondary\n",
    "import json\n",
    "# reduced experiment configs        \n",
    "config_experiments_nbrData_secondary(results_path + '/MNIST/results/results_NbrData_Secondary/',True)\n",
    "with open(results_path + '/MNIST/results/results_NbrData_Secondary/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9028c1",
   "metadata": {},
   "source": [
    "## run from terminal - secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4678982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='NbrData_Secondary' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a301d34",
   "metadata": {},
   "source": [
    "# NbrData Secondary experiments - upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14b769",
   "metadata": {},
   "source": [
    "## Configs for secondary upsampled experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d065dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_nbrData_secondary_upsampled\n",
    "import json\n",
    "# reduced experiment configs        \n",
    "config_experiments_nbrData_secondary_upsampled(results_path + '/MNIST/results/results_NbrData_Secondary_Upsampled/',True) \n",
    "with open(results_path + '/MNIST/results/results_NbrData_Secondary_Upsampled/' + 'configs/' + str(0) + '.json') as config_file: \n",
    "        config = json.load(config_file)\n",
    "        print(config)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ecfd2b",
   "metadata": {},
   "source": [
    "## run from terminal - secondary upsampled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea48c552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='NbrData_Secondary_Upsampled' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec25ce",
   "metadata": {},
   "source": [
    "# NbrData Reduced experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd26e952",
   "metadata": {},
   "source": [
    "## Configs for reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_nbrData_reduced\n",
    "import json        \n",
    "        \n",
    "# reduced experiment configs        \n",
    "config_experiments_nbrData_reduced(results_path + '/MNIST/results/results_NbrData_Reduced/',True) \n",
    "with open(results_path + '/MNIST/results/results_NbrData_Reduced/' + 'configs/' + str(0) + '.json') as config_file: \n",
    "        config = json.load(config_file)\n",
    "        print(config)              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1dbd4",
   "metadata": {},
   "source": [
    "## run from terminal - reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a8c244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='NbrData_Reduced' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850b7ee",
   "metadata": {},
   "source": [
    "# NbrData Secondary Reduced experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4210440f",
   "metadata": {},
   "source": [
    "## Configs for reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e05a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_nbrData_reduced_secondary\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_nbrData_reduced_secondary(results_path + '/MNIST/results/results_NbrData_ReducedSecondary/',True) \n",
    "with open(results_path + '/MNIST/results/results_NbrData_ReducedSecondary/' + 'configs/' + str(0) + '.json') as config_file: \n",
    "        config = json.load(config_file)\n",
    "        print(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9976d0b",
   "metadata": {},
   "source": [
    "## run from terminal - reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec96a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='NbrData_ReducedSecondary' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad39134",
   "metadata": {},
   "source": [
    "# NbrData Secondary Reduced experiments - upsampled "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ab6de",
   "metadata": {},
   "source": [
    "## Configs for reduced secondary upsampled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce79c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_nbrData_reduced_secondary_upsampled\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_nbrData_reduced_secondary_upsampled(results_path + '/MNIST/results/results_NbrData_ReducedSecondary_upsampled/',True) \n",
    "with open(results_path + '/MNIST/results/results_NbrData_ReducedSecondary_upsampled/' + 'configs/' + str(0) + '.json') as config_file: \n",
    "        config = json.load(config_file)\n",
    "        print(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a1052",
   "metadata": {},
   "source": [
    "## run from terminal - reduced secondary upsampled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a817f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='NbrData_ReducedSecondary_upsampled' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b79e21",
   "metadata": {},
   "source": [
    "## NbrData Secondary Reduced experiments - test on other modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_nbrData_reduced_secondary_test\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_nbrData_reduced_secondary_test(results_path + '/MNIST/results/results_NbrData_ReducedSecondary_test/',True) \n",
    "with open(results_path + '/MNIST/results/results_NbrData_ReducedSecondary_test/' + 'configs/' + str(0) + '.json') as config_file: \n",
    "        config = json.load(config_file)\n",
    "        print(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd099f",
   "metadata": {},
   "source": [
    "## run from terminal - reduced secondary test experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='NbrData_ReducedSecondary_test' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b393dd85",
   "metadata": {},
   "source": [
    "# Sampled datapoints experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe19ae9",
   "metadata": {},
   "source": [
    "## Configs for sampled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_sampled\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_sampled(results_path + '/MNIST/results/results_Sampled/',True) \n",
    "with open(results_path + '/MNIST/results/results_Sampled/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d155e70e",
   "metadata": {},
   "source": [
    "## run from terminal - sampled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2947c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='Sampled' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e40f7b",
   "metadata": {},
   "source": [
    "# Sampled Secondary experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd4652",
   "metadata": {},
   "source": [
    "## Configs for secondary experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d765e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_sampled_secondary\n",
    "import json\n",
    "# reduced experiment configs        \n",
    "config_experiments_sampled_secondary(results_path + '/MNIST/results/results_Sampled_Secondary/',True) \n",
    "with open(results_path + '/MNIST/results/results_Sampled_Secondary/' + 'configs/' + str(0) + '.json') as config_file: \n",
    "        config = json.load(config_file)\n",
    "        print(config)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e171a468",
   "metadata": {},
   "source": [
    "## run from terminal - secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35407018",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='Sampled_Secondary' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbba280",
   "metadata": {},
   "source": [
    "# Sampled Secondary experiments - upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326ba94",
   "metadata": {},
   "source": [
    "## Configs for secondary upsampled experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_sampled_secondary_upsampled\n",
    "import json\n",
    "# reduced experiment configs        \n",
    "config_experiments_sampled_secondary_upsampled(results_path + '/MNIST/results/results_Sampled_Secondary_Upsampled/',True) \n",
    "with open(results_path + '/MNIST/results/results_Sampled_Secondary_Upsampled/' + 'configs/' + str(0) + '.json') as config_file: \n",
    "        config = json.load(config_file)\n",
    "        print(config)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804325f7",
   "metadata": {},
   "source": [
    "## run from terminal - secondary upsampled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='Sampled_Secondary_Upsampled' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52860d6f",
   "metadata": {},
   "source": [
    "# Sampled Reduced experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084af08f",
   "metadata": {},
   "source": [
    "## Configs for reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_sampled_reduced\n",
    "import json        \n",
    "        \n",
    "# reduced experiment configs        \n",
    "config_experiments_sampled_reduced(results_path + '/MNIST/results/results_Sampled_Reduced/',True)\n",
    "with open(results_path + '/MNIST/results/results_Sampled_Reduced/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b09860",
   "metadata": {},
   "source": [
    "## run from terminal - reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ee31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='Sampled_Reduced' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb34e10",
   "metadata": {},
   "source": [
    "# Sampled Secondary Reduced experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e7e32",
   "metadata": {},
   "source": [
    "## Configs for reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_sampled_reduced_secondary\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_sampled_reduced_secondary(results_path + '/MNIST/results/results_Sampled_ReducedSecondary/',True)\n",
    "with open(results_path + '/MNIST/results/results_Sampled_ReducedSecondary/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf2eaa",
   "metadata": {},
   "source": [
    "## run from terminal - reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a067530",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='Sampled_ReducedSecondary' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1dcdd",
   "metadata": {},
   "source": [
    "# Sampled Secondary Reduced experiments - upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3583a",
   "metadata": {},
   "source": [
    "## Configs for reduced secondary upsampled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb66cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_mnist import config_experiments_sampled_reduced_secondary_upsampled\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_sampled_reduced_secondary_upsampled(results_path + 'MNIST/results/results_Sampled_ReducedSecondary_upsampled/',True)\n",
    "with open(results_path + '/MNIST/results/results_Sampled_ReducedSecondary_upsampled/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170616e",
   "metadata": {},
   "source": [
    "## run from terminal - reduced secondary upsampled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cae700",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_mnist.py --experiment_id=0 --task_to_run='Sampled_ReducedSecondary_upsampled' --gpu_id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f6f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
