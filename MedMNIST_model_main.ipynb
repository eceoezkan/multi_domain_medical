{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# folders\n",
    "data_path = 'xxx' # todo\n",
    "results_path = 'xxx' # todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# hard-code MedMNIST has 3 views and 11 organs\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "CLASS_NAMES_exp.append(['Bladder','Left femoral head','Right femoral head','Heart','Left kidney',\n",
    "                        'Right kidney','Liver','Left lung','Right lung','Pancreas','Spleen'])\n",
    "CLASS_NAMES_exp.append(['Axial','Coronal','Sagittal'])\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[0])))\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[1])))\n",
    "\n",
    "\n",
    "data_dir = data_path + '/Data/MedMNIST/'\n",
    "with np.load(data_dir+'organ'+'a'+'mnist.npz') as data:\n",
    "    imgs = data['train_images']\n",
    "    print(imgs.shape)\n",
    "# with np.load(data_dir+'organ'+'c'+'mnist.npz') as data:\n",
    "#     imgs = data['train_images']\n",
    "#     print(imgs.shape)\n",
    "# with np.load(data_dir+'organ'+'s'+'mnist.npz') as data:\n",
    "#     imgs = data['train_images']\n",
    "#     print(imgs.shape)\n",
    "\n",
    "# get the image\n",
    "curr_img = imgs[7688,:,:]\n",
    "print(curr_img.max() != 0)\n",
    "curr_img = curr_img*(255/curr_img.max())\n",
    "curr_img = np.stack((curr_img,)*3, axis=-1)\n",
    "\n",
    "img = Image.fromarray(curr_img.astype(np.uint8))\n",
    "     \n",
    "transformList = []\n",
    "transformList.append(transforms.Resize(size=32))\n",
    "transformList.append(transforms.ToTensor())\n",
    "train_transform=transforms.Compose(transformList)\n",
    "img = train_transform(img)   \n",
    "plt.imshow(img.permute(1,2,0),cmap='gray')\n",
    "plt.show()\n",
    "print('End Size: '+ str(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datapoints_train = np.array([[1956,1153,1148],\n",
    "         [1408, 626, 637],\n",
    "         [1359, 608, 615],\n",
    "         [1474, 600, 721],\n",
    "         [3963,1088,1132],\n",
    "         [3817,1170,1119],\n",
    "         [6164,2986,3464],\n",
    "         [3919,1002, 741],\n",
    "         [3929,1022, 803],\n",
    "         [3031,1173,2004],\n",
    "         [3561,1572,1556]])\n",
    "datapoints_val = np.array([[ 321, 191, 188],\n",
    "         [ 233, 102, 104],\n",
    "         [ 225,  96,  95],\n",
    "         [ 392, 202, 246],\n",
    "         [ 568, 132, 140],\n",
    "         [ 637, 157, 159],\n",
    "         [1033, 429, 491],\n",
    "         [1033, 347, 261],\n",
    "         [1009, 352, 275],\n",
    "         [ 529, 179, 280],\n",
    "         [ 511, 205, 213]])\n",
    "datapoints_test = np.array([[1036, 833, 811],\n",
    " [ 784, 442, 439],\n",
    " [ 793, 441, 447],\n",
    " [ 785, 421, 510],\n",
    " [2064, 732, 704],\n",
    " [1965, 737, 693],\n",
    " [3285,1836,2078],\n",
    " [1747, 550, 397],\n",
    " [1813, 558, 439],\n",
    " [1622, 750,1343],\n",
    " [1884, 968, 968]])\n",
    "print(datapoints_train.sum())\n",
    "print(datapoints_val.sum())\n",
    "print(datapoints_test.sum())\n",
    "\n",
    "y_list =['Bladder','Left femoral head','Right femoral head','Heart','Left kidney',\n",
    "                        'Right kidney','Liver','Left lung','Right lung','Pancreas','Spleen']\n",
    "x_list = ['Axial','Coronal','Sagittal']\n",
    "\n",
    "# train\n",
    "fig = plt.figure(figsize=(5, 5), dpi=80)\n",
    "plt.imshow(datapoints_train) \n",
    "plt.xticks(np.arange(len(x_list)), labels=x_list, rotation=45)\n",
    "plt.yticks(np.arange(len(y_list)), labels=y_list, rotation=0)\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.savefig('figs/medmnist_data_train.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/medmnist_data_train.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "# val\n",
    "fig = plt.figure(figsize=(5, 5), dpi=80)\n",
    "plt.imshow(datapoints_val) \n",
    "plt.xticks(np.arange(len(x_list)), labels=x_list, rotation=45)\n",
    "plt.yticks(np.arange(len(y_list)), labels=y_list, rotation=0)\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.savefig('figs/medmnist_data_val.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/medmnist_data_val.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "# test\n",
    "fig = plt.figure(figsize=(5, 5), dpi=80)\n",
    "plt.imshow(datapoints_test) \n",
    "plt.xticks(np.arange(len(x_list)), labels=x_list, rotation=45)\n",
    "plt.yticks(np.arange(len(y_list)), labels=y_list, rotation=0)\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.savefig('figs/medmnist_data_test.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/medmnist_data_test.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "data_dir = data_path + '/Data/MedMNIST/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "    \n",
    "# hard-code MedMNIST has 3 views and 11 organs\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "CLASS_NAMES_exp.append(['Bladder','Left femoral head','Right femoral head','Heart','Left kidney',\n",
    "                        'Right kidney','Liver','Left lung','Right lung','Pancreas','Spleen'])\n",
    "CLASS_NAMES_exp.append(['Axial','Coronal','Sagittal'])\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[0])))\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[1])))\n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "# load data\n",
    "print('Annotations loading..')\n",
    "imgs = np.empty((0,28,28))\n",
    "label_vec = np.empty((0,2))\n",
    "cnt = 0\n",
    "curr_phase = 'train'\n",
    "for i in ['a','c','s']:\n",
    "    data_path = data_dir+'organ'+i+'mnist.npz'\n",
    "    with np.load(data_path) as data:\n",
    "        imgs = np.concatenate((imgs,data[curr_phase+'_images']),axis=0)\n",
    "        labels = data[curr_phase+'_labels']\n",
    "        labels = np.concatenate((labels,cnt*np.ones((len(labels),1))),axis=1)\n",
    "        label_vec = np.concatenate((label_vec,labels),axis=0)\n",
    "        cnt = cnt + 1  \n",
    "print('Annotations loaded!')\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(num_classes[1], num_classes[0]), dpi=80)\n",
    "np.random.seed(42)\n",
    "img_size = 224\n",
    "for organ in range(0,num_classes[0]):\n",
    "    for modality in range(0,num_classes[1]):\n",
    "        curr_label = [organ,modality]\n",
    "        curr_list = np.where(np.sum(label_vec == curr_label,axis=1) == 2)[0]\n",
    "        if len(curr_list) > 0:\n",
    "            # get a random number\n",
    "            idx = np.random.randint(1,len(curr_list))\n",
    "            curr_img = imgs[curr_list[idx],:,:]\n",
    "            if curr_img.max() != 0:\n",
    "                curr_img = curr_img*(255.0/curr_img.max())\n",
    "            curr_img = np.stack((curr_img,)*3, axis=-1)\n",
    "            img = Image.fromarray(curr_img.astype(np.uint8))\n",
    "        else:\n",
    "            continue\n",
    "        img = transforms.Resize(size=img_size)(img)\n",
    "            \n",
    "        # plot\n",
    "        cnt = organ*num_classes[1] + modality + 1\n",
    "        plt.subplot(num_classes[0],num_classes[1],cnt)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off') \n",
    "plt.subplots_adjust(wspace=0, hspace=0)     \n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for hyper experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_medmnist import config_experiments_hyper\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_hyper(results_path + '/MedMNIST/results/results_Organ_hyper/',True)\n",
    "with open(results_path + '/MedMNIST/results/results_Organ_hyper/' + 'configs/' + str(10) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - hyper experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_medmnist.py --experiment_id=0 --task_to_run='Organ_hyper' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for seed experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_medmnist import config_experiments\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments(results_path + '/MedMNIST/results/results_Organ/',True)\n",
    "with open(results_path + 'MedMNIST/results/results_Organ/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - seed experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_medmnist.py --experiment_id=0 --task_to_run='Organ' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for distribution experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_medmnist import config_experiments_dist\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_dist(results_path + '/MedMNIST/results/results_Organ_dist/',True)\n",
    "with open(results_path + '/MedMNIST/results/results_Organ_dist/' + 'configs/' + str(20) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - dist experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_medmnist.py --experiment_id=0 --task_to_run='Organ_dist' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_medmnist import config_experiments_secondary\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_secondary(results_path + '/MedMNIST/results/results_Secondary/',True)\n",
    "with open(results_path + '/MedMNIST/results/results_Secondary/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_medmnist.py --experiment_id=0 --task_to_run='Secondary' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for distribution secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_medmnist import config_experiments_secondary_dist\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_secondary_dist(results_path + '/MedMNIST/results/results_Secondary_dist/',True)\n",
    "with open(results_path + '/MedMNIST/results/results_Secondary_dist/' + 'configs/' + str(60) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - dist secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_medmnist.py --experiment_id=0 --task_to_run='Secondary_dist' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_medmnist import config_experiments_reduced\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_reduced(results_path + '/MedMNIST/results/results_Reduced/',True)\n",
    "with open(results_path + '/MedMNIST/results/results_Reduced/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_medmnist.py --experiment_id=0 --task_to_run='Reduced' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments_medmnist import config_experiments_reduced_secondary\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_reduced_secondary(results_path + '/MedMNIST/results/results_ReducedSecondary/',True)\n",
    "with open(results_path + '/MedMNIST/results/results_ReducedSecondary/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main_medmnist.py --experiment_id=0 --task_to_run='ReducedSecondary' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - hyper experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_medmnist import config_experiments_hyper\n",
    "from utils import gatherMetrics_medmnist\n",
    "import json\n",
    "\n",
    "# current task\n",
    "task = 'Organ_hyper'\n",
    "    \n",
    "experiment_list = config_experiments_hyper(results_path + '/MedMNIST/results/results_' + task + '/',False)\n",
    "\n",
    "cnt = 0\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MedMNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_hyper = gatherMetrics_medmnist(experiment_list, task)  \n",
    "idx = np.argmax(df_hyper['val_bal_acc'])\n",
    "print(df_hyper['learning_rate'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - seed experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_medmnist import config_experiments\n",
    "from utils import gatherMetrics_medmnist\n",
    "import json\n",
    "\n",
    "# current task\n",
    "task = 'Organ'\n",
    "    \n",
    "experiment_list = config_experiments(results_path + '/MedMNIST/results/results_' + task + '/',False)\n",
    "\n",
    "cnt = 0\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MedMNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df = gatherMetrics_medmnist(experiment_list, task)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_medmnist import config_experiments_dist\n",
    "from utils import gatherMetrics_medmnist\n",
    "import json\n",
    "\n",
    "# current task\n",
    "task = 'Organ_dist'\n",
    "    \n",
    "experiment_list = config_experiments_dist(results_path + '/MedMNIST/results/results_' + task + '/',False)\n",
    "\n",
    "cnt = 0\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MedMNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "    # else:\n",
    "    #     print(curr_exp)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_dist = gatherMetrics_medmnist(experiment_list, task)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_medmnist import config_experiments_secondary\n",
    "from utils import gatherMetrics_medmnist\n",
    "import json\n",
    "\n",
    "task = 'Secondary'\n",
    "\n",
    "experiment_list = config_experiments_secondary(results_path + '/MedMNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MedMNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        print(curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments\n",
    "df_secondary = gatherMetrics_medmnist(experiment_list, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_medmnist import config_experiments_secondary_dist\n",
    "from utils import gatherMetrics_medmnist\n",
    "import json\n",
    "\n",
    "task = 'Secondary_dist'\n",
    "\n",
    "experiment_list = config_experiments_secondary_dist(results_path + '/MedMNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MedMNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        cnt = cnt + 1\n",
    "    # else:\n",
    "    #     print(curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments\n",
    "df_dist_secondary = gatherMetrics_medmnist(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_medmnist import config_experiments_reduced\n",
    "from utils import gatherMetrics_medmnist\n",
    "import json\n",
    "\n",
    "task = 'Reduced'\n",
    "\n",
    "experiment_list = config_experiments_reduced(results_path + '/MedMNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MedMNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        cnt = cnt + 1\n",
    "    # else:\n",
    "    #     print(curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments\n",
    "df_reduced = gatherMetrics_medmnist(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_medmnist import config_experiments_reduced_secondary\n",
    "from utils import gatherMetrics_medmnist\n",
    "import json\n",
    "\n",
    "task = 'ReducedSecondary'\n",
    "\n",
    "experiment_list = config_experiments_reduced_secondary(results_path + '/MedMNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MedMNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        print(curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments\n",
    "df_reduced_secondary = gatherMetrics_medmnist(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot accuracy difference - secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MedMNIST/'\n",
    "results_dir = results_path + '/MedMNIST/results/results_Organ/'\n",
    "results_dir_sec = results_path + '/MedMNIST/results/results_Secondary/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "\n",
    "# hard-code MedMNIST has 3 views and 11 organs\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "CLASS_NAMES_exp.append(['Bladder','Left femoral head','Right femoral head','Heart','Left kidney',\n",
    "                        'Right kidney','Liver','Left lung','Right lung','Pancreas','Spleen'])\n",
    "CLASS_NAMES_exp.append(['Axial','Coronal','Sagittal'])\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[0])))\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[1])))\n",
    "        \n",
    "# x and y_axis ticks\n",
    "y_list = CLASS_NAMES_exp[0]  \n",
    "x_list = CLASS_NAMES_exp[1]  \n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "# plot params\n",
    "plotOOD = False\n",
    "\n",
    "# iterate over seeds\n",
    "seed_vec = [42,73,666,777,1009]# ,1279,1597,1811,1949,2053]\n",
    "model_type_vec = ['ResNet18'] # ,'DenseNet121','ResNet50','ViTb16'\n",
    "sampling_percentage_vec = [100,75,50,35,25,10,5]\n",
    "\n",
    "# colors for plotting\n",
    "blue_colors = [mcolors.CSS4_COLORS['darkslateblue'],\n",
    "               mcolors.CSS4_COLORS['midnightblue'],\n",
    "                mcolors.CSS4_COLORS['darkblue'],\n",
    "                mcolors.CSS4_COLORS['mediumblue'],\n",
    "                mcolors.CSS4_COLORS['royalblue'],\n",
    "                mcolors.CSS4_COLORS['cornflowerblue'],\n",
    "                mcolors.CSS4_COLORS['lightblue']]\n",
    "\n",
    "red_colors = [mcolors.CSS4_COLORS['darkred'],\n",
    "                  mcolors.CSS4_COLORS['firebrick'],\n",
    "                  mcolors.CSS4_COLORS['crimson'],\n",
    "                  mcolors.CSS4_COLORS['red'],\n",
    "                  mcolors.CSS4_COLORS['orangered'],\n",
    "                  mcolors.CSS4_COLORS['orange'],\n",
    "                  mcolors.CSS4_COLORS['gold']]\n",
    "\n",
    "purple_colors = [mcolors.CSS4_COLORS['indigo'],\n",
    "                mcolors.CSS4_COLORS['purple'],\n",
    "                mcolors.CSS4_COLORS['darkviolet'],\n",
    "                mcolors.CSS4_COLORS['mediumorchid'],\n",
    "                mcolors.CSS4_COLORS['orchid'],\n",
    "                mcolors.CSS4_COLORS['thistle'],\n",
    "                mcolors.CSS4_COLORS['lavender']]\n",
    "\n",
    "# iterate over random seed\n",
    "for model_type in model_type_vec:\n",
    "    print('Model type: ' + model_type)\n",
    "    \n",
    "    # initialize\n",
    "    mean_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    mean_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    mean_eval_mat_ = np.zeros([len(sampling_percentage_vec),num_classes[1]])\n",
    "    mean_eval_sec_mat_ = np.zeros([len(sampling_percentage_vec),num_classes[1]])\n",
    "    std_eval_mat_ = np.zeros([len(sampling_percentage_vec),num_classes[1]])\n",
    "    std_eval_sec_mat_ = np.zeros([len(sampling_percentage_vec),num_classes[1]])\n",
    "    cnt_sampling_percentage = 0\n",
    "    \n",
    "    # iterate over sampling percentages\n",
    "    for sampling_percentage in sampling_percentage_vec:\n",
    "        cnt_seed = 0\n",
    "    \n",
    "        # initialize\n",
    "        eval_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_sec_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_vec_ = np.zeros([len(seed_vec),num_classes[1]])\n",
    "        eval_sec_vec_ = np.zeros([len(seed_vec),num_classes[1]])\n",
    "        eval_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_sec_vec = np.zeros([len(seed_vec),1])\n",
    "        cnt_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    \n",
    "        for seed in seed_vec:\n",
    "            \n",
    "            # get the current experiment\n",
    "            df_ = df[(df['seed'] == seed) & (df['model_type'] == model_type) & (df['sampling_percentage'] == sampling_percentage) ]\n",
    "            \n",
    "            # get the current experiment\n",
    "            curr_exp = int(df_['experiment_id'])\n",
    "            curr_path = results_dir + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                eval_ = np.array(data['eval_mat_sec']) \n",
    "    \n",
    "            # filter df_nbrData_secondary\n",
    "            eval_sec = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "    \n",
    "            # iterate over secondary experiments\n",
    "            cnt_sec = 0\n",
    "            for i in range(num_classes[1]):\n",
    "        \n",
    "                # get the current experiment\n",
    "                df_secondary_ = df_secondary[(df_secondary['model_type'] == model_type) &\n",
    "                                             (df_secondary['sampling_percentage'] == sampling_percentage) &\n",
    "                                             (df_secondary['task2'] == i) & \n",
    "                                             (df_secondary['seed'] == seed)]\n",
    "                curr_exp = int(df_secondary_['experiment_id'])\n",
    "                curr_path = results_dir_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f) \n",
    "                    # calculate id accuracy \n",
    "                    for j in range(num_classes[0]):\n",
    "                        eval_sec[j,i] = np.array(data['eval_mat'])[j]  \n",
    "                    \n",
    "            # sum for each seed\n",
    "            eval_mat = eval_mat + eval_\n",
    "            eval_sec_mat = eval_sec_mat + eval_sec\n",
    "            eval_vec_[cnt_seed,:] = np.nanmean(eval_,axis=0)\n",
    "            eval_sec_vec_[cnt_seed,:] = np.nanmean(eval_sec,axis=0)\n",
    "            eval_vec[cnt_seed,:] = np.nanmean(eval_)\n",
    "            eval_sec_vec[cnt_seed,:] = np.nanmean(eval_sec)\n",
    "            cnt_mat = cnt_mat + ((eval_sec - eval_) > 0)\n",
    "            cnt_seed = cnt_seed + 1\n",
    "               \n",
    "        # average\n",
    "        eval_mat = eval_mat/cnt_seed\n",
    "        eval_sec_mat = eval_sec_mat/cnt_seed\n",
    "        # detailed\n",
    "        mean_eval_mat_[cnt_sampling_percentage,:] = np.mean(eval_vec_,axis=0)\n",
    "        mean_eval_sec_mat_[cnt_sampling_percentage,:] = np.mean(eval_sec_vec_,axis=0)\n",
    "        std_eval_mat_[cnt_sampling_percentage,:] = np.nanstd(eval_vec_,axis=0)\n",
    "        std_eval_sec_mat_[cnt_sampling_percentage,:] = np.nanstd(eval_sec_vec_,axis=0)\n",
    "        # general\n",
    "        mean_eval_mat[cnt_sampling_percentage,:] = np.mean(eval_vec)\n",
    "        mean_eval_sec_mat[cnt_sampling_percentage,:] = np.mean(eval_sec_vec)\n",
    "        std_eval_mat[cnt_sampling_percentage,:] = np.nanstd(eval_vec)\n",
    "        std_eval_sec_mat[cnt_sampling_percentage,:] = np.nanstd(eval_sec_vec)\n",
    "        \n",
    "        # print\n",
    "        if plotOOD:\n",
    "            print('Sampling percentage: ' + str(sampling_percentage))\n",
    "            print('General model - mean & std: ' + str(mean_eval_mat[cnt_sampling_percentage,:]) + '&' + str(std_eval_mat[cnt_sampling_percentage,:]))\n",
    "            print('Specialized model - mean & std: ' + str(mean_eval_sec_mat[cnt_sampling_percentage,:]) + '&' + str(std_eval_sec_mat[cnt_sampling_percentage,:]))\n",
    "        cnt_sampling_percentage = cnt_sampling_percentage + 1\n",
    "        \n",
    "        # number of datapoints\n",
    "        datapoints_train = np.array([[1956,1153,1148],\n",
    "         [1408, 626, 637],\n",
    "         [1359, 608, 615],\n",
    "         [1474, 600, 721],\n",
    "         [3963,1088,1132],\n",
    "         [3817,1170,1119],\n",
    "         [6164,2986,3464],\n",
    "         [3919,1002, 741],\n",
    "         [3929,1022, 803],\n",
    "         [3031,1173,2004],\n",
    "         [3561,1572,1556]])\n",
    "        datapoints_train = datapoints_train * (sampling_percentage/100)\n",
    "\n",
    "        # datapoints_train = np.array([[1000,1000,1000],\n",
    "        #  [1000, 626, 637],\n",
    "        #  [1000, 608, 615],\n",
    "        #  [1000, 600, 721],\n",
    "        #  [1000,1000,1000],\n",
    "        #  [1000,1000,1000],\n",
    "        #  [1000,1000,1000],\n",
    "        #  [1000,1000, 741],\n",
    "        #  [1000,1000, 803],\n",
    "        #  [1000,1000,1000],\n",
    "        #  [1000,1000,1000]])\n",
    "\n",
    "        if plotOOD:    \n",
    "    \n",
    "            # diff ood\n",
    "            eval_diff = eval_mat - eval_sec_mat\n",
    "\n",
    "            # plot\n",
    "            fig = plt.figure(figsize=(12, 4), dpi=80)\n",
    "    \n",
    "            # number of datapoints\n",
    "            ax1 = fig.add_subplot(1,5,1)\n",
    "            im1 = ax1.imshow(datapoints_train) \n",
    "            ax1.set_xticks(np.arange(len(x_list)), labels=x_list)\n",
    "            ax1.set_yticks(np.arange(len(y_list)), labels=y_list)\n",
    "            plt.setp(ax1.get_xticklabels(), rotation=30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            plt.setp(ax1.get_yticklabels(), rotation=-30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            ax1.set_title(\"Number of samples\")\n",
    "            fig.colorbar(im1, orientation='vertical')\n",
    "\n",
    "            # specialized model\n",
    "            ax2 = fig.add_subplot(1,5,2)\n",
    "            im2 = ax2.imshow(eval_sec_mat, vmin=0, vmax=1) \n",
    "            ax2.set_xticks(np.arange(len(x_list)), labels=x_list)\n",
    "            ax2.set_yticks([])\n",
    "            plt.setp(ax2.get_xticklabels(), rotation=30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            plt.setp(ax2.get_yticklabels(), rotation=-30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            ax2.set_title(\"Specialized model\")\n",
    "            fig.colorbar(im2, orientation='vertical')\n",
    "\n",
    "            # test\n",
    "            ax3 = fig.add_subplot(1,5,3)\n",
    "            im3 = ax3.imshow(eval_mat, vmin=0, vmax=1) \n",
    "            ax3.set_xticks(np.arange(len(x_list)),labels=x_list)\n",
    "            ax3.set_yticks([])\n",
    "            plt.setp(ax3.get_xticklabels(), rotation=30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            plt.setp(ax3.get_yticklabels(), rotation=-30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            ax3.set_title(\"General model\")\n",
    "            fig.colorbar(im3, orientation='vertical')\n",
    "\n",
    "            # difference\n",
    "            ax4 = fig.add_subplot(1,5,4)\n",
    "            im4 = ax4.imshow(eval_diff, vmin=-0.1, vmax=0.1, cmap=cmap) \n",
    "            ax4.set_xticks(np.arange(len(x_list)),labels=x_list)\n",
    "            ax4.set_yticks([])\n",
    "            plt.setp(ax4.get_xticklabels(), rotation=30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            plt.setp(ax4.get_yticklabels(), rotation=-30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            ax4.set_title(\"Difference\")\n",
    "            fig.colorbar(im4, orientation='vertical')\n",
    "    \n",
    "            # check how many times specialized better than general\n",
    "            ax5 = fig.add_subplot(1,5,5)\n",
    "            im5 = ax5.imshow(cnt_mat, vmin=0, vmax=len(seed_vec)) \n",
    "            ax5.set_xticks(np.arange(len(x_list)),labels=x_list)\n",
    "            ax5.set_yticks([])\n",
    "            plt.setp(ax5.get_xticklabels(), rotation=30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            plt.setp(ax5.get_yticklabels(), rotation=-30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "            ax5.set_title(\"Specialized better\")\n",
    "            fig.colorbar(im5, orientation='vertical')\n",
    "\n",
    "            plt.subplots_adjust(wspace=0.1)\n",
    "            plt.show()\n",
    "            \n",
    "    fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "    # plt.subplot(1,2,1)\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_sec_mat[:,0],yerr=std_eval_sec_mat[:,0],linewidth=2.5,label='Specialized',color=blue_colors[0])\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_mat[:,0],yerr=std_eval_mat[:,0],linewidth=2.5,label='Multi-domain',color=red_colors[0])\n",
    "    plt.ylim([0.5,1])\n",
    "    plt.xlabel('Sampling percentage [%]')\n",
    "    plt.ylabel('Average balanced accuracy')\n",
    "    # plt.title('Specialized vs General -  OOD')\n",
    "    plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=2)\n",
    "    # plt.show()\n",
    "    # plt.savefig('figs/medmnist_specialized_vs_general.eps', bbox_inches='tight', format='eps')  \n",
    "    plt.savefig('figs/medmnist_specialized_vs_general.pdf', bbox_inches='tight', format='pdf')  \n",
    "\n",
    "    if plotOOD:        \n",
    "        # plot\n",
    "        fig = plt.figure(figsize=(13, 3), dpi=80)\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(sampling_percentage_vec,mean_eval_sec_mat,label='Specialized',color=blue_colors[0])\n",
    "        for i in range(0,num_classes[1]):\n",
    "            if i == 0:\n",
    "                view = 'Axial'\n",
    "            elif i == 1:\n",
    "                view = 'Coronal'\n",
    "            else:\n",
    "                view = 'Sagittal'\n",
    "            plt.plot(sampling_percentage_vec,mean_eval_sec_mat_[:,i],label='Specialized - View: ' + view,linestyle='dashed',color=blue_colors[2*i+1])\n",
    "        plt.plot(sampling_percentage_vec,mean_eval_mat,label='General',color=red_colors[0])\n",
    "        for i in range(0,num_classes[1]):\n",
    "            if i == 0:\n",
    "                view = 'Axial'\n",
    "            elif i == 1:\n",
    "                view = 'Coronal'\n",
    "            else:\n",
    "                view = 'Sagittal'\n",
    "            plt.plot(sampling_percentage_vec,mean_eval_mat_[:,i],label='General - View: ' + view,linestyle='dashed',color=red_colors[2*i+1])\n",
    "        plt.ylim([0.5,1])\n",
    "        plt.xlabel('Sampling percentage [%]')\n",
    "        plt.ylabel('Average balanced accuracy')\n",
    "        plt.title('Specialized vs General')\n",
    "        plt.legend(bbox_to_anchor=(1.75, 0.5),loc='right', ncol=1)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(sampling_percentage_vec,mean_eval_mat-mean_eval_sec_mat,color=purple_colors[0],label='Average')\n",
    "        for i in range(0,num_classes[1]):\n",
    "            if i == 0:\n",
    "                view = 'Axial'\n",
    "            elif i == 1:\n",
    "                view = 'Coronal'\n",
    "            else:\n",
    "                view = 'Sagittal'\n",
    "            plt.plot(sampling_percentage_vec,mean_eval_mat_[:,i]-mean_eval_sec_mat_[:,i],label='View: ' + view,linestyle='dashed',color=purple_colors[2*i+1])\n",
    "        plt.ylim([-0.05,0.05])\n",
    "        plt.xlabel('Sampling percentage [%]')\n",
    "        plt.ylabel('Balanced accuracy difference')\n",
    "        plt.title('Difference - Specialized vs General')\n",
    "        plt.legend(bbox_to_anchor=(1.475, 0.5),loc='right', ncol=1)\n",
    "        plt.subplots_adjust(wspace=1)\n",
    "        plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot accuracy difference - dist experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MedMNIST/'\n",
    "results_dir = results_path + '/MedMNIST/results/results_Organ_dist/'\n",
    "results_dir_sec = results_path + '/MedMNIST/results/results_Secondary_dist/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "\n",
    "# hard-code MedMNIST has 3 views and 11 organs\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "CLASS_NAMES_exp.append(['Bladder','Left femoral head','Right femoral head','Heart','Left kidney',\n",
    "                        'Right kidney','Liver','Left lung','Right lung','Pancreas','Spleen'])\n",
    "CLASS_NAMES_exp.append(['Axial','Coronal','Sagittal'])\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[0])))\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[1])))\n",
    "        \n",
    "# x and y_axis ticks\n",
    "y_list = CLASS_NAMES_exp[0]  \n",
    "x_list = CLASS_NAMES_exp[1]  \n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "# iterate over seeds\n",
    "seed_vec = [42,73,666,777,1009]# ,1279,1597,1811,1949,2053]\n",
    "model_type_vec = ['ResNet18'] # ,'DenseNet121' \n",
    "sampling_percentage_vec = [100,75,50,35,25,10,5]\n",
    "max_sample_train = 600\n",
    "\n",
    "blue_colors = [mcolors.CSS4_COLORS['darkslateblue'],\n",
    "               mcolors.CSS4_COLORS['midnightblue'],\n",
    "                mcolors.CSS4_COLORS['darkblue'],\n",
    "                mcolors.CSS4_COLORS['mediumblue'],\n",
    "                mcolors.CSS4_COLORS['royalblue'],\n",
    "                mcolors.CSS4_COLORS['cornflowerblue'],\n",
    "                mcolors.CSS4_COLORS['lightblue']]\n",
    "\n",
    "red_colors = [mcolors.CSS4_COLORS['darkred'],\n",
    "                  mcolors.CSS4_COLORS['firebrick'],\n",
    "                  mcolors.CSS4_COLORS['crimson'],\n",
    "                  mcolors.CSS4_COLORS['red'],\n",
    "                  mcolors.CSS4_COLORS['orangered'],\n",
    "                  mcolors.CSS4_COLORS['orange'],\n",
    "                  mcolors.CSS4_COLORS['gold']]\n",
    "\n",
    "purple_colors = [mcolors.CSS4_COLORS['indigo'],\n",
    "                mcolors.CSS4_COLORS['purple'],\n",
    "                mcolors.CSS4_COLORS['darkviolet'],\n",
    "                mcolors.CSS4_COLORS['mediumorchid'],\n",
    "                mcolors.CSS4_COLORS['orchid'],\n",
    "                mcolors.CSS4_COLORS['thistle'],\n",
    "                mcolors.CSS4_COLORS['lavender']]\n",
    "\n",
    "# iterate over random seed\n",
    "for model_type in model_type_vec:\n",
    "    print('Model type: ' + model_type)\n",
    "\n",
    "    # initialize\n",
    "    mean_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    mean_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    mean_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    mean_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    cnt_sampling_percentage = 0\n",
    "    \n",
    "    # iterate over sampling percentage\n",
    "    for sampling_percentage in sampling_percentage_vec:\n",
    "        # print\n",
    "        print('Sampling percentage: ' + str(sampling_percentage))\n",
    "    \n",
    "        # initlaize eval_mat\n",
    "        eval_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_id_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_sec_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_sec_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_sec_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_sec_id_vec = np.zeros([len(seed_vec),1])\n",
    "        cnt_seed = 0\n",
    "    \n",
    "        # iterate over random seed\n",
    "        for seed in seed_vec:     \n",
    "        \n",
    "            # get the current general experiment\n",
    "            df_ = df_dist[(df_dist['seed'] == seed) & \n",
    "                     (df_dist['model_type'] == model_type) &\n",
    "                     (df_dist['max_sample_train'] == max_sample_train) &\n",
    "                     (df_dist['sampling_percentage'] == sampling_percentage)]\n",
    "            curr_exp = int(df_['experiment_id'])\n",
    "            curr_path = results_dir + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                eval_ = np.array(data['eval_mat_sec'])\n",
    "                eval_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "                # calculate id accuracy \n",
    "                for j in range(num_classes[0]):\n",
    "                    for i in range(num_classes[1]):\n",
    "                        tmp = np.array(data['eval_mat_sec'], copy=True)  \n",
    "                        tmp[j,i] = float('nan')\n",
    "                        eval_id[j,i] = np.nanmean(tmp) \n",
    "                    \n",
    "            # sum for each seed\n",
    "            eval_mat = eval_mat + eval_\n",
    "            eval_id_mat = eval_id_mat + eval_id\n",
    "            eval_vec[cnt_seed] = np.nanmean(eval_)\n",
    "            eval_id_vec[cnt_seed] = np.nanmean(eval_id)\n",
    "    \n",
    "            # filter df_nbrData_secondary\n",
    "            eval_sec = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_sec_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "    \n",
    "            # iterate over secondary experiments\n",
    "            for i in range(num_classes[1]):\n",
    "        \n",
    "                # get the current experiment\n",
    "                df_sec_ = df_dist_secondary[(df_dist_secondary['task2'] == i) & \n",
    "                                   (df_dist_secondary['seed'] == seed) & \n",
    "                                   (df_dist_secondary['model_type'] == model_type) & \n",
    "                                   (df_dist_secondary['max_sample_train'] == max_sample_train) &\n",
    "                                   (df_dist_secondary['sampling_percentage'] == sampling_percentage)]\n",
    "                curr_exp = int(df_sec_['experiment_id'])\n",
    "                curr_path = results_dir_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f) \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    for j in range(num_classes[0]):\n",
    "                        eval_sec[j,i] = np.array(data['eval_mat'])[j]\n",
    "                        tmp = np.array(data['eval_mat'], copy=True)  \n",
    "                        tmp[j] = float('nan')\n",
    "                        eval_sec_id[j,i] = np.nanmean(tmp) \n",
    "                    \n",
    "            # sum for each seed\n",
    "            eval_sec_mat = eval_sec_mat + eval_sec\n",
    "            eval_sec_id_mat = eval_sec_id_mat + eval_sec_id\n",
    "            eval_sec_vec[cnt_seed] = np.nanmean(eval_sec)\n",
    "            eval_sec_id_vec[cnt_seed] = np.nanmean(eval_sec_id)\n",
    "            cnt_seed = cnt_seed + 1\n",
    "        \n",
    "        # assign for each sampling_percentage\n",
    "        # general\n",
    "        eval_mat = eval_mat/cnt_seed\n",
    "        eval_id_mat = eval_id_mat/cnt_seed\n",
    "        mean_eval_mat[cnt_sampling_percentage] = np.nanmean(eval_vec)\n",
    "        mean_eval_id_mat[cnt_sampling_percentage] = np.nanmean(eval_id_vec)\n",
    "        std_eval_mat[cnt_sampling_percentage] = np.nanstd(eval_vec)\n",
    "        std_eval_id_mat[cnt_sampling_percentage] = np.nanstd(eval_id_vec)\n",
    "        # secondary\n",
    "        eval_sec_mat = eval_sec_mat/cnt_seed\n",
    "        eval_sec_id_mat = eval_sec_id_mat/cnt_seed\n",
    "        mean_eval_sec_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_vec)\n",
    "        mean_eval_sec_id_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_id_vec)\n",
    "        std_eval_sec_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_vec)\n",
    "        std_eval_sec_id_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_id_vec)\n",
    "        cnt_sampling_percentage = cnt_sampling_percentage + 1\n",
    "    \n",
    "    fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "    # plt.subplot(1,2,1)\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_sec_mat[:,0],yerr=std_eval_sec_mat[:,0],linewidth=2.5,label='Specialized',color=blue_colors[0])\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_mat[:,0],yerr=std_eval_mat[:,0],linewidth=2.5,label='Multi-domain',color=red_colors[0])\n",
    "    plt.ylim([0.5,1])\n",
    "    plt.xlabel('Sampling percentage [%]')\n",
    "    plt.ylabel('Average balanced accuracy')\n",
    "    # plt.title('Specialized vs General -  OOD')\n",
    "    plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=2)\n",
    "    # plt.show()\n",
    "    # plt.savefig('figs/medmnist_dist_specialized_vs_general.eps', bbox_inches='tight', format='eps')\n",
    "    plt.savefig('figs/medmnist_dist_specialized_vs_general.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot accuracy difference - all reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MedMNIST/'\n",
    "results_dir = results_path + '/MedMNIST/results/results_Organ/'\n",
    "results_dir_red = results_path + '/MedMNIST/results/results_Reduced/'\n",
    "results_dir_sec = results_path + '/MedMNIST/results/results_Secondary/'\n",
    "results_dir_red_sec = results_path + '/MedMNIST/results/results_ReducedSecondary/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "\n",
    "# hard-code MedMNIST has 3 views and 11 organs\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "CLASS_NAMES_exp.append(['Bladder','Left femoral head','Right femoral head','Heart','Left kidney',\n",
    "                        'Right kidney','Liver','Left lung','Right lung','Pancreas','Spleen'])\n",
    "CLASS_NAMES_exp.append(['Axial','Coronal','Sagittal'])\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[0])))\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[1])))\n",
    "        \n",
    "# x and y_axis ticks\n",
    "y_list = CLASS_NAMES_exp[0]  \n",
    "x_list = CLASS_NAMES_exp[1]  \n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "# iterate over seeds\n",
    "seed_vec = [42,73,666,777,1009]# ,1279,1597,1811,1949,2053]\n",
    "model_type_vec = ['ResNet18'] # ,'DenseNet121' \n",
    "sampling_percentage_vec = [100,75,50,35,25,10,5]\n",
    "reduced_percentage_vec = [25,50,75,85,95,100] \n",
    "\n",
    "blue_colors = [mcolors.CSS4_COLORS['darkslateblue'],\n",
    "               mcolors.CSS4_COLORS['midnightblue'],\n",
    "                mcolors.CSS4_COLORS['darkblue'],\n",
    "                mcolors.CSS4_COLORS['mediumblue'],\n",
    "                mcolors.CSS4_COLORS['royalblue'],\n",
    "                mcolors.CSS4_COLORS['cornflowerblue'],\n",
    "                mcolors.CSS4_COLORS['lightblue']]\n",
    "\n",
    "red_colors = [mcolors.CSS4_COLORS['darkred'],\n",
    "                  mcolors.CSS4_COLORS['firebrick'],\n",
    "                  mcolors.CSS4_COLORS['crimson'],\n",
    "                  mcolors.CSS4_COLORS['red'],\n",
    "                  mcolors.CSS4_COLORS['orangered'],\n",
    "                  mcolors.CSS4_COLORS['orange'],\n",
    "                  mcolors.CSS4_COLORS['gold']]\n",
    "\n",
    "purple_colors = [mcolors.CSS4_COLORS['indigo'],\n",
    "                mcolors.CSS4_COLORS['purple'],\n",
    "                mcolors.CSS4_COLORS['darkviolet'],\n",
    "                mcolors.CSS4_COLORS['mediumorchid'],\n",
    "                mcolors.CSS4_COLORS['orchid'],\n",
    "                mcolors.CSS4_COLORS['thistle'],\n",
    "                mcolors.CSS4_COLORS['lavender']]\n",
    "\n",
    "# iterate over random seed\n",
    "for model_type in model_type_vec:\n",
    "    print('Model type: ' + model_type)\n",
    "\n",
    "    # initialize\n",
    "    mean_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    mean_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    mean_eval_red_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "    mean_eval_red_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "    std_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_red_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "    std_eval_red_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "    mean_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    mean_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    mean_eval_red_sec_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "    mean_eval_red_sec_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "    std_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "    std_eval_red_sec_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "    std_eval_red_sec_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "    cnt_sampling_percentage = 0\n",
    "    \n",
    "    # iterate over sampling percentage\n",
    "    for sampling_percentage in sampling_percentage_vec:\n",
    "        # print\n",
    "        print('Sampling percentage: ' + str(sampling_percentage))\n",
    "    \n",
    "        # initlaize eval_mat\n",
    "        eval_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_id_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_sec_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_sec_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_sec_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_sec_id_vec = np.zeros([len(seed_vec),1])\n",
    "        cnt_seed = 0\n",
    "    \n",
    "        # iterate over random seed\n",
    "        for seed in seed_vec:     \n",
    "        \n",
    "            # get the current general experiment\n",
    "            df_ = df[(df['seed'] == seed) & \n",
    "                     (df['model_type'] == model_type) &\n",
    "                     (df['sampling_percentage'] == sampling_percentage)]\n",
    "            curr_exp = int(df_['experiment_id'])\n",
    "            curr_path = results_dir + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                \n",
    "                eval_ = np.array(data['eval_mat_sec'])\n",
    "                eval_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "                # calculate id accuracy \n",
    "                for j in range(num_classes[0]):\n",
    "                    for i in range(num_classes[1]):\n",
    "                        tmp = np.array(data['eval_mat_sec'], copy=True)  \n",
    "                        tmp[j,i] = float('nan')\n",
    "                        eval_id[j,i] = np.nanmean(tmp) \n",
    "                    \n",
    "            # sum for each seed\n",
    "            eval_mat = eval_mat + eval_\n",
    "            eval_id_mat = eval_id_mat + eval_id\n",
    "            eval_vec[cnt_seed] = np.nanmean(eval_)\n",
    "            eval_id_vec[cnt_seed] = np.nanmean(eval_id)\n",
    "    \n",
    "            # filter df_nbrData_secondary\n",
    "            eval_sec = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_sec_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "    \n",
    "            # iterate over secondary experiments\n",
    "            for i in range(num_classes[1]):\n",
    "        \n",
    "                # get the current experiment\n",
    "                df_sec_ = df_secondary[(df_secondary['task2'] == i) & \n",
    "                                   (df_secondary['seed'] == seed) & \n",
    "                                   (df_secondary['model_type'] == model_type) & \n",
    "                                   (df_secondary['sampling_percentage'] == sampling_percentage)]\n",
    "                curr_exp = int(df_sec_['experiment_id'])\n",
    "                curr_path = results_dir_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f) \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    for j in range(num_classes[0]):\n",
    "                        eval_sec[j,i] = np.array(data['eval_mat'])[j]\n",
    "                        tmp = np.array(data['eval_mat'], copy=True)  \n",
    "                        tmp[j] = float('nan')\n",
    "                        eval_sec_id[j,i] = np.nanmean(tmp) \n",
    "                    \n",
    "            # sum for each seed\n",
    "            eval_sec_mat = eval_sec_mat + eval_sec\n",
    "            eval_sec_id_mat = eval_sec_id_mat + eval_sec_id\n",
    "            eval_sec_vec[cnt_seed] = np.nanmean(eval_sec)\n",
    "            eval_sec_id_vec[cnt_seed] = np.nanmean(eval_sec_id)\n",
    "            cnt_seed = cnt_seed + 1\n",
    "        \n",
    "        # assign for each sampling_percentage\n",
    "        # general\n",
    "        eval_mat = eval_mat/cnt_seed\n",
    "        eval_id_mat = eval_id_mat/cnt_seed\n",
    "        mean_eval_mat[cnt_sampling_percentage] = np.nanmean(eval_vec)\n",
    "        mean_eval_id_mat[cnt_sampling_percentage] = np.nanmean(eval_id_vec)\n",
    "        std_eval_mat[cnt_sampling_percentage] = np.nanstd(eval_vec)\n",
    "        std_eval_id_mat[cnt_sampling_percentage] = np.nanstd(eval_id_vec)\n",
    "        # secondary\n",
    "        eval_sec_mat = eval_sec_mat/cnt_seed\n",
    "        eval_sec_id_mat = eval_sec_id_mat/cnt_seed\n",
    "        mean_eval_sec_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_vec)\n",
    "        mean_eval_sec_id_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_id_vec)\n",
    "        std_eval_sec_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_vec)\n",
    "        std_eval_sec_id_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_id_vec)\n",
    "    \n",
    "        # iterate over reduced secondary experiments\n",
    "        cnt_reduced_percentage = 0\n",
    "    \n",
    "        for reduced_percentage in reduced_percentage_vec:\n",
    "            # initialize\n",
    "            eval_red_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_red_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_red_vec = np.zeros([len(seed_vec),1])\n",
    "            eval_red_id_vec = np.zeros([len(seed_vec),1])\n",
    "            eval_red_sec_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_red_sec_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_red_sec_vec = np.zeros([len(seed_vec),1])\n",
    "            eval_red_sec_id_vec = np.zeros([len(seed_vec),1])\n",
    "            cnt_seed = 0\n",
    "        \n",
    "            # iterate over random seed\n",
    "            for seed in seed_vec: \n",
    "            \n",
    "                # initialize\n",
    "                eval_red = np.zeros([num_classes[0],num_classes[1]])\n",
    "                eval_red_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "                # get the current experiment\n",
    "                df_red = df_reduced[(df_reduced['seed'] == seed) & \n",
    "                                (df_reduced['model_type'] == model_type) & \n",
    "                                (df_reduced['sampling_percentage'] == sampling_percentage) & \n",
    "                                (df_reduced['reduced_percentage'] == reduced_percentage)]\n",
    "            \n",
    "                # iterate over tasks\n",
    "                for i in range(num_classes[1]):\n",
    "                    for j in range(num_classes[0]):\n",
    "                        # get the current experiment\n",
    "                        df_red_ = df_red[(df_red['task1'] == j) & (df_red['task2'] == i)]\n",
    "                        curr_exp = int(df_red_['experiment_id'])\n",
    "                        curr_path = results_dir_red + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                        if os.path.exists(curr_path):\n",
    "                            with open(curr_path, 'r') as f:\n",
    "                                data = json.load(f) \n",
    "                \n",
    "                            eval_red[j,i] = np.array(data['eval_mat_sec'])[j,i]\n",
    "                            tmp = np.array(data['eval_mat_sec'], copy=True)  \n",
    "                            tmp[j,i] = float('nan')\n",
    "                            eval_red_id[j,i] = np.nanmean(tmp)   \n",
    "                # sum for each seed\n",
    "                eval_red_mat = eval_red_mat + eval_red\n",
    "                eval_red_id_mat = eval_red_id_mat + eval_red_id\n",
    "                eval_red_vec[cnt_seed] = np.nanmean(eval_red)\n",
    "                eval_red_id_vec[cnt_seed] = np.nanmean(eval_red_id)\n",
    "            \n",
    "                # initialize\n",
    "                eval_red_sec = np.zeros([num_classes[0],num_classes[1]])\n",
    "                eval_red_sec_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "                # get the current experiment\n",
    "                df_red_sec = df_reduced_secondary[(df_reduced_secondary['seed'] == seed) & \n",
    "                                             (df_reduced_secondary['model_type'] == model_type) &      \n",
    "                                             (df_reduced_secondary['sampling_percentage'] == sampling_percentage) & \n",
    "                                             (df_reduced_secondary['reduced_percentage'] == reduced_percentage)]\n",
    "            \n",
    "                # iterate over tasks\n",
    "                for i in range(num_classes[1]):\n",
    "                    # initialize cnt\n",
    "                    for j in range(num_classes[0]):\n",
    "                        # get the current experiment\n",
    "                        df_red_sec_ = df_red_sec[(df_red_sec['task1'] == j) & (df_red_sec['task2'] == i)]\n",
    "                        curr_exp = int(df_red_sec_['experiment_id'])\n",
    "                        curr_path = results_dir_red_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                        if os.path.exists(curr_path):\n",
    "                            with open(curr_path, 'r') as f:\n",
    "                                data = json.load(f) \n",
    "                \n",
    "                            eval_red_sec[j,i] = np.array(data['eval_mat'])[j]\n",
    "                            tmp = np.array(data['eval_mat'], copy=True)  \n",
    "                            tmp[j] = float('nan')\n",
    "                            eval_red_sec_id[j,i] = np.nanmean(tmp)  \n",
    "                    \n",
    "                # sum for each seed\n",
    "                eval_red_sec_mat = eval_red_sec_mat + eval_red_sec\n",
    "                eval_red_sec_id_mat = eval_red_sec_id_mat + eval_red_sec_id\n",
    "                eval_red_sec_vec[cnt_seed] = np.nanmean(eval_red_sec)\n",
    "                eval_red_sec_id_vec[cnt_seed] = np.nanmean(eval_red_sec_id)\n",
    "                cnt_seed = cnt_seed + 1   \n",
    "            \n",
    "            # assign for each sampling_percentage\n",
    "            # general\n",
    "            eval_red_mat = eval_red_mat/cnt_seed\n",
    "            eval_red_id_mat = eval_red_id_mat/cnt_seed\n",
    "            mean_eval_red_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_vec)\n",
    "            mean_eval_red_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_id_vec)\n",
    "            std_eval_red_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_vec)\n",
    "            std_eval_red_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_id_vec)\n",
    "            # secondary\n",
    "            eval_red_sec_mat = eval_red_sec_mat/cnt_seed\n",
    "            eval_red_sec_id_mat = eval_red_sec_id_mat/cnt_seed\n",
    "            mean_eval_red_sec_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_sec_vec)\n",
    "            mean_eval_red_sec_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_sec_id_vec)\n",
    "            std_eval_red_sec_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_sec_vec)\n",
    "            std_eval_red_sec_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_sec_id_vec)\n",
    "            cnt_reduced_percentage = cnt_reduced_percentage + 1   \n",
    "    \n",
    "        # increment cnt for sampling percentage\n",
    "        cnt_sampling_percentage = cnt_sampling_percentage + 1   \n",
    "    \n",
    "    fig = plt.figure(figsize=(5.25, 3), dpi=80)\n",
    "    # plt.subplot(1,2,1)\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_sec_mat[:,0],yerr=std_eval_sec_mat[:,0],label='Specialized - '+ '0%',color=blue_colors[0])\n",
    "    for i in range(0,len(reduced_percentage_vec)):\n",
    "        plt.errorbar(sampling_percentage_vec,mean_eval_red_sec_mat[:,i],yerr=std_eval_red_sec_mat[:,i],label='Specialized - ' + str(reduced_percentage_vec[i])+'%',color=blue_colors[i+1])\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_mat[:,0],yerr=std_eval_mat[:,0],label='Multi-domain - '+ '0%',color=red_colors[0])\n",
    "    for i in range(0,len(reduced_percentage_vec)):\n",
    "        plt.errorbar(sampling_percentage_vec,mean_eval_red_mat[:,i],yerr=std_eval_red_mat[:,i],label='Multi-domain - ' + str(reduced_percentage_vec[i])+'%',color=red_colors[i+1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.xlabel('Sampling percentage [%]')\n",
    "    plt.ylabel('Average balanced accuracy')\n",
    "    # plt.title('Specialized vs General -  OOD')\n",
    "    plt.legend(bbox_to_anchor=(1.5, 0.5),loc='right', ncol=1)\n",
    "    # plt.show()\n",
    "    # plt.savefig('figs/medmnist_specialized_vs_general_ood.eps', bbox_inches='tight', format='eps')\n",
    "    plt.savefig('figs/medmnist_specialized_vs_general_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "    \n",
    "    fig = plt.figure(figsize=(5.25, 3), dpi=80)\n",
    "    # plt.subplot(1,2,2)\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_sec_id_mat[:,0],yerr=std_eval_sec_id_mat[:,0],label='Specialized - ' +'0%',color=blue_colors[0])\n",
    "    for i in range(0,len(reduced_percentage_vec)):\n",
    "        plt.errorbar(sampling_percentage_vec,mean_eval_red_sec_id_mat[:,i],yerr=std_eval_red_sec_id_mat[:,i],label='Specialized - ' + str(reduced_percentage_vec[i])+'%',color=blue_colors[i+1])\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_id_mat[:,0],yerr=std_eval_id_mat[:,0],label='Multi-domain - ' +'0%',color=red_colors[0])\n",
    "    for i in range(0,len(reduced_percentage_vec)):\n",
    "        plt.errorbar(sampling_percentage_vec,mean_eval_red_id_mat[:,i],yerr=std_eval_red_id_mat[:,i],label='Multi-domain - ' + str(reduced_percentage_vec[i])+'%',color=red_colors[i+1])\n",
    "    plt.ylim([0.5,1])\n",
    "    plt.xlabel('Sampling percentage [%]')\n",
    "    plt.ylabel('Average balanced accuracy')\n",
    "    # plt.title('Specialized vs General - ID')\n",
    "    plt.legend(bbox_to_anchor=(1.5, 0.5),loc='right',ncol=1)\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    # plt.show()  \n",
    "    # plt.savefig('figs/medmnist_specialized_vs_general_id.eps', bbox_inches='tight', format='eps')\n",
    "    plt.savefig('figs/medmnist_specialized_vs_general_id.pdf', bbox_inches='tight', format='pdf')\n",
    "    \n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "    plt.plot(sampling_percentage_vec,mean_eval_mat-mean_eval_sec_mat,label='0%',color=purple_colors[0])\n",
    "    for i in range(0,len(reduced_percentage_vec)):\n",
    "        plt.plot(sampling_percentage_vec,mean_eval_red_mat[:,i]-mean_eval_red_sec_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=purple_colors[i+1])\n",
    "    plt.ylim([-0.05,0.7])\n",
    "    plt.xlabel('Sampling percentage [%]')\n",
    "    plt.ylabel('Balanced accuracy difference')\n",
    "    # plt.title('MedMNIST -  OOD')\n",
    "    plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "    # plt.savefig('figs/medmnist_specialized_vs_general_diff_ood.eps', bbox_inches='tight', format='eps')\n",
    "    plt.savefig('figs/medmnist_specialized_vs_general_diff_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "    \n",
    "    fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "    plt.plot(sampling_percentage_vec,mean_eval_id_mat-mean_eval_sec_id_mat,label='0%',color=purple_colors[0])\n",
    "    for i in range(0,len(reduced_percentage_vec)):\n",
    "        plt.plot(sampling_percentage_vec,mean_eval_red_id_mat[:,i]-mean_eval_red_sec_id_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=purple_colors[i+1])\n",
    "    plt.ylim([-0.05,0.05])\n",
    "    plt.xlabel('Sampling percentage [%]')\n",
    "    plt.ylabel('Balanced accuracy difference')\n",
    "    # plt.title('MedMNIST - ID')\n",
    "    plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right',ncol=1)\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    # plt.show() \n",
    "    # plt.savefig('figs/medmnist_specialized_vs_general_diff_id.eps', bbox_inches='tight', format='eps')\n",
    "    plt.savefig('figs/medmnist_specialized_vs_general_diff_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "reduced_percentage_vec = [0,25,50,75,85,95,100]\n",
    "\n",
    "# ood\n",
    "ood_score = np.zeros([len(reduced_percentage_vec),2])\n",
    "ood_score[0,0] = auc(sampling_percentage_vec,mean_eval_mat[:,0])\n",
    "ood_score[0,1] = auc(sampling_percentage_vec,mean_eval_sec_mat[:,0])\n",
    "for i in range(1,len(reduced_percentage_vec)):\n",
    "    ood_score[i,0] = auc(sampling_percentage_vec,mean_eval_red_mat[:,i-1]) \n",
    "    ood_score[i,1] = auc(sampling_percentage_vec,mean_eval_red_sec_mat[:,i-1]) \n",
    "fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "plt.plot(reduced_percentage_vec,ood_score[:,1],color=blue_colors[0],linewidth=2.5,marker='o',label='Specialized')\n",
    "plt.plot(reduced_percentage_vec,ood_score[:,0],color=red_colors[0],linewidth=2.5,marker='o',label='Multi-domain')\n",
    "plt.plot(reduced_percentage_vec,100*np.ones((len(reduced_percentage_vec),1)),'--',color='k')\n",
    "plt.ylim([0,105])\n",
    "plt.xlabel('OOD level [%]')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=2)\n",
    "# plt.show() \n",
    "# plt.savefig('figs/medmnist_auc_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/medmnist_auc_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "# id\n",
    "id_score = np.zeros([len(reduced_percentage_vec),3])\n",
    "id_score[0,0] = auc(sampling_percentage_vec,mean_eval_id_mat[:,0])\n",
    "id_score[0,1] = auc(sampling_percentage_vec,mean_eval_sec_id_mat[:,0])\n",
    "for i in range(1,len(reduced_percentage_vec)):\n",
    "    id_score[i,0] = auc(sampling_percentage_vec,mean_eval_red_id_mat[:,i-1]) \n",
    "    id_score[i,1] = auc(sampling_percentage_vec,mean_eval_red_sec_id_mat[:,i-1])   \n",
    "fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "plt.plot(reduced_percentage_vec,id_score[:,1],color=blue_colors[0],linewidth=2.5,marker='o',label='Specialized')\n",
    "plt.plot(reduced_percentage_vec,id_score[:,0],color=red_colors[0],linewidth=2.5,marker='o',label='Multi-domain')\n",
    "plt.plot(reduced_percentage_vec,100*np.ones((len(reduced_percentage_vec),1)),'--',color='k')\n",
    "plt.ylim([0,105])\n",
    "plt.xlabel('OOD level [%]')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=2)\n",
    "# plt.show()\n",
    "# plt.savefig('figs/medmnist_auc_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/medmnist_auc_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MedMNIST/'\n",
    "results_dir = results_path + '/MedMNIST/results/results_Organ/'\n",
    "results_dir_red = results_path + '/MedMNIST/results/results_Reduced/'\n",
    "results_dir_sec = results_path + '/MedMNIST/results/results_Secondary/'\n",
    "results_dir_red_sec = results_path + '/MedMNIST/results/results_ReducedSecondary/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "\n",
    "# hard-code MedMNIST has 3 views and 11 organs\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "CLASS_NAMES_exp.append(['Bladder','Left femoral head','Right femoral head','Heart','Left kidney',\n",
    "                        'Right kidney','Liver','Left lung','Right lung','Pancreas','Spleen'])\n",
    "CLASS_NAMES_exp.append(['Axial','Coronal','Sagittal'])\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[0])))\n",
    "CLASS_NAMES.append(range(0,len(CLASS_NAMES_exp[1])))\n",
    "        \n",
    "# x and y_axis ticks\n",
    "y_list = CLASS_NAMES_exp[0]  \n",
    "x_list = CLASS_NAMES_exp[1]  \n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "# iterate over seeds\n",
    "seed_vec = [42,73,666,777,1009]# ,1279,1597,1811,1949,2053]\n",
    "model_type_vec = ['ResNet18'] # ,'DenseNet121' \n",
    "sampling_percentage_vec = [100,75,50,35,25,10,5]\n",
    "\n",
    "blue_colors = [mcolors.CSS4_COLORS['darkslateblue'],\n",
    "               mcolors.CSS4_COLORS['midnightblue'],\n",
    "                mcolors.CSS4_COLORS['darkblue'],\n",
    "                mcolors.CSS4_COLORS['mediumblue'],\n",
    "                mcolors.CSS4_COLORS['royalblue'],\n",
    "                mcolors.CSS4_COLORS['cornflowerblue'],\n",
    "                mcolors.CSS4_COLORS['lightblue']]\n",
    "\n",
    "red_colors = [mcolors.CSS4_COLORS['darkred'],\n",
    "                  mcolors.CSS4_COLORS['firebrick'],\n",
    "                  mcolors.CSS4_COLORS['crimson'],\n",
    "                  mcolors.CSS4_COLORS['red'],\n",
    "                  mcolors.CSS4_COLORS['orangered'],\n",
    "                  mcolors.CSS4_COLORS['orange'],\n",
    "                  mcolors.CSS4_COLORS['gold']]\n",
    "\n",
    "purple_colors = [mcolors.CSS4_COLORS['indigo'],\n",
    "                mcolors.CSS4_COLORS['purple'],\n",
    "                mcolors.CSS4_COLORS['darkviolet'],\n",
    "                mcolors.CSS4_COLORS['mediumorchid'],\n",
    "                mcolors.CSS4_COLORS['orchid'],\n",
    "                mcolors.CSS4_COLORS['thistle'],\n",
    "                mcolors.CSS4_COLORS['lavender']]\n",
    "\n",
    "# iterate for each view\n",
    "for model_type in model_type_vec:\n",
    "    print('Model type: ' + model_type)\n",
    "    \n",
    "    for view in range(0,num_classes[1]):\n",
    "        if view == 0:\n",
    "            view_str = 'Axial'\n",
    "        elif view == 1:\n",
    "            view_str = 'Coronal'\n",
    "        else:\n",
    "            view_str = 'Sagittal'\n",
    "        print('View: ' + view_str)\n",
    "        \n",
    "        reduced_percentage_vec = [25,50,75,85,95,100] \n",
    "\n",
    "        # initialize\n",
    "        mean_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "        mean_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "        mean_eval_red_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "        mean_eval_red_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "        std_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "        std_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "        std_eval_red_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "        std_eval_red_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "        mean_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "        mean_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "        mean_eval_red_sec_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "        mean_eval_red_sec_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "        std_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "        std_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "        std_eval_red_sec_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "        std_eval_red_sec_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "        cnt_sampling_percentage = 0\n",
    "    \n",
    "        # iterate over sampling percentage\n",
    "        for sampling_percentage in sampling_percentage_vec:\n",
    "            # print\n",
    "            print('Sampling percentage: ' + str(sampling_percentage))\n",
    "    \n",
    "            # initlaize eval_mat\n",
    "            eval_mat = np.zeros([num_classes[0],1])\n",
    "            eval_id_mat = np.zeros([num_classes[0],1])\n",
    "            eval_vec = np.zeros([len(seed_vec),1])\n",
    "            eval_id_vec = np.zeros([len(seed_vec),1])\n",
    "            eval_sec_mat = np.zeros([num_classes[0],1])\n",
    "            eval_sec_id_mat = np.zeros([num_classes[0],1])\n",
    "            eval_sec_vec = np.zeros([len(seed_vec),1])\n",
    "            eval_sec_id_vec = np.zeros([len(seed_vec),1])\n",
    "            cnt_seed = 0\n",
    "    \n",
    "            # iterate over random seed\n",
    "            for seed in seed_vec:     \n",
    "        \n",
    "                # get the current general experiment\n",
    "                df_ = df[(df['seed'] == seed) & \n",
    "                     (df['model_type'] == model_type) &\n",
    "                     (df['sampling_percentage'] == sampling_percentage)]\n",
    "                curr_exp = int(df_['experiment_id'])\n",
    "                curr_path = results_dir + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f) \n",
    "                \n",
    "                    eval_ = np.array(data['eval_mat_sec'])\n",
    "                    eval_ = eval_[:,view]\n",
    "                    eval_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "                    # calculate id accuracy \n",
    "                    for j in range(num_classes[0]):\n",
    "                            tmp = np.array(data['eval_mat_sec'], copy=True)  \n",
    "                            tmp = tmp[:,view]\n",
    "                            tmp[j] = float('nan')\n",
    "                            eval_id[j] = np.nanmean(tmp) \n",
    "                    \n",
    "                # sum for each seed\n",
    "                eval_mat = eval_mat + eval_\n",
    "                eval_id_mat = eval_id_mat + eval_id\n",
    "                eval_vec[cnt_seed] = np.nanmean(eval_)\n",
    "                eval_id_vec[cnt_seed] = np.nanmean(eval_id)\n",
    "    \n",
    "                # filter df_nbrData_secondary\n",
    "                eval_sec = np.zeros([num_classes[0],1])\n",
    "                eval_sec_id = np.zeros([num_classes[0],1])\n",
    "        \n",
    "                # get the current experiment\n",
    "                df_sec_ = df_secondary[(df_secondary['task2'] == view) & \n",
    "                                   (df_secondary['seed'] == seed) & \n",
    "                                   (df_secondary['model_type'] == model_type) & \n",
    "                                   (df_secondary['sampling_percentage'] == sampling_percentage)]\n",
    "                curr_exp = int(df_sec_['experiment_id'])\n",
    "                curr_path = results_dir_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f) \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    for j in range(num_classes[0]):\n",
    "                        eval_sec[j] = np.array(data['eval_mat'])[j]\n",
    "                        tmp = np.array(data['eval_mat'], copy=True)  \n",
    "                        tmp[j] = float('nan')\n",
    "                        eval_sec_id[j] = np.nanmean(tmp) \n",
    "                    \n",
    "                # sum for each seed\n",
    "                eval_sec_mat = eval_sec_mat + eval_sec\n",
    "                eval_sec_id_mat = eval_sec_id_mat + eval_sec_id\n",
    "                eval_sec_vec[cnt_seed] = np.nanmean(eval_sec)\n",
    "                eval_sec_id_vec[cnt_seed] = np.nanmean(eval_sec_id)\n",
    "                cnt_seed = cnt_seed + 1\n",
    "        \n",
    "            # assign for each sampling_percentage\n",
    "            # general\n",
    "            eval_mat = eval_mat/cnt_seed\n",
    "            eval_id_mat = eval_id_mat/cnt_seed\n",
    "            mean_eval_mat[cnt_sampling_percentage] = np.nanmean(eval_vec)\n",
    "            mean_eval_id_mat[cnt_sampling_percentage] = np.nanmean(eval_id_vec)\n",
    "            std_eval_mat[cnt_sampling_percentage] = np.nanstd(eval_vec)\n",
    "            std_eval_id_mat[cnt_sampling_percentage] = np.nanstd(eval_id_vec)\n",
    "            # secondary\n",
    "            eval_sec_mat = eval_sec_mat/cnt_seed\n",
    "            eval_sec_id_mat = eval_sec_id_mat/cnt_seed\n",
    "            mean_eval_sec_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_vec)\n",
    "            mean_eval_sec_id_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_id_vec)\n",
    "            std_eval_sec_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_vec)\n",
    "            std_eval_sec_id_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_id_vec)\n",
    "    \n",
    "            # iterate over reduced secondary experiments\n",
    "            cnt_reduced_percentage = 0\n",
    "    \n",
    "            for reduced_percentage in reduced_percentage_vec:\n",
    "                # initialize\n",
    "                eval_red_mat = np.zeros([num_classes[0],1])\n",
    "                eval_red_id_mat = np.zeros([num_classes[0],1])\n",
    "                eval_red_vec = np.zeros([len(seed_vec),1])\n",
    "                eval_red_id_vec = np.zeros([len(seed_vec),1])\n",
    "                eval_red_sec_mat = np.zeros([num_classes[0],1])\n",
    "                eval_red_sec_id_mat = np.zeros([num_classes[0],1])\n",
    "                eval_red_sec_vec = np.zeros([len(seed_vec),1])\n",
    "                eval_red_sec_id_vec = np.zeros([len(seed_vec),1])\n",
    "                cnt_seed = 0\n",
    "        \n",
    "                # iterate over random seed\n",
    "                for seed in seed_vec: \n",
    "            \n",
    "                    # initialize\n",
    "                    eval_red = np.zeros([num_classes[0],1])\n",
    "                    eval_red_id = np.zeros([num_classes[0],1])\n",
    "            \n",
    "                    # get the current experiment\n",
    "                    df_red = df_reduced[(df_reduced['seed'] == seed) & \n",
    "                                (df_reduced['model_type'] == model_type) & \n",
    "                                (df_reduced['sampling_percentage'] == sampling_percentage) & \n",
    "                                (df_reduced['reduced_percentage'] == reduced_percentage)]\n",
    "            \n",
    "                    # initialize cnt\n",
    "                    for j in range(num_classes[0]):\n",
    "                        # get the current experiment\n",
    "                        df_red_ = df_red[(df_red['task1'] == j) & (df_red['task2'] == view)]\n",
    "                        curr_exp = int(df_red_['experiment_id'])\n",
    "                        curr_path = results_dir_red + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                        if os.path.exists(curr_path):\n",
    "                            with open(curr_path, 'r') as f:\n",
    "                                data = json.load(f) \n",
    "                \n",
    "                            eval_red[j] = np.array(data['eval_mat_sec'])[j,view]\n",
    "                            tmp = np.array(data['eval_mat_sec'], copy=True)  \n",
    "                            tmp = tmp[:,view]\n",
    "                            tmp[j] = float('nan')\n",
    "                            eval_red_id[j] = np.nanmean(tmp) \n",
    "                    # sum for each seed\n",
    "                    eval_red_mat = eval_red_mat + eval_red\n",
    "                    eval_red_id_mat = eval_red_id_mat + eval_red_id\n",
    "                    eval_red_vec[cnt_seed] = np.nanmean(eval_red)\n",
    "                    eval_red_id_vec[cnt_seed] = np.nanmean(eval_red_id)\n",
    "            \n",
    "                    # initialize\n",
    "                    eval_red_sec = np.zeros([num_classes[0],1])\n",
    "                    eval_red_sec_id = np.zeros([num_classes[0],1])\n",
    "            \n",
    "                    # get the current experiment\n",
    "                    df_red_sec = df_reduced_secondary[(df_reduced_secondary['seed'] == seed) & \n",
    "                                             (df_reduced_secondary['model_type'] == model_type) &      \n",
    "                                             (df_reduced_secondary['sampling_percentage'] == sampling_percentage) & \n",
    "                                             (df_reduced_secondary['reduced_percentage'] == reduced_percentage)]\n",
    "            \n",
    "                    for j in range(num_classes[0]):\n",
    "                        # get the current experiment\n",
    "                        df_red_sec_ = df_red_sec[(df_red_sec['task1'] == j) & (df_red_sec['task2'] == view)]\n",
    "                        curr_exp = int(df_red_sec_['experiment_id'])\n",
    "                        curr_path = results_dir_red_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                        if os.path.exists(curr_path):\n",
    "                            with open(curr_path, 'r') as f:\n",
    "                                data = json.load(f) \n",
    "                \n",
    "                            eval_red_sec[j] = np.array(data['eval_mat'])[j]\n",
    "                            tmp = np.array(data['eval_mat'], copy=True)  \n",
    "                            tmp[j] = float('nan')\n",
    "                            eval_red_sec_id[j] = np.nanmean(tmp) \n",
    "                    \n",
    "                    # sum for each seed\n",
    "                    eval_red_sec_mat = eval_red_sec_mat + eval_red_sec\n",
    "                    eval_red_sec_id_mat = eval_red_sec_id_mat + eval_red_sec_id\n",
    "                    eval_red_sec_vec[cnt_seed] = np.nanmean(eval_red_sec)\n",
    "                    eval_red_sec_id_vec[cnt_seed] = np.nanmean(eval_red_sec_id)\n",
    "                    cnt_seed = cnt_seed + 1   \n",
    "            \n",
    "                # assign for each sampling_percentage\n",
    "                # general\n",
    "                eval_red_mat = eval_red_mat/cnt_seed\n",
    "                eval_red_id_mat = eval_red_id_mat/cnt_seed\n",
    "                mean_eval_red_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_vec)\n",
    "                mean_eval_red_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_id_vec)\n",
    "                std_eval_red_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_vec)\n",
    "                std_eval_red_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_id_vec)\n",
    "                # secondary\n",
    "                eval_red_sec_mat = eval_red_sec_mat/cnt_seed\n",
    "                eval_red_sec_id_mat = eval_red_sec_id_mat/cnt_seed\n",
    "                mean_eval_red_sec_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_sec_vec)\n",
    "                mean_eval_red_sec_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_sec_id_vec)\n",
    "                std_eval_red_sec_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_sec_vec)\n",
    "                std_eval_red_sec_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_sec_id_vec)\n",
    "                cnt_reduced_percentage = cnt_reduced_percentage + 1   \n",
    "    \n",
    "            # increment cnt for sampling percentage\n",
    "            cnt_sampling_percentage = cnt_sampling_percentage + 1   \n",
    "        \n",
    "        # plot\n",
    "        fig = plt.figure(figsize=(5.25, 3), dpi=80)\n",
    "        # plt.subplot(1,2,1)\n",
    "        plt.errorbar(sampling_percentage_vec,mean_eval_sec_mat[:,0],yerr=std_eval_sec_mat[:,0],label='Specialized - '+ '0%',color=blue_colors[0])\n",
    "        for i in range(0,len(reduced_percentage_vec)):\n",
    "            plt.errorbar(sampling_percentage_vec,mean_eval_red_sec_mat[:,i],yerr=std_eval_red_sec_mat[:,i],label='Specialized - ' + str(reduced_percentage_vec[i])+'%',color=blue_colors[i+1])\n",
    "        plt.errorbar(sampling_percentage_vec,mean_eval_mat[:,0],yerr=std_eval_mat[:,0],label='Multi-domain - '+ '0%',color=red_colors[0])\n",
    "        for i in range(0,len(reduced_percentage_vec)):\n",
    "            plt.errorbar(sampling_percentage_vec,mean_eval_red_mat[:,i],yerr=std_eval_red_mat[:,i],label='Multi-domain - ' + str(reduced_percentage_vec[i])+'%',color=red_colors[i+1])\n",
    "        plt.ylim([0,1])\n",
    "        plt.xlabel('Sampling percentage [%]')\n",
    "        plt.ylabel('Average balanced accuracy')\n",
    "        # plt.title(view_str + ' - Specialized vs General -  OOD')\n",
    "        plt.legend(bbox_to_anchor=(1.5, 0.5),loc='right', ncol=1)\n",
    "        # plt.savefig('figs/medmnist_'+view_str+'_ood.eps', bbox_inches='tight', format='eps')\n",
    "        plt.savefig('figs/medmnist_'+view_str+'_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "        \n",
    "        fig = plt.figure(figsize=(5.25, 3), dpi=80)\n",
    "        # plt.subplot(1,2,2)\n",
    "        plt.errorbar(sampling_percentage_vec,mean_eval_sec_id_mat[:,0],yerr=std_eval_sec_id_mat[:,0],label='Specialized - ' +'0%',color=blue_colors[0])\n",
    "        for i in range(0,len(reduced_percentage_vec)):\n",
    "            plt.errorbar(sampling_percentage_vec,mean_eval_red_sec_id_mat[:,i],yerr=std_eval_red_sec_id_mat[:,i],label='Specialized - ' + str(reduced_percentage_vec[i])+'%',color=blue_colors[i+1])\n",
    "        plt.errorbar(sampling_percentage_vec,mean_eval_id_mat[:,0],yerr=std_eval_id_mat[:,0],label='Multi-domain - ' +'0%',color=red_colors[0])\n",
    "        for i in range(0,len(reduced_percentage_vec)):\n",
    "            plt.errorbar(sampling_percentage_vec,mean_eval_red_id_mat[:,i],yerr=std_eval_red_id_mat[:,i],label='Multi-domain - ' + str(reduced_percentage_vec[i])+'%',color=red_colors[i+1])\n",
    "        plt.ylim([0.5,1])\n",
    "        plt.xlabel('Sampling percentage [%]')\n",
    "        plt.ylabel('Average balanced accuracy')\n",
    "        # plt.title(view_str + ' - Specialized vs General  - ID')\n",
    "        plt.legend(bbox_to_anchor=(1.5, 0.5),loc='right',ncol=1)\n",
    "        plt.subplots_adjust(wspace=0.5)\n",
    "        # plt.show()  \n",
    "        # plt.savefig('figs/medmnist_'+view_str+'_id.eps', bbox_inches='tight', format='eps')   \n",
    "        plt.savefig('figs/medmnist_'+view_str+'_id.pdf', bbox_inches='tight', format='pdf')       \n",
    "    \n",
    "        # plot\n",
    "        fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "        # plt.subplot(1,2,1)\n",
    "        plt.plot(sampling_percentage_vec,mean_eval_mat-mean_eval_sec_mat,label='0%',color=purple_colors[0])\n",
    "        for i in range(0,len(reduced_percentage_vec)):\n",
    "            plt.plot(sampling_percentage_vec,mean_eval_red_mat[:,i]-mean_eval_red_sec_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=purple_colors[i+1])\n",
    "        plt.ylim([-0.05,0.7])\n",
    "        plt.xlabel('Sampling percentage [%]')\n",
    "        plt.ylabel('Balanced accuracy difference')\n",
    "        # plt.title(view_str + ' - Difference -  OOD')\n",
    "        plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "        # plt.savefig('figs/medmnist_'+view_str+'_diff_ood.eps', bbox_inches='tight', format='eps')\n",
    "        plt.savefig('figs/medmnist_'+view_str+'_diff_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "        \n",
    "        fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "        # plt.subplot(1,2,2)\n",
    "        plt.plot(sampling_percentage_vec,mean_eval_id_mat-mean_eval_sec_id_mat,label='0%',color=purple_colors[0])\n",
    "        for i in range(0,len(reduced_percentage_vec)):\n",
    "            plt.plot(sampling_percentage_vec,mean_eval_red_id_mat[:,i]-mean_eval_red_sec_id_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=purple_colors[i+1])\n",
    "        plt.ylim([-0.05,0.05])\n",
    "        plt.xlabel('Sampling percentage [%]')\n",
    "        plt.ylabel('Balanced accuracy difference')\n",
    "        # plt.title(view_str + ' - Difference - ID')\n",
    "        plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right',ncol=1)\n",
    "        plt.subplots_adjust(wspace=0.5)\n",
    "        # plt.show()  \n",
    "        # plt.savefig('figs/medmnist_'+view_str+'_diff_id.eps', bbox_inches='tight', format='eps')\n",
    "        plt.savefig('figs/medmnist_'+view_str+'_diff_id.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "        # auc plot\n",
    "        reduced_percentage_vec = [0,25,50,75,85,95,100]\n",
    "\n",
    "        # ood\n",
    "        ood_score = np.zeros([len(reduced_percentage_vec),2])\n",
    "        ood_score[0,0] = auc(sampling_percentage_vec,mean_eval_mat[:,0])\n",
    "        ood_score[0,1] = auc(sampling_percentage_vec,mean_eval_sec_mat[:,0])\n",
    "        for i in range(1,len(reduced_percentage_vec)):\n",
    "            ood_score[i,0] = auc(sampling_percentage_vec,mean_eval_red_mat[:,i-1]) \n",
    "            ood_score[i,1] = auc(sampling_percentage_vec,mean_eval_red_sec_mat[:,i-1]) \n",
    "        fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "        plt.plot(reduced_percentage_vec,ood_score[:,1],color=blue_colors[0],linewidth=2.5,marker='o',label='Specialized')\n",
    "        plt.plot(reduced_percentage_vec,ood_score[:,0],color=red_colors[0],linewidth=2.5,marker='o',label='Multi-domain')\n",
    "        plt.plot(reduced_percentage_vec,100*np.ones((len(reduced_percentage_vec),1)),'--',color='k')\n",
    "        plt.ylim([0,105])\n",
    "        plt.xlabel('OOD level [%]')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=2)\n",
    "        # plt.show() \n",
    "        # plt.savefig('figs/medmnist_'+view_str+'_auc_ood.eps', bbox_inches='tight', format='eps')\n",
    "        plt.savefig('figs/medmnist_'+view_str+'_auc_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "        # id\n",
    "        id_score = np.zeros([len(reduced_percentage_vec),3])\n",
    "        id_score[0,0] = auc(sampling_percentage_vec,mean_eval_id_mat[:,0])\n",
    "        id_score[0,1] = auc(sampling_percentage_vec,mean_eval_sec_id_mat[:,0])\n",
    "        for i in range(1,len(reduced_percentage_vec)):\n",
    "            id_score[i,0] = auc(sampling_percentage_vec,mean_eval_red_id_mat[:,i-1]) \n",
    "            id_score[i,1] = auc(sampling_percentage_vec,mean_eval_red_sec_id_mat[:,i-1])   \n",
    "        fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "        plt.plot(reduced_percentage_vec,id_score[:,1],color=blue_colors[0],linewidth=2.5,marker='o',label='Specialized')\n",
    "        plt.plot(reduced_percentage_vec,id_score[:,0],color=red_colors[0],linewidth=2.5,marker='o',label='Multi-domain')\n",
    "        plt.plot(reduced_percentage_vec,100*np.ones((len(reduced_percentage_vec),1)),'--',color='k')\n",
    "        plt.ylim([0,105])\n",
    "        plt.xlabel('OOD level [%]')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=2)\n",
    "        # plt.show()\n",
    "        # plt.savefig('figs/medmnist_'+view_str+'_auc_id.eps', bbox_inches='tight', format='eps')\n",
    "        plt.savefig('figs/medmnist_'+view_str+'_auc_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
