{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afdc27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders\n",
    "data_path = 'xxx' # todo\n",
    "results_path = 'xxx' # todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b431ac1a",
   "metadata": {},
   "source": [
    "## Prepare MostCommonCUIs.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# paths\n",
    "data_dir = data_path + '/Data/ROCO_ext/'\n",
    "concept_list = 'concept_names.csv'\n",
    "task_ext = 'concept_detection_'\n",
    "imgs_ext = '_images/'\n",
    "\n",
    "\n",
    "# train concepts\n",
    "df = pd.read_csv(data_dir + task_ext + 'train.csv'    ,sep='\\t')  \n",
    "print(df)\n",
    "\n",
    "# all concepts\n",
    "df_concepts_all = pd.read_csv(data_dir + concept_list ,sep='\\t')  \n",
    "print(df_concepts_all)\n",
    "\n",
    "# initialize full concept list\n",
    "all_concepts = []\n",
    "\n",
    "# iterate lines\n",
    "for index, row in df.iterrows():\n",
    "        \n",
    "    # split the line\n",
    "    x = row['cuis'].split(';')\n",
    "    all_concepts.extend(x)\n",
    "\n",
    "# initialize occurance \n",
    "occ = []\n",
    "for curr_concept in df_concepts_all['concept']:\n",
    "    occ.append(all_concepts.count(curr_concept))\n",
    "    \n",
    "# save most common CUIs\n",
    "df_mostcommon = pd.DataFrame()\n",
    "df_mostcommon['CUI'] = df_concepts_all['concept']\n",
    "df_mostcommon['Number of occurance'] = occ\n",
    "df_mostcommon['Explanation'] = df_concepts_all['concept_name']\n",
    "\n",
    "# sort according to the number of occurance\n",
    "df_mostcommon = df_mostcommon.sort_values('Number of occurance', ascending=False)\n",
    "df_mostcommon.to_csv('./MostCommonCUIs.csv', index=False)  \n",
    "\n",
    "## we added a manual column of \"Semantic type\" \n",
    "## using UMLS page: https://uts.nlm.nih.gov/uts/umls/home\n",
    "## and placed MostCommonCUIs.csv (with top 100 concepts) to the data_dir "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82c621",
   "metadata": {},
   "source": [
    "## Plot figure 1 for ImageCLEFmedical (organ vs modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "data_dir = data_path + '/Data/ROCO_ext/'\n",
    "sample_class = 3\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "\n",
    "# read semantic group\n",
    "df_concepts_all_semantic = pd.read_csv(data_dir + 'MostCommonCUIs.csv',sep=',')\n",
    "df_concepts_all_semantic = df_concepts_all_semantic[0:100]\n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "task = ['Body Part, Organ, or Organ Component','Diagnostic Procedure'] # ['Diagnostic Procedure'] # \n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "for i in range(len(task)):\n",
    "    idx = df_concepts_all_semantic['Semantic attribute'] == task[i]\n",
    "    \n",
    "    CLASS_NAMES.append(df_concepts_all_semantic[idx]['CUI'].to_numpy())\n",
    "    CLASS_NAMES_exp.append(df_concepts_all_semantic[idx]['Explanation'].to_numpy())\n",
    "    \n",
    "# get every sample_class class\n",
    "CLASS_NAMES[0] = CLASS_NAMES[0][1::sample_class]\n",
    "CLASS_NAMES_exp[0] = CLASS_NAMES_exp[0][1::sample_class]\n",
    "        \n",
    "# x and y_axis ticks\n",
    "y_list = CLASS_NAMES_exp[0]  \n",
    "x_list = CLASS_NAMES_exp[1]  \n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "task_ext = 'concept_detection_'\n",
    "imgs_ext = '_images/'\n",
    "annot_dir = data_dir + task_ext + 'train.csv'    \n",
    "df = pd.read_csv(annot_dir,sep='\\t')  \n",
    "img_idx = []\n",
    "label_vec = np.zeros((0,len(task)), dtype = float)\n",
    "\n",
    "# iterate lines\n",
    "for index, row in df.iterrows():\n",
    "        \n",
    "    # split the line\n",
    "    x = row['cuis'].split(';')\n",
    "    curr_label = []\n",
    "        \n",
    "    # iterate over task for getting the label\n",
    "    for task_id in range(len(task)):\n",
    "        \n",
    "        # compare the concepts of the current row with the classes to find the label\n",
    "        curr_concept_list = np.intersect1d(x,CLASS_NAMES[task_id])\n",
    "        \n",
    "        # if not only one concept per image, skip\n",
    "        if len(curr_concept_list) == 0:\n",
    "            continue      \n",
    "        elif len(curr_concept_list) > 1:\n",
    "            continue           \n",
    "     \n",
    "        idx = np.where(CLASS_NAMES[task_id]==curr_concept_list)[0][0]\n",
    "        curr_label.append(idx)\n",
    "\n",
    "    if len(curr_label) != len(task):\n",
    "        continue    \n",
    "        \n",
    "    img_idx.append(row['ID'])\n",
    "    label_vec = np.vstack([label_vec, curr_label])    \n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(num_classes[1], num_classes[0]), dpi=80)\n",
    "\n",
    "np.random.seed(77)\n",
    "data_dir = data_path + '/Data/ROCO_ext/train_images/'\n",
    "img_size = 224\n",
    "for organ in range(0,num_classes[0]):\n",
    "    for modality in range(0,num_classes[1]):\n",
    "        curr_label = [organ,modality]\n",
    "        curr_list = np.where(np.sum(label_vec == curr_label,axis=1) == 2)[0]\n",
    "        if len(curr_list) > 0:\n",
    "            # get a random number\n",
    "            idx = np.random.randint(1,len(curr_list))\n",
    "            curr_img = img_idx[curr_list[idx]]\n",
    "        else:\n",
    "            continue\n",
    "        curr_file = data_dir + curr_img + '.jpg'\n",
    "        with Image.open(curr_file).convert('RGB') as img:\n",
    "            # center crop\n",
    "            height, width = img.size\n",
    "            r_min = max(0,np.floor((height-width)/2))\n",
    "            r_max = r_min + min(height,width)\n",
    "            c_min = max(0,np.floor((width-height)/2))\n",
    "            c_max = c_min + min(height,width)\n",
    "            img = img.crop((r_min,c_min,r_max,c_max))\n",
    "            img = transforms.Resize(size=img_size)(img)\n",
    "            \n",
    "            # plot\n",
    "            cnt = organ*num_classes[1] + modality + 1\n",
    "            plt.subplot(num_classes[0],num_classes[1],cnt)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off') \n",
    "plt.subplots_adjust(wspace=0, hspace=0)     \n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4e5f5",
   "metadata": {},
   "source": [
    "## Plot train+validation and test split number of datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9d733",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# paths\n",
    "data_dir = data_path + '/Data/ROCO_ext/' \n",
    "task_ext = 'concept_detection_'\n",
    "imgs_ext = '_images/'\n",
    "sample_class = 3\n",
    "\n",
    "# read semantic concepts\n",
    "df_concepts_all_semantic = pd.read_csv(data_dir + 'MostCommonCUIs.csv',sep=',')\n",
    "\n",
    "# classes task[0] primary task task[1] to filter\n",
    "task = ['Body Part, Organ, or Organ Component','Diagnostic Procedure'] # ['Diagnostic Procedure'] # \n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "for i in range(len(task)):\n",
    "    idx = df_concepts_all_semantic['Semantic attribute'] == task[i]\n",
    "    \n",
    "    CLASS_NAMES.append(df_concepts_all_semantic[idx]['CUI'].to_numpy())\n",
    "    CLASS_NAMES_exp.append(df_concepts_all_semantic[idx]['Explanation'].to_numpy())\n",
    "    \n",
    "# get every sample_class class\n",
    "CLASS_NAMES[0] = CLASS_NAMES[0][1::sample_class]\n",
    "CLASS_NAMES_exp[0] = CLASS_NAMES_exp[0][1::sample_class]\n",
    "\n",
    "# x and y_axis ticks\n",
    "# y_list = CLASS_NAMES_exp[0]  \n",
    "# x_list = CLASS_NAMES_exp[1]  \n",
    "y_list =['Pelvis', 'Vertebral column', 'Lung','Urinary bladder', 'Right ventricular structure', 'Stomach', 'Pulmonary artery structure', 'Art. desc. b. left cor. artery', 'Left kidney']\n",
    "x_list = ['CT', 'X-ray', 'MRI', 'US', 'AG', 'PET']\n",
    "\n",
    "# train concepts\n",
    "df = pd.read_csv(data_dir + task_ext + 'train.csv'    ,sep='\\t')  \n",
    "\n",
    "# initialize\n",
    "img_idx = []\n",
    "label_vec = np.zeros((0,len(task)), dtype = float)\n",
    "\n",
    "# iterate lines\n",
    "for index, row in df.iterrows():\n",
    "        \n",
    "    # split the line\n",
    "    x = row['cuis'].split(';')\n",
    "    curr_label = []\n",
    "    \n",
    "    # iterate over task for getting the label\n",
    "    for task_id in range(len(task)):\n",
    "        \n",
    "        # compare the concepts of the current row with the classes to find the label\n",
    "        curr_concept_list = np.intersect1d(x,CLASS_NAMES[task_id])\n",
    "        \n",
    "        # if not only one concept per image, skip (eg. multiple organs in am image is skipped)\n",
    "        if len(curr_concept_list) == 0:\n",
    "            continue      \n",
    "        elif len(curr_concept_list) > 1:\n",
    "            continue           \n",
    "            \n",
    "        idx = np.where(CLASS_NAMES[task_id]==curr_concept_list)[0][0]\n",
    "        curr_label.append(idx)\n",
    "\n",
    "    if len(curr_label) != len(task):\n",
    "        continue    \n",
    "        \n",
    "    # save names and labels    \n",
    "    img_idx.append(row['ID'])\n",
    "    label_vec = np.vstack([label_vec, curr_label])     \n",
    "    \n",
    "# plot \n",
    "number_imgs_mat_train_val = np.zeros((len(CLASS_NAMES[0]),len(CLASS_NAMES[1])))\n",
    "\n",
    "# iterate over classes\n",
    "for i in range(len(CLASS_NAMES[0])):\n",
    "    for j in range(len(CLASS_NAMES[1])):\n",
    "        number_imgs_mat_train_val[i,j] = sum((label_vec[:,0] == i) & (label_vec[:,1] == j)) # sum(label_vec[label_vec[:,1]==j,0]==i)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(5, 5), dpi=80)\n",
    "plt.imshow(number_imgs_mat_train_val) \n",
    "plt.xticks(np.arange(len(x_list)), labels=x_list, rotation=45)\n",
    "plt.yticks(np.arange(len(y_list)), labels=y_list, rotation=0)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "# plt.savefig('figs/imageclef_data_train_val.eps', bbox_inches='tight', format='eps')\n",
    "# plt.savefig('figs/imageclef_data_train_val.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "# train concepts\n",
    "df = pd.read_csv(data_dir + task_ext + 'valid.csv'    ,sep='\\t')  \n",
    "\n",
    "# initialize\n",
    "img_idx = []\n",
    "label_vec = np.zeros((0,len(task)), dtype = float)\n",
    "\n",
    "# iterate lines\n",
    "for index, row in df.iterrows():\n",
    "        \n",
    "    # split the line\n",
    "    x = row['cuis'].split(';')\n",
    "    curr_label = []\n",
    "    \n",
    "    # iterate over task for getting the label\n",
    "    for task_id in range(len(task)):\n",
    "        \n",
    "        # compare the concepts of the current row with the classes to find the label\n",
    "        curr_concept_list = np.intersect1d(x,CLASS_NAMES[task_id])\n",
    "        \n",
    "        # if not only one concept per image, skip (eg. multiple organs in am image is skipped)\n",
    "        if len(curr_concept_list) == 0:\n",
    "            continue      \n",
    "        elif len(curr_concept_list) > 1:\n",
    "            continue           \n",
    "            \n",
    "        idx = np.where(CLASS_NAMES[task_id]==curr_concept_list)[0][0]\n",
    "        curr_label.append(idx)\n",
    "\n",
    "    if len(curr_label) != len(task):\n",
    "        continue    \n",
    "        \n",
    "    # save names and labels    \n",
    "    img_idx.append(row['ID'])\n",
    "    label_vec = np.vstack([label_vec, curr_label])     \n",
    "    \n",
    "# plot \n",
    "number_imgs_mat_test = np.zeros((len(CLASS_NAMES[0]),len(CLASS_NAMES[1])))\n",
    "\n",
    "# iterate over classes\n",
    "for i in range(len(CLASS_NAMES[0])):\n",
    "    for j in range(len(CLASS_NAMES[1])):\n",
    "        number_imgs_mat_test[i,j] = sum((label_vec[:,0] == i) & (label_vec[:,1] == j))\n",
    "\n",
    "# plot\n",
    "# fig = plt.figure(figsize=(15, 5), dpi=80)\n",
    "fig = plt.figure(figsize=(5, 5), dpi=80)\n",
    "\n",
    "# validation\n",
    "plt.imshow(number_imgs_mat_test) \n",
    "plt.xticks(np.arange(len(x_list)), labels=x_list, rotation=45)\n",
    "plt.yticks(np.arange(len(y_list)), labels=y_list, rotation=0)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "# plt.savefig('figs/imageclef_data_test.eps', bbox_inches='tight', format='eps')\n",
    "# plt.savefig('figs/imageclef_data_test.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "print(number_imgs_mat_train_val)\n",
    "print(number_imgs_mat_test)\n",
    "print(sum(sum(number_imgs_mat_train_val)))\n",
    "print(sum(sum(number_imgs_mat_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2023e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(number_imgs_mat_train_val,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade54f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
