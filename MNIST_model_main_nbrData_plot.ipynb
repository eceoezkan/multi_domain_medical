{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders\n",
    "data_path = 'xxx' # todo\n",
    "results_path = 'xxx' # todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7559a9",
   "metadata": {},
   "source": [
    "# Try different distributions - NbrData experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7c1a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_val = 1000*np.ones((10,5))\n",
    "cnt = 0\n",
    "\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(['a','b','c','d','e'])\n",
    "\n",
    "# initialize\n",
    "df_datapoints = pd.DataFrame(columns = ['mean_organ', \n",
    "                                        'std_organ', \n",
    "                                        'mean_modality',\n",
    "                                        'std_modality',\n",
    "                                        'mean_datapoints',\n",
    "                                        'median_datapoints',\n",
    "                                        'total_datapoints'])\n",
    "    \n",
    "for mean_organ in [0]:\n",
    "    for std_organ in [3,5,9,17]:\n",
    "        \n",
    "        # distribution for organ\n",
    "        set_seeds(seed=42)\n",
    "        s_organ = np.random.normal(mean_organ, std_organ, 500000)\n",
    "        \n",
    "        for mean_modality in [0,2]:\n",
    "            for std_modality in [1,3,5]:\n",
    "                \n",
    "                print(mean_organ,std_organ,mean_modality,std_modality)\n",
    "                \n",
    "                # distribution for modality\n",
    "                set_seeds(seed=42)\n",
    "                s_modality = np.random.normal(mean_modality, std_modality, 100000)\n",
    "                \n",
    "                # initialize\n",
    "                hist_organ_mat = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "                hist_modality_mat = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "                \n",
    "                # histogram\n",
    "                hist_organ = np.histogram(s_organ, bins=range(0,11), density=True)\n",
    "                hist_modality = np.histogram(s_modality, bins=range(0,6), density=True)\n",
    "                \n",
    "                # normalize\n",
    "                hist_organ = hist_organ[0]/hist_organ[0].max()\n",
    "                hist_modality = hist_modality[0]/hist_modality[0].max()\n",
    "                \n",
    "                # iterate \n",
    "                for i in range(len(CLASS_NAMES[1])):\n",
    "                    hist_organ_mat[:,i] = hist_organ\n",
    "                for i in range(len(CLASS_NAMES[0])):\n",
    "                    hist_modality_mat[i,:] = hist_modality\n",
    "\n",
    "                # number of datapoints\n",
    "                datapoints = train_val*hist_organ_mat*hist_modality_mat\n",
    "                mean_datapoints = datapoints.mean()\n",
    "                median_datapoints = np.median(datapoints)\n",
    "                total_datapoints = datapoints.sum()\n",
    "                # print(np.round(0.75*datapoints.sum(axis=1)))\n",
    "                print(median_datapoints,mean_datapoints,total_datapoints)\n",
    "                df_datapoints = pd.concat([df_datapoints, pd.DataFrame.from_records([{'mean_organ':mean_organ, \n",
    "                                                     'std_organ': std_organ,\n",
    "                                                     'mean_modality':mean_modality,\n",
    "                                                     'std_modality':std_modality,\n",
    "                                                     'mean_datapoints':mean_datapoints,\n",
    "                                                     'median_datapoints':median_datapoints,\n",
    "                                                     'total_datapoints':total_datapoints}])], ignore_index=True)\n",
    "            \n",
    "                # plot\n",
    "                fig = plt.figure(figsize=(7, 3), dpi=80)\n",
    "                \n",
    "                # plot\n",
    "                ax = fig.add_subplot(1,3,1)\n",
    "                im = ax.imshow(hist_organ_mat, vmin=0, vmax=1)\n",
    "                ax.set_title('Mean: '+str(mean_organ)+ ' Std: '+str(std_organ))\n",
    "                ax.set_yticks(np.arange(10), labels=range(0,10))  \n",
    "                ax.set_xticks(np.arange(5), labels=['a','b','c','d','e'])  \n",
    "                fig.colorbar(im, orientation='vertical')\n",
    "                ax = fig.add_subplot(1,3,2)\n",
    "                im = ax.imshow(hist_modality_mat, vmin=0, vmax=1)\n",
    "                ax.set_title('Mean: '+str(mean_modality)+ ' Std: '+str(std_modality))\n",
    "                ax.set_yticks(np.arange(10), labels=range(0,10))  \n",
    "                ax.set_xticks(np.arange(5), labels=['a','b','c','d','e'])  \n",
    "                fig.colorbar(im, orientation='vertical')\n",
    "                ax = fig.add_subplot(1,3,3)\n",
    "                im = ax.imshow(datapoints, vmin=0, vmax=1000)\n",
    "                ax.set_title('Number of samples')\n",
    "                ax.set_yticks(np.arange(10), labels=range(0,10))  \n",
    "                ax.set_xticks(np.arange(5), labels=['a','b','c','d','e'])  \n",
    "                fig.colorbar(im, orientation='vertical')\n",
    "                # plt.show()\n",
    "                # plt.savefig('figs/polymnist_datapoints_'+str(mean_organ)+'_'+str(std_organ)+'_'+str(mean_modality)+'_'+str(std_modality)+'.eps', bbox_inches='tight', format='eps')\n",
    "                plt.savefig('figs/polymnist_datapoints_'+str(mean_organ)+'_'+str(std_organ)+'_'+str(mean_modality)+'_'+str(std_modality)+'.pdf', bbox_inches='tight', format='pdf')\n",
    "                \n",
    "                cnt = cnt + 1\n",
    "print(cnt)     \n",
    "df_datapoints = df_datapoints.sort_values('median_datapoints',ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_val = 1000*np.ones((10,5))\n",
    "cnt = 0\n",
    "\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "# initialize\n",
    "df_datapoints = pd.DataFrame(columns = ['mean_organ', \n",
    "                                        'std_organ', \n",
    "                                        'mean_modality',\n",
    "                                        'std_modality',\n",
    "                                        'mean_datapoints',\n",
    "                                        'median_datapoints',\n",
    "                                        'total_datapoints'])\n",
    "    \n",
    "for mean_organ in [0]:\n",
    "    for std_organ in [3,5,9,17]:\n",
    "        \n",
    "        # distribution for organ\n",
    "        set_seeds(seed=42)\n",
    "        s_organ = np.random.normal(mean_organ, std_organ, 500000)\n",
    "        \n",
    "        for mean_modality in [0,2]:\n",
    "            for std_modality in [1,3,5]:\n",
    "                \n",
    "                # distribution for modality\n",
    "                set_seeds(seed=42)\n",
    "                s_modality = np.random.normal(mean_modality, std_modality, 100000)\n",
    "                \n",
    "                # initialize\n",
    "                hist_organ_mat = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "                hist_modality_mat = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "                \n",
    "                # histogram\n",
    "                hist_organ = np.histogram(s_organ, bins=range(0,11), density=True)\n",
    "                hist_modality = np.histogram(s_modality, bins=range(0,6), density=True)\n",
    "                \n",
    "                # normalize\n",
    "                hist_organ = hist_organ[0]/hist_organ[0].max()\n",
    "                hist_modality = hist_modality[0]/hist_modality[0].max()\n",
    "                \n",
    "                # iterate \n",
    "                for i in range(len(CLASS_NAMES[1])):\n",
    "                    hist_organ_mat[:,i] = hist_organ\n",
    "                for i in range(len(CLASS_NAMES[0])):\n",
    "                    hist_modality_mat[i,:] = hist_modality\n",
    "\n",
    "                # number of datapoints\n",
    "                datapoints = train_val*hist_organ_mat*hist_modality_mat\n",
    "                mean_datapoints = datapoints.mean()\n",
    "                median_datapoints = np.median(datapoints)\n",
    "                total_datapoints = datapoints.sum()\n",
    "                # print(np.round(0.75*datapoints.sum(axis=1)))\n",
    "                # print(median_datapoints,mean_datapoints,total_datapoints)\n",
    "                df_datapoints = pd.concat([df_datapoints, pd.DataFrame.from_records([{'mean_organ':mean_organ, \n",
    "                                                     'std_organ': std_organ,\n",
    "                                                     'mean_modality':mean_modality,\n",
    "                                                     'std_modality':std_modality,\n",
    "                                                     'mean_datapoints':mean_datapoints,\n",
    "                                                     'median_datapoints':median_datapoints,\n",
    "                                                     'total_datapoints':total_datapoints}])], ignore_index=True)\n",
    "\n",
    "df_datapoints = df_datapoints.sort_values('median_datapoints',ignore_index=True)\n",
    "print(df_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over rows\n",
    "fig = plt.figure(figsize=(24, 8), dpi=80)\n",
    "cnt = 1\n",
    "for index, row in df_datapoints.iterrows():\n",
    "    mean_organ = row['mean_organ']\n",
    "    std_organ = row['std_organ']\n",
    "    mean_modality = row['mean_modality']\n",
    "    std_modality = row['std_modality']\n",
    "    median_datapoints = row['median_datapoints']\n",
    "    set_seeds(seed=42)\n",
    "    s_organ = np.random.normal(mean_organ, std_organ, 500000)\n",
    "    s_modality = np.random.normal(mean_modality, std_modality, 100000)\n",
    "    \n",
    "    # initialize\n",
    "    hist_organ_mat = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "    hist_modality_mat = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "                \n",
    "    # histogram\n",
    "    hist_organ = np.histogram(s_organ, bins=range(0,11), density=True)\n",
    "    hist_modality = np.histogram(s_modality, bins=range(0,6), density=True)\n",
    "                \n",
    "    # normalize\n",
    "    hist_organ = hist_organ[0]/hist_organ[0].max()\n",
    "    hist_modality = hist_modality[0]/hist_modality[0].max()\n",
    "                \n",
    "    # iterate \n",
    "    for i in range(len(CLASS_NAMES[1])):\n",
    "        hist_organ_mat[:,i] = hist_organ\n",
    "    for i in range(len(CLASS_NAMES[0])):\n",
    "        hist_modality_mat[i,:] = hist_modality\n",
    "\n",
    "    # number of datapoints\n",
    "    datapoints = train_val*hist_organ_mat*hist_modality_mat\n",
    "                \n",
    "    # plot\n",
    "    ax = fig.add_subplot(2,12,cnt)\n",
    "    im = ax.imshow(datapoints, vmin=0, vmax=1000)\n",
    "    ax.set_title('Datapoint: '+str(int(np.round(median_datapoints))))\n",
    "    if np.mod(cnt,12)!=1:\n",
    "        ax.set_yticks([])\n",
    "    else:\n",
    "        ax.set_yticks(np.arange(10), labels=range(0,10))  \n",
    "    ax.set_xticks(np.arange(5), labels=['a','b','c','d','e'])  \n",
    "    # if np.mod(cnt,12)==0:\n",
    "    #     fig.colorbar(im, orientation='vertical')  \n",
    "    cnt = cnt + 1\n",
    "plt.subplots_adjust(wspace=0.1)    \n",
    "# plt.show()  \n",
    "# plt.savefig('figs/polymnist_datapoints.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_datapoints.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc258e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import numpy as np\n",
    "\n",
    "# distribution for modality\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "mean_organ = 0\n",
    "std_organ = 5\n",
    "mean_modality = 2\n",
    "std_modality = 3\n",
    "set_seeds(seed=42)\n",
    "s_organ = np.random.normal(mean_organ, std_organ, 500000)\n",
    "set_seeds(seed=42)\n",
    "s_modality = np.random.normal(mean_modality, std_modality, 100000)\n",
    "                \n",
    "# initialize\n",
    "hist_organ_mat = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "hist_modality_mat = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "                \n",
    "# histogram\n",
    "hist_organ = np.histogram(s_organ, bins=range(0,11), density=True)\n",
    "hist_modality = np.histogram(s_modality, bins=range(0,6), density=True)\n",
    "                \n",
    "# normalize\n",
    "hist_organ = hist_organ[0]/hist_organ[0].max()\n",
    "hist_modality = hist_modality[0]/hist_modality[0].max()\n",
    "                \n",
    "# iterate \n",
    "for i in range(len(CLASS_NAMES[1])):\n",
    "    hist_organ_mat[:,i] = hist_organ\n",
    "for i in range(len(CLASS_NAMES[0])):\n",
    "    hist_modality_mat[i,:] = hist_modality\n",
    "\n",
    "# number of datapoints\n",
    "datapoints = hist_organ_mat*hist_modality_mat\n",
    "datapoints_test = 0.89*np.ones((10,5))\n",
    "print(datapoints)\n",
    "print(datapoints_test)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(5, 10), dpi=80)\n",
    "data_dir = data_path + '/Data/PolyMNIST/train/'\n",
    "for digit in range(0,10):\n",
    "    for modality in range(0,5):\n",
    "        curr_file = data_dir + 'm' + str(modality) + '/30.' + str(digit) + '.png'\n",
    "        with Image.open(curr_file).convert('RGB') as img:\n",
    "            cnt = digit*5 + modality + 1\n",
    "            plt.subplot(10,5,cnt)  \n",
    "            transparent_area = (0,0,28,28)\n",
    "            mask=Image.new('L', img.size, color=255)\n",
    "            draw=ImageDraw.Draw(mask) \n",
    "            draw.rectangle(transparent_area, fill=int(255*datapoints[digit,modality]))\n",
    "            img.putalpha(mask)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off') \n",
    "plt.subplots_adjust(wspace=0, hspace=0)         \n",
    "# plt.show() \n",
    "plt.savefig('figs/polymnist_imgs_data_dist.png', bbox_inches='tight')\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(5, 10), dpi=80)\n",
    "data_dir = data_path + '/Data/PolyMNIST/train/'\n",
    "for digit in range(0,10):\n",
    "    for modality in range(0,5):\n",
    "        curr_file = data_dir + 'm' + str(modality) + '/30.' + str(digit) + '.png'\n",
    "        with Image.open(curr_file).convert('RGB') as img:\n",
    "            cnt = digit*5 + modality + 1\n",
    "            plt.subplot(10,5,cnt)  \n",
    "            transparent_area = (0,0,28,28)\n",
    "            mask=Image.new('L', img.size, color=255)\n",
    "            draw=ImageDraw.Draw(mask) \n",
    "            draw.rectangle(transparent_area, fill=191)\n",
    "            img.putalpha(mask)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off') \n",
    "plt.subplots_adjust(wspace=0, hspace=0)         \n",
    "# plt.show() \n",
    "plt.savefig('figs/polymnist_imgs_data_avail.png', bbox_inches='tight')\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(5, 10), dpi=80)\n",
    "data_dir = data_path + '/Data/PolyMNIST/train/'\n",
    "for digit in range(0,10):\n",
    "    for modality in range(0,5):\n",
    "        curr_file = data_dir + 'm' + str(modality) + '/30.' + str(digit) + '.png'\n",
    "        with Image.open(curr_file).convert('RGB') as img:\n",
    "            cnt = digit*5 + modality + 1\n",
    "            plt.subplot(10,5,cnt)  \n",
    "            if digit == 2 and modality == 3:\n",
    "                transparent_area = (0,0,28,28)\n",
    "                mask=Image.new('L', img.size, color=255)\n",
    "                draw=ImageDraw.Draw(mask) \n",
    "                draw.rectangle(transparent_area, fill=64)\n",
    "                img.putalpha(mask)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off') \n",
    "plt.subplots_adjust(wspace=0, hspace=0)         \n",
    "# plt.show() \n",
    "plt.savefig('figs/polymnist_imgs_ood.png', bbox_inches='tight')\n",
    "\n",
    "# test\n",
    "fig = plt.figure(figsize=(5, 10), dpi=80)\n",
    "data_dir = data_path + '/Data/PolyMNIST/test/'\n",
    "for digit in range(0,10):\n",
    "    for modality in range(0,5):\n",
    "        curr_file = data_dir + 'm' + str(modality) + '/30.' + str(digit) + '.png'\n",
    "        with Image.open(curr_file).convert('RGB') as img:\n",
    "            cnt = digit*5 + modality + 1\n",
    "            plt.subplot(10,5,cnt)  \n",
    "            transparent_area = (0,0,28,28)\n",
    "            mask=Image.new('L', img.size, color=255)\n",
    "            draw=ImageDraw.Draw(mask) \n",
    "            draw.rectangle(transparent_area, fill=int(255*datapoints_test[digit,modality]))\n",
    "            img.putalpha(mask)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off') \n",
    "plt.subplots_adjust(wspace=0, hspace=0)         \n",
    "# plt.show() \n",
    "plt.savefig('figs/polymnist_imgs_data_dist_test.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b8582",
   "metadata": {},
   "source": [
    "# Number of datapoints experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_mnist import config_experiments_nbrData\n",
    "from utils import gatherMetrics_mnist\n",
    "import json\n",
    "\n",
    "# current task\n",
    "task = 'NbrData'\n",
    "print('Task: ' + task)\n",
    "    \n",
    "experiment_list = config_experiments_nbrData(results_path + '/MNIST/results/results_' + task + '/',False)\n",
    "\n",
    "cnt = 0\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_nbrData = gatherMetrics_mnist(experiment_list, task)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139807b8",
   "metadata": {},
   "source": [
    "# NbrData Secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_mnist import config_experiments_nbrData_secondary\n",
    "from utils import gatherMetrics_mnist, set_seeds\n",
    "import json\n",
    "\n",
    "task = 'NbrData_Secondary'\n",
    "\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "experiment_list = config_experiments_nbrData_secondary(results_path + '/MNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = int(experiment_list[i]['experiment_id'])\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "    else:    \n",
    "        print(curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))   \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_nbrData_secondary = gatherMetrics_mnist(experiment_list, task)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a301d34",
   "metadata": {},
   "source": [
    "# NbrData Secondary experiments - upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_mnist import config_experiments_nbrData_secondary_upsampled\n",
    "from utils import gatherMetrics_mnist, set_seeds\n",
    "import json\n",
    "\n",
    "task = 'NbrData_Secondary_Upsampled'\n",
    "\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "experiment_list = config_experiments_nbrData_secondary_upsampled(results_path + '/MNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = int(experiment_list[i]['experiment_id'])\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "    else:    \n",
    "        print(curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))   \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_nbrData_secondary_upsampled = gatherMetrics_mnist(experiment_list, task)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec25ce",
   "metadata": {},
   "source": [
    "# NbrData Reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0edd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_mnist import config_experiments_nbrData_reduced\n",
    "from utils import gatherMetrics_mnist\n",
    "\n",
    "task = 'NbrData_Reduced'\n",
    "\n",
    "experiment_list = config_experiments_nbrData_reduced(results_path + '/MNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "    # else:\n",
    "    #     print(curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_nbrData_reduced = gatherMetrics_mnist(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850b7ee",
   "metadata": {},
   "source": [
    "# NbrData Secondary Reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ee90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_mnist import config_experiments_nbrData_reduced_secondary\n",
    "from utils import gatherMetrics_mnist, set_seeds\n",
    "\n",
    "task = 'NbrData_ReducedSecondary'\n",
    "\n",
    "experiment_list = config_experiments_nbrData_reduced_secondary(results_path + '/MNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = int(experiment_list[i]['experiment_id'])\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print('Done: ' + curr_path)\n",
    "        cnt = cnt + 1\n",
    "    # else: \n",
    "        # print('Not done yet:' + curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))  \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_nbrData_reduced_secondary = gatherMetrics_mnist(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad39134",
   "metadata": {},
   "source": [
    "# NbrData Secondary Reduced experiments - upsampled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb812d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_mnist import config_experiments_nbrData_reduced_secondary_upsampled\n",
    "from utils import gatherMetrics_mnist, set_seeds\n",
    "\n",
    "task = 'NbrData_ReducedSecondary_upsampled'\n",
    "\n",
    "experiment_list = config_experiments_nbrData_reduced_secondary_upsampled(results_path + '/MNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = int(experiment_list[i]['experiment_id'])\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print('Done: ' + curr_path)\n",
    "        cnt = cnt + 1\n",
    "    # else: \n",
    "        # print('Not done yet:' + curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))  \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_nbrData_reduced_secondary_upsampled = gatherMetrics_mnist(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ba42f",
   "metadata": {},
   "source": [
    "## NbrData Secondary Reduced experiments - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_mnist import config_experiments_nbrData_reduced_secondary_test\n",
    "from utils import gatherMetrics_mnist, set_seeds\n",
    "\n",
    "task = 'NbrData_ReducedSecondary_test'\n",
    "\n",
    "experiment_list = config_experiments_nbrData_reduced_secondary_test(results_path + '/MNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = int(experiment_list[i]['experiment_id'])\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print('Done: ' + curr_path)\n",
    "        cnt = cnt + 1\n",
    "    # else: \n",
    "        # print('Not done yet:' + curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))  \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_nbrData_reduced_secondary_test = gatherMetrics_mnist(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d06692",
   "metadata": {},
   "source": [
    "# Plotting - Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c8c3e",
   "metadata": {},
   "source": [
    "## plot accuracy difference - reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a826353",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MNIST/'\n",
    "results_dir_nbrData_Sec = results_path + '/MNIST/results/results_NbrData_Secondary/'\n",
    "results_dir_nbrData_Red_Sec = results_path + '/MNIST/results/results_NbrData_ReducedSecondary/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "# initialize vectors\n",
    "reduced_percentage_mat = [25,50,75,85,95,100]\n",
    "vec_mean_nbrData_sec = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_sec_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_sec = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_sec_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over reduced percentage\n",
    "for reduced_percentage in reduced_percentage_mat:\n",
    "\n",
    "    # iterate lines\n",
    "    for index, row in df_nbrData.iterrows():\n",
    "        mean_organ = row['mean_organ']\n",
    "        std_organ = row['std_organ']\n",
    "        mean_modality = row['mean_modality']\n",
    "        std_modality = row['std_modality']\n",
    "        \n",
    "        # get the index\n",
    "        idx_nbr_datapoint = df_datapoints[(df_datapoints['mean_organ']==mean_organ) & (df_datapoints['std_organ']==std_organ) & (df_datapoints['mean_modality']==mean_modality) & (df_datapoints['std_modality']==std_modality)].index[0]\n",
    "    \n",
    "        # initialize\n",
    "        eval_mat_nbrData_sec = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_sec_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_sec = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_sec_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        \n",
    "        # filter reduced secondary experiments\n",
    "        df_red_sec_ = df_nbrData_reduced_secondary[(df_nbrData_reduced_secondary['reduced_percentage'] == reduced_percentage) & (df_nbrData_reduced_secondary['mean_organ'] == mean_organ) & (df_nbrData_reduced_secondary['std_organ'] == std_organ) & (df_nbrData_reduced_secondary['mean_modality'] == mean_modality) & (df_nbrData_reduced_secondary['std_modality'] == std_modality)]\n",
    "\n",
    "        # iterate over secondary experiments\n",
    "        for i in range(len(CLASS_NAMES[1])):\n",
    "            df_sec_ = df_nbrData_secondary[(df_nbrData_secondary['task2'] == i) & (df_nbrData_secondary['mean_organ'] == mean_organ) & (df_nbrData_secondary['std_organ'] == std_organ) & (df_nbrData_secondary['mean_modality'] == mean_modality) & (df_nbrData_secondary['std_modality'] == std_modality)]\n",
    "            curr_exp = int(df_sec_['experiment_id'])\n",
    "        \n",
    "            # get the current experiment\n",
    "            curr_path = results_dir_nbrData_Sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                \n",
    "                # calculate id accuracy \n",
    "                for j in range(len(CLASS_NAMES[0])):\n",
    "                    eval_mat_nbrData_sec[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    eval_mat_= np.array(data['eval_mat'], copy=True)  \n",
    "                    eval_mat_[j] = float('nan')\n",
    "                    eval_mat_nbrData_sec_id[j,i] = np.nanmean(eval_mat_)  \n",
    "                    \n",
    "            # iterate over reduced secondary experiments\n",
    "            for j in range(len(CLASS_NAMES[0])): \n",
    "                curr_exp = int(df_red_sec_[(df_red_sec_['task2']==i) & (df_red_sec_['task1']==j)]['experiment_id'])\n",
    "                curr_path = results_dir_nbrData_Red_Sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f)     \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    eval_mat_nbrData_red_sec[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    eval_mat_= np.array(data['eval_mat'], copy=True)  \n",
    "                    eval_mat_[j] = float('nan')\n",
    "                    eval_mat_nbrData_red_sec_id[j,i] = np.nanmean(eval_mat_)  \n",
    "                \n",
    "        # assign \n",
    "        vec_mean_nbrData_sec[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_sec)\n",
    "        vec_mean_nbrData_sec_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_sec_id)\n",
    "        vec_mean_nbrData_red_sec[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_sec)\n",
    "        vec_mean_nbrData_red_sec_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_sec_id)\n",
    "        \n",
    "    # increment\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "blue_colors = [mcolors.CSS4_COLORS['darkslateblue'],\n",
    "               mcolors.CSS4_COLORS['midnightblue'],\n",
    "                mcolors.CSS4_COLORS['darkblue'],\n",
    "                mcolors.CSS4_COLORS['mediumblue'],\n",
    "                mcolors.CSS4_COLORS['royalblue'],\n",
    "                mcolors.CSS4_COLORS['cornflowerblue'],\n",
    "                mcolors.CSS4_COLORS['lightblue']]\n",
    "                \n",
    "# plot\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.subplot(1,2,1)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_sec[:,0],label='0%',color=blue_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red_sec[:,i],label=str(reduced_percentage_mat[i])+'%',color=blue_colors[i+1])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "# plt.title('Specialized - OOD')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "# plt.show()    \n",
    "# plt.savefig('figs/polymnist_specialized_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_specialized_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.subplot(1,2,2)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_sec_id[:,0],label='0%',color=blue_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red_sec_id[:,i],label=str(reduced_percentage_mat[i])+'%',color=blue_colors[i+1])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "# plt.title('Specialized - ID')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()    \n",
    "# plt.savefig('figs/polymnist_specialized_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_specialized_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961ba83",
   "metadata": {},
   "source": [
    "## plot accuracy - reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot accuracy difference - reduced experiments\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MNIST/'\n",
    "results_dir_nbrData = results_path + '/MNIST/results/results_NbrData/'\n",
    "results_dir_nbrData_Red = results_path + '/MNIST/results/results_NbrData_Reduced/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "# initialize vectors\n",
    "reduced_percentage_mat = [25,50,75,85,95,100]\n",
    "vec_mean_nbrData = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "\n",
    "cnt = 0\n",
    "# iterate over reduced percentage\n",
    "for reduced_percentage in reduced_percentage_mat:\n",
    "\n",
    "    # iterate lines\n",
    "    for index, row in df_nbrData.iterrows():\n",
    "        mean_organ = row['mean_organ']\n",
    "        std_organ = row['std_organ']\n",
    "        mean_modality = row['mean_modality']\n",
    "        std_modality = row['std_modality']\n",
    "        curr_exp = row['experiment_id']\n",
    "        \n",
    "        # get the index\n",
    "        idx_nbr_datapoint = df_datapoints[(df_datapoints['mean_organ']==mean_organ) & (df_datapoints['std_organ']==std_organ) & (df_datapoints['mean_modality']==mean_modality) & (df_datapoints['std_modality']==std_modality)].index[0]\n",
    "    \n",
    "        # get the current experiment\n",
    "        curr_path = results_dir_nbrData + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "        if os.path.exists(curr_path):\n",
    "            with open(curr_path, 'r') as f:\n",
    "                data = json.load(f) \n",
    "    \n",
    "            eval_mat_nbrData = np.array(data['eval_mat_sec'])\n",
    "            eval_mat_nbrData_id = np.zeros([eval_mat_nbrData.shape[0],eval_mat_nbrData.shape[1]])\n",
    "    \n",
    "            # calculate id accuracy \n",
    "            for i in range(len(CLASS_NAMES[0])):\n",
    "                for j in range(len(CLASS_NAMES[1])):\n",
    "                    eval_mat_= np.array(eval_mat_nbrData, copy=True)  \n",
    "                    eval_mat_[i,j] = float('nan')\n",
    "                    eval_mat_nbrData_id[i,j] = np.nanmean(eval_mat_)  \n",
    "        \n",
    "        # initialize\n",
    "        eval_mat_nbrData_red = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        \n",
    "        # filter reduced secondary experiments\n",
    "        df_red_ = df_nbrData_reduced[(df_nbrData_reduced['reduced_percentage'] == reduced_percentage) & (df_nbrData_reduced['mean_organ'] == mean_organ) & (df_nbrData_reduced['std_organ'] == std_organ) & (df_nbrData_reduced['mean_modality'] == mean_modality) & (df_nbrData_reduced['std_modality'] == std_modality)]\n",
    "\n",
    "        # iterate over reduced experiments\n",
    "        for i in range(len(CLASS_NAMES[0])):\n",
    "            for j in range(len(CLASS_NAMES[1])): \n",
    "                curr_exp = int(df_red_[(df_red_['task1']==i) & (df_red_['task2']==j)]['experiment_id'])\n",
    "                curr_path = results_dir_nbrData_Red + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f)     \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    eval_mat_nbrData_red[i,j] = np.array(data['eval_mat_sec'])[i,j]\n",
    "                    eval_mat_= np.array(data['eval_mat_sec'], copy=True)  \n",
    "                    eval_mat_[i,j] = float('nan')\n",
    "                    eval_mat_nbrData_red_id[i,j] = np.nanmean(eval_mat_)  \n",
    "                    \n",
    "        # assign \n",
    "        vec_mean_nbrData[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData)\n",
    "        vec_mean_nbrData_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_id)\n",
    "        vec_mean_nbrData_red[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red)\n",
    "        vec_mean_nbrData_red_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_id)\n",
    "        \n",
    "    # increment\n",
    "    cnt = cnt + 1\n",
    "\n",
    "red_colors = [mcolors.CSS4_COLORS['darkred'],\n",
    "                  mcolors.CSS4_COLORS['firebrick'],\n",
    "                  mcolors.CSS4_COLORS['crimson'],\n",
    "                  mcolors.CSS4_COLORS['red'],\n",
    "                  mcolors.CSS4_COLORS['orangered'],\n",
    "                  mcolors.CSS4_COLORS['orange'],\n",
    "                  mcolors.CSS4_COLORS['gold']]\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.subplot(1,2,1)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData[:,0],label='0%',color=red_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red[:,i],label=str(reduced_percentage_mat[i])+'%',color=red_colors[i+1])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "# plt.title('General - OOD')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "# plt.savefig('figs/polymnist_general_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_general_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.subplot(1,2,2)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_id[:,0],label='0%',color=red_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red_id[:,i],label=str(reduced_percentage_mat[i])+'%',color=red_colors[i+1])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "# plt.title('General - ID')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()    \n",
    "# plt.savefig('figs/polymnist_general_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_general_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13d1bf",
   "metadata": {},
   "source": [
    "## plot accuracy - reduced secondary upsampled experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d047aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MNIST/'\n",
    "results_dir_nbrData_Sec_Ups = results_path + '/MNIST/results/results_NbrData_Secondary_Upsampled/'\n",
    "results_dir_nbrData_Red_Sec_Ups = results_path + '/MNIST/results/results_NbrData_ReducedSecondary_upsampled/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "# initialize vectors\n",
    "reduced_percentage_mat = [25,50,75,85,95,100]\n",
    "vec_mean_nbrData_sec_ups = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_sec_ups_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_sec_ups = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_sec_ups_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over reduced percentage\n",
    "for reduced_percentage in reduced_percentage_mat:\n",
    "\n",
    "    # iterate lines\n",
    "    for index, row in df_nbrData.iterrows():\n",
    "        mean_organ = row['mean_organ']\n",
    "        std_organ = row['std_organ']\n",
    "        mean_modality = row['mean_modality']\n",
    "        std_modality = row['std_modality']\n",
    "        \n",
    "        # get the index\n",
    "        idx_nbr_datapoint = df_datapoints[(df_datapoints['mean_organ']==mean_organ) & (df_datapoints['std_organ']==std_organ) & (df_datapoints['mean_modality']==mean_modality) & (df_datapoints['std_modality']==std_modality)].index[0]\n",
    "    \n",
    "        # initialize\n",
    "        eval_mat_nbrData_sec_ups = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_sec_ups_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_sec_ups = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_sec_ups_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        \n",
    "        # filter reduced secondary upsampled experiments\n",
    "        df_red_sec_ups_ = df_nbrData_reduced_secondary_upsampled[(df_nbrData_reduced_secondary_upsampled['reduced_percentage'] == reduced_percentage) & (df_nbrData_reduced_secondary_upsampled['mean_organ'] == mean_organ) & (df_nbrData_reduced_secondary_upsampled['std_organ'] == std_organ) & (df_nbrData_reduced_secondary_upsampled['mean_modality'] == mean_modality) & (df_nbrData_reduced_secondary_upsampled['std_modality'] == std_modality)]\n",
    "        \n",
    "        # iterate over secondary experiments upsampled\n",
    "        for i in range(len(CLASS_NAMES[1])):\n",
    "            df_sec_ups_ = df_nbrData_secondary_upsampled[(df_nbrData_secondary_upsampled['task2'] == i) & (df_nbrData_secondary_upsampled['mean_organ'] == mean_organ) & (df_nbrData_secondary_upsampled['std_organ'] == std_organ) & (df_nbrData_secondary_upsampled['mean_modality'] == mean_modality) & (df_nbrData_secondary_upsampled['std_modality'] == std_modality)]\n",
    "            curr_exp = int(df_sec_ups_['experiment_id'])\n",
    "        \n",
    "            # get the current experiment\n",
    "            curr_path = results_dir_nbrData_Sec_Ups + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                \n",
    "                # calculate id accuracy \n",
    "                for j in range(len(CLASS_NAMES[0])):\n",
    "                    eval_mat_nbrData_sec_ups[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    eval_mat_= np.array(data['eval_mat'], copy=True)  \n",
    "                    eval_mat_[j] = float('nan')\n",
    "                    eval_mat_nbrData_sec_ups_id[j,i] = np.nanmean(eval_mat_)  \n",
    "                    \n",
    "            # iterate over reduced secondary experiments\n",
    "            for j in range(len(CLASS_NAMES[0])): \n",
    "                curr_exp = int(df_red_sec_ups_[(df_red_sec_ups_['task2']==i) & (df_red_sec_ups_['task1']==j)]['experiment_id'])\n",
    "                curr_path = results_dir_nbrData_Red_Sec_Ups + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f)     \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    eval_mat_nbrData_red_sec_ups[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    eval_mat_= np.array(data['eval_mat'], copy=True)  \n",
    "                    eval_mat_[j] = float('nan')\n",
    "                    eval_mat_nbrData_red_sec_ups_id[j,i] = np.nanmean(eval_mat_)  \n",
    "                \n",
    "        # assign \n",
    "        vec_mean_nbrData_sec_ups[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_sec_ups)\n",
    "        vec_mean_nbrData_sec_ups_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_sec_ups_id)\n",
    "        vec_mean_nbrData_red_sec_ups[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_sec_ups)\n",
    "        vec_mean_nbrData_red_sec_ups_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_sec_ups_id)\n",
    "        \n",
    "    # increment\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "green_colors = [mcolors.CSS4_COLORS['darkolivegreen'],\n",
    "                mcolors.CSS4_COLORS['darkgreen'],\n",
    "                mcolors.CSS4_COLORS['forestgreen'],\n",
    "                mcolors.CSS4_COLORS['seagreen'],\n",
    "                mcolors.CSS4_COLORS['mediumseagreen'],\n",
    "                mcolors.CSS4_COLORS['limegreen'],\n",
    "                mcolors.CSS4_COLORS['greenyellow']]\n",
    "                \n",
    "# plot\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.subplot(1,2,1)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_sec_ups[:,0],label='0%',color=green_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red_sec_ups[:,i],label=str(reduced_percentage_mat[i])+'%',color=green_colors[i+1])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "# plt.title('Specialized Upsampled - OOD')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "# plt.savefig('figs/polymnist_upsampled_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_upsampled_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.subplot(1,2,2)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_sec_ups_id[:,0],label='0%',color=green_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red_sec_ups_id[:,i],label=str(reduced_percentage_mat[i])+'%',color=green_colors[i+1])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "# plt.title('Specialized Upsampled - ID')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()   \n",
    "# plt.savefig('figs/polymnist_upsampled_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_upsampled_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f54f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "reduced_percentage_vec = [0,25,50,75,85,95,100]\n",
    "\n",
    "# ood\n",
    "ood_score = np.zeros([len(reduced_percentage_vec),3])\n",
    "ood_score[0,0] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData[:,0])\n",
    "ood_score[0,1] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_sec[:,0])\n",
    "ood_score[0,2] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_sec_ups[:,0])\n",
    "for i in range(1,len(reduced_percentage_vec)):\n",
    "    ood_score[i,0] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_red[:,i-1]) \n",
    "    ood_score[i,1] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_red_sec[:,i-1]) \n",
    "    ood_score[i,2] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_red_sec_ups[:,i-1]) \n",
    "fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "plt.plot(reduced_percentage_vec,ood_score[:,1],color=blue_colors[0],linewidth=2.5,marker='o',label='Specialized')\n",
    "plt.plot(reduced_percentage_vec,ood_score[:,2],color=green_colors[0],linewidth=2.5,marker='o',label='Specialized upsampled')\n",
    "plt.plot(reduced_percentage_vec,ood_score[:,0],color=red_colors[0],linewidth=2.5,marker='o',label='Multi-domain')\n",
    "plt.plot(reduced_percentage_vec,890*np.ones((len(reduced_percentage_vec),1)),'--',color='k')\n",
    "plt.ylim([0,1000])\n",
    "plt.xlabel('OOD level [%]')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=3)\n",
    "# plt.show()\n",
    "# plt.savefig('figs/polymnist_nbrData_auc_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_nbrData_auc_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "# id\n",
    "id_score = np.zeros([len(reduced_percentage_vec),3])\n",
    "id_score[0,0] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_id[:,0])\n",
    "id_score[0,1] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_sec_id[:,0])\n",
    "id_score[0,2] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_sec_ups_id[:,0])\n",
    "for i in range(1,len(reduced_percentage_vec)):\n",
    "    id_score[i,0] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_red_id[:,i-1]) \n",
    "    id_score[i,1] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_red_sec_id[:,i-1]) \n",
    "    id_score[i,2] = auc(df_datapoints['median_datapoints'],vec_mean_nbrData_red_sec_ups_id[:,i-1])  \n",
    "fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "plt.plot(reduced_percentage_vec,id_score[:,1],color=blue_colors[0],linewidth=2.5,marker='o',label='Specialized')\n",
    "plt.plot(reduced_percentage_vec,id_score[:,2],color=green_colors[0],linewidth=2.5,marker='o',label='Specialized upsampled')\n",
    "plt.plot(reduced_percentage_vec,id_score[:,0],color=red_colors[0],linewidth=2.5,marker='o',label='Multi-domain')\n",
    "plt.plot(reduced_percentage_vec,890*np.ones((len(reduced_percentage_vec),1)),'--',color='k')\n",
    "plt.ylim([0,1000])\n",
    "plt.xlabel('OOD level [%]')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=3)\n",
    "# plt.show()\n",
    "# plt.savefig('figs/polymnist_nbrData_auc_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_nbrData_auc_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df6675",
   "metadata": {},
   "source": [
    "## plot difference - specialized vs general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7593f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MNIST/'\n",
    "results_dir_nbrData = results_path + '/MNIST/results/results_NbrData/'\n",
    "results_dir_nbrData_Red = results_path + '/MNIST/results/results_NbrData_Reduced/'\n",
    "results_dir_nbrData_Sec = results_path + '/MNIST/results/results_NbrData_Secondary/'\n",
    "results_dir_nbrData_Red_Sec = results_path + '/MNIST/results/results_NbrData_ReducedSecondary/'\n",
    "\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "# initialize vectors\n",
    "reduced_percentage_mat = [25,50,75,85,95,100]\n",
    "vec_mean_nbrData = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_sec = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_sec_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_sec = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_sec_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over reduced percentage\n",
    "for reduced_percentage in reduced_percentage_mat:\n",
    "\n",
    "    # iterate lines\n",
    "    for index, row in df_nbrData.iterrows():\n",
    "        mean_organ = row['mean_organ']\n",
    "        std_organ = row['std_organ']\n",
    "        mean_modality = row['mean_modality']\n",
    "        std_modality = row['std_modality']\n",
    "        curr_exp = row['experiment_id']\n",
    "        \n",
    "        # get the index\n",
    "        idx_nbr_datapoint = df_datapoints[(df_datapoints['mean_organ']==mean_organ) & (df_datapoints['std_organ']==std_organ) & (df_datapoints['mean_modality']==mean_modality) & (df_datapoints['std_modality']==std_modality)].index[0]\n",
    "    \n",
    "        # get the current experiment\n",
    "        curr_path = results_dir_nbrData + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "        if os.path.exists(curr_path):\n",
    "            with open(curr_path, 'r') as f:\n",
    "                data = json.load(f) \n",
    "    \n",
    "            eval_mat_nbrData = np.array(data['eval_mat_sec'])\n",
    "            eval_mat_nbrData_id = np.zeros([eval_mat_nbrData.shape[0],eval_mat_nbrData.shape[1]])\n",
    "    \n",
    "            # calculate id accuracy \n",
    "            for i in range(len(CLASS_NAMES[0])):\n",
    "                for j in range(len(CLASS_NAMES[1])):\n",
    "                    eval_mat_= np.array(eval_mat_nbrData, copy=True)  \n",
    "                    eval_mat_[i,j] = float('nan')\n",
    "                    eval_mat_nbrData_id[i,j] = np.nanmean(eval_mat_)  \n",
    "        \n",
    "        # initialize\n",
    "        eval_mat_nbrData_red = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        \n",
    "        # filter reduced secondary experiments\n",
    "        df_red_ = df_nbrData_reduced[(df_nbrData_reduced['reduced_percentage'] == reduced_percentage) & (df_nbrData_reduced['mean_organ'] == mean_organ) & (df_nbrData_reduced['std_organ'] == std_organ) & (df_nbrData_reduced['mean_modality'] == mean_modality) & (df_nbrData_reduced['std_modality'] == std_modality)]\n",
    "\n",
    "        # iterate over reduced experiments\n",
    "        for i in range(len(CLASS_NAMES[0])):\n",
    "            for j in range(len(CLASS_NAMES[1])): \n",
    "                curr_exp = int(df_red_[(df_red_['task1']==i) & (df_red_['task2']==j)]['experiment_id'])\n",
    "                curr_path = results_dir_nbrData_Red + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f)     \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    eval_mat_nbrData_red[i,j] = np.array(data['eval_mat_sec'])[i,j]\n",
    "                    eval_mat_= np.array(data['eval_mat_sec'], copy=True)  \n",
    "                    eval_mat_[i,j] = float('nan')\n",
    "                    eval_mat_nbrData_red_id[i,j] = np.nanmean(eval_mat_)  \n",
    "                    \n",
    "        # assign \n",
    "        vec_mean_nbrData[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData)\n",
    "        vec_mean_nbrData_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_id)\n",
    "        vec_mean_nbrData_red[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red)\n",
    "        vec_mean_nbrData_red_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_id)\n",
    "        \n",
    "        # initialize\n",
    "        eval_mat_nbrData_sec = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_sec_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_sec = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_sec_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        \n",
    "        # filter reduced secondary experiments\n",
    "        df_red_sec_ = df_nbrData_reduced_secondary[(df_nbrData_reduced_secondary['reduced_percentage'] == reduced_percentage) & (df_nbrData_reduced_secondary['mean_organ'] == mean_organ) & (df_nbrData_reduced_secondary['std_organ'] == std_organ) & (df_nbrData_reduced_secondary['mean_modality'] == mean_modality) & (df_nbrData_reduced_secondary['std_modality'] == std_modality)]\n",
    "\n",
    "        # iterate over secondary experiments\n",
    "        for i in range(len(CLASS_NAMES[1])):\n",
    "            df_sec_ = df_nbrData_secondary[(df_nbrData_secondary['task2'] == i) & (df_nbrData_secondary['mean_organ'] == mean_organ) & (df_nbrData_secondary['std_organ'] == std_organ) & (df_nbrData_secondary['mean_modality'] == mean_modality) & (df_nbrData_secondary['std_modality'] == std_modality)]\n",
    "            curr_exp = int(df_sec_['experiment_id'])\n",
    "        \n",
    "            # get the current experiment\n",
    "            curr_path = results_dir_nbrData_Sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                \n",
    "                # calculate id accuracy \n",
    "                for j in range(len(CLASS_NAMES[0])):\n",
    "                    eval_mat_nbrData_sec[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    eval_mat_= np.array(data['eval_mat'], copy=True)  \n",
    "                    eval_mat_[j] = float('nan')\n",
    "                    eval_mat_nbrData_sec_id[j,i] = np.nanmean(eval_mat_)  \n",
    "                    \n",
    "            # iterate over reduced secondary experiments\n",
    "            for j in range(len(CLASS_NAMES[0])): \n",
    "                curr_exp = int(df_red_sec_[(df_red_sec_['task2']==i) & (df_red_sec_['task1']==j)]['experiment_id'])\n",
    "                curr_path = results_dir_nbrData_Red_Sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f)     \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    eval_mat_nbrData_red_sec[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    eval_mat_= np.array(data['eval_mat'], copy=True)  \n",
    "                    eval_mat_[j] = float('nan')\n",
    "                    eval_mat_nbrData_red_sec_id[j,i] = np.nanmean(eval_mat_)  \n",
    "                \n",
    "        # assign \n",
    "        vec_mean_nbrData_sec[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_sec)\n",
    "        vec_mean_nbrData_sec_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_sec_id)\n",
    "        vec_mean_nbrData_red_sec[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_sec)\n",
    "        vec_mean_nbrData_red_sec_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_sec_id)\n",
    "        \n",
    "    # increment\n",
    "    cnt = cnt + 1  \n",
    "\n",
    "purple_colors = [mcolors.CSS4_COLORS['indigo'],\n",
    "                mcolors.CSS4_COLORS['purple'],\n",
    "                mcolors.CSS4_COLORS['darkviolet'],\n",
    "                mcolors.CSS4_COLORS['mediumorchid'],\n",
    "                mcolors.CSS4_COLORS['orchid'],\n",
    "                mcolors.CSS4_COLORS['thistle'],\n",
    "                mcolors.CSS4_COLORS['lavender']]          \n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData[:,0]-vec_mean_nbrData_sec[:,0],label='0%',color=purple_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red[:,i]-vec_mean_nbrData_red_sec[:,i],label=str(reduced_percentage_mat[i])+'%',color=purple_colors[i+1])\n",
    "plt.ylim([-0.1,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Balanced accuracy difference')\n",
    "# plt.title('PolyMNIST - OOD')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "# plt.show()  \n",
    "# plt.savefig('figs/polymnist_specialized_vs_general_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_specialized_vs_general_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_id[:,0]-vec_mean_nbrData_sec_id[:,0],label='0%',color=purple_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red_id[:,i]-vec_mean_nbrData_red_sec_id[:,i],label=str(reduced_percentage_mat[i])+'%',color=purple_colors[i+1])\n",
    "plt.ylim([-0.1,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Balanced accuracy difference')\n",
    "# plt.title('PolyMNIST - ID')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "# plt.show()    \n",
    "# plt.savefig('figs/polymnist_specialized_vs_general_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_specialized_vs_general_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a5d37",
   "metadata": {},
   "source": [
    "## plot difference - specialized upsampled vs general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MNIST/'\n",
    "results_dir_nbrData = results_path + '/MNIST/results/results_NbrData/'\n",
    "results_dir_nbrData_Red = results_path + '/MNIST/results/results_NbrData_Reduced/'\n",
    "results_dir_nbrData_Sec_Ups = results_path + '/MNIST/results/results_NbrData_Secondary_Upsampled/'\n",
    "results_dir_nbrData_Red_Sec_Ups = results_path + '/MNIST/results/results_NbrData_ReducedSecondary_upsampled/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "\n",
    "# initialize vectors\n",
    "reduced_percentage_mat = [25,50,75,85,95,100]\n",
    "vec_mean_nbrData = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_sec_ups = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_sec_ups_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_sec_ups = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "vec_mean_nbrData_red_sec_ups_id = np.zeros([len(df_datapoints),len(reduced_percentage_mat)])\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over reduced percentage\n",
    "for reduced_percentage in reduced_percentage_mat:\n",
    "\n",
    "    # iterate lines\n",
    "    for index, row in df_nbrData.iterrows():\n",
    "        mean_organ = row['mean_organ']\n",
    "        std_organ = row['std_organ']\n",
    "        mean_modality = row['mean_modality']\n",
    "        std_modality = row['std_modality']\n",
    "        curr_exp = row['experiment_id']\n",
    "        \n",
    "        # get the index\n",
    "        idx_nbr_datapoint = df_datapoints[(df_datapoints['mean_organ']==mean_organ) & (df_datapoints['std_organ']==std_organ) & (df_datapoints['mean_modality']==mean_modality) & (df_datapoints['std_modality']==std_modality)].index[0]\n",
    "    \n",
    "        # get the current experiment\n",
    "        curr_path = results_dir_nbrData + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "        if os.path.exists(curr_path):\n",
    "            with open(curr_path, 'r') as f:\n",
    "                data = json.load(f) \n",
    "    \n",
    "            eval_mat_nbrData = np.array(data['eval_mat_sec'])\n",
    "            eval_mat_nbrData_id = np.zeros([eval_mat_nbrData.shape[0],eval_mat_nbrData.shape[1]])\n",
    "    \n",
    "            # calculate id accuracy \n",
    "            for i in range(len(CLASS_NAMES[0])):\n",
    "                for j in range(len(CLASS_NAMES[1])):\n",
    "                    eval_mat_= np.array(eval_mat_nbrData, copy=True)  \n",
    "                    eval_mat_[i,j] = float('nan')\n",
    "                    eval_mat_nbrData_id[i,j] = np.nanmean(eval_mat_)  \n",
    "        \n",
    "        # initialize\n",
    "        eval_mat_nbrData_red = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        \n",
    "        # filter reduced secondary experiments\n",
    "        df_red_ = df_nbrData_reduced[(df_nbrData_reduced['reduced_percentage'] == reduced_percentage) & (df_nbrData_reduced['mean_organ'] == mean_organ) & (df_nbrData_reduced['std_organ'] == std_organ) & (df_nbrData_reduced['mean_modality'] == mean_modality) & (df_nbrData_reduced['std_modality'] == std_modality)]\n",
    "\n",
    "        # iterate over reduced experiments\n",
    "        for i in range(len(CLASS_NAMES[0])):\n",
    "            for j in range(len(CLASS_NAMES[1])): \n",
    "                curr_exp = int(df_red_[(df_red_['task1']==i) & (df_red_['task2']==j)]['experiment_id'])\n",
    "                curr_path = results_dir_nbrData_Red + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f)     \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    eval_mat_nbrData_red[i,j] = np.array(data['eval_mat_sec'])[i,j]\n",
    "                    eval_mat_= np.array(data['eval_mat_sec'], copy=True)  \n",
    "                    eval_mat_[i,j] = float('nan')\n",
    "                    eval_mat_nbrData_red_id[i,j] = np.nanmean(eval_mat_)  \n",
    "                    \n",
    "        # assign \n",
    "        vec_mean_nbrData[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData)\n",
    "        vec_mean_nbrData_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_id)\n",
    "        vec_mean_nbrData_red[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red)\n",
    "        vec_mean_nbrData_red_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_id)\n",
    "        \n",
    "        # initialize\n",
    "        eval_mat_nbrData_sec_ups = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_sec_ups_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_sec_ups = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        eval_mat_nbrData_red_sec_ups_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        \n",
    "        # filter reduced secondary upsampled experiments\n",
    "        df_red_sec_ups_ = df_nbrData_reduced_secondary_upsampled[(df_nbrData_reduced_secondary_upsampled['reduced_percentage'] == reduced_percentage) & (df_nbrData_reduced_secondary_upsampled['mean_organ'] == mean_organ) & (df_nbrData_reduced_secondary_upsampled['std_organ'] == std_organ) & (df_nbrData_reduced_secondary_upsampled['mean_modality'] == mean_modality) & (df_nbrData_reduced_secondary_upsampled['std_modality'] == std_modality)]\n",
    "        \n",
    "        # iterate over secondary experiments upsampled\n",
    "        for i in range(len(CLASS_NAMES[1])):\n",
    "            df_sec_ups_ = df_nbrData_secondary_upsampled[(df_nbrData_secondary_upsampled['task2'] == i) & (df_nbrData_secondary_upsampled['mean_organ'] == mean_organ) & (df_nbrData_secondary_upsampled['std_organ'] == std_organ) & (df_nbrData_secondary_upsampled['mean_modality'] == mean_modality) & (df_nbrData_secondary_upsampled['std_modality'] == std_modality)]\n",
    "            curr_exp = int(df_sec_ups_['experiment_id'])\n",
    "        \n",
    "            # get the current experiment\n",
    "            curr_path = results_dir_nbrData_Sec_Ups + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                \n",
    "                # calculate id accuracy \n",
    "                for j in range(len(CLASS_NAMES[0])):\n",
    "                    eval_mat_nbrData_sec_ups[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    eval_mat_= np.array(data['eval_mat'], copy=True)  \n",
    "                    eval_mat_[j] = float('nan')\n",
    "                    eval_mat_nbrData_sec_ups_id[j,i] = np.nanmean(eval_mat_)  \n",
    "                    \n",
    "            # iterate over reduced secondary experiments\n",
    "            for j in range(len(CLASS_NAMES[0])): \n",
    "                curr_exp = int(df_red_sec_ups_[(df_red_sec_ups_['task2']==i) & (df_red_sec_ups_['task1']==j)]['experiment_id'])\n",
    "                curr_path = results_dir_nbrData_Red_Sec_Ups + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "\n",
    "                if os.path.exists(curr_path):\n",
    "                    with open(curr_path, 'r') as f:\n",
    "                        data = json.load(f)     \n",
    "                \n",
    "                    # calculate id accuracy \n",
    "                    eval_mat_nbrData_red_sec_ups[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    eval_mat_= np.array(data['eval_mat'], copy=True)  \n",
    "                    eval_mat_[j] = float('nan')\n",
    "                    eval_mat_nbrData_red_sec_ups_id[j,i] = np.nanmean(eval_mat_)  \n",
    "                \n",
    "        # assign \n",
    "        vec_mean_nbrData_sec_ups[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_sec_ups)\n",
    "        vec_mean_nbrData_sec_ups_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_sec_ups_id)\n",
    "        vec_mean_nbrData_red_sec_ups[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_sec_ups)\n",
    "        vec_mean_nbrData_red_sec_ups_id[idx_nbr_datapoint,cnt] = np.nanmean(eval_mat_nbrData_red_sec_ups_id)\n",
    "        \n",
    "    # increment\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "\n",
    "gray_colors = [mcolors.CSS4_COLORS['black'],\n",
    "                  mcolors.CSS4_COLORS['dimgray'],\n",
    "                  mcolors.CSS4_COLORS['gray'],\n",
    "                  mcolors.CSS4_COLORS['darkgray'],\n",
    "                  mcolors.CSS4_COLORS['silver'],\n",
    "                  mcolors.CSS4_COLORS['lightgray'],\n",
    "                  mcolors.CSS4_COLORS['gainsboro']]\n",
    "                \n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.subplot(1,2,1)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData[:,0]-vec_mean_nbrData_sec_ups[:,0],label='0%',color=gray_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red[:,i]-vec_mean_nbrData_red_sec_ups[:,i],label=str(reduced_percentage_mat[i])+'%',color=gray_colors[i+1])\n",
    "plt.ylim([-0.1,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Balanced accuracy difference')\n",
    "# plt.title('Specialized Upsampled vs General - OOD')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "# plt.savefig('figs/polymnist_upsampled_vs_general_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_upsampled_vs_general_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "# plt.subplot(1,2,2)\n",
    "plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_id[:,0]-vec_mean_nbrData_sec_ups_id[:,0],label='0%',color=gray_colors[0])\n",
    "for i in range(0,len(reduced_percentage_mat)):\n",
    "    plt.plot(df_datapoints['median_datapoints'],vec_mean_nbrData_red_id[:,i]-vec_mean_nbrData_red_sec_ups_id[:,i],label=str(reduced_percentage_mat[i])+'%',color=gray_colors[i+1])\n",
    "plt.ylim([-0.1,1])\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Balanced accuracy difference')\n",
    "# plt.title('Specialized Upsampled vs General - ID')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()\n",
    "# plt.savefig('figs/polymnist_upsampled_vs_general_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_upsampled_vs_general_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91939f64",
   "metadata": {},
   "source": [
    "## control experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93557eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments_mnist import config_experiments_control\n",
    "from utils import gatherMetrics_mnist\n",
    "import json\n",
    "\n",
    "task = 'Control'\n",
    "\n",
    "experiment_list = config_experiments_control(results_path + '/MNIST/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/MNIST/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))  \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_control = gatherMetrics_mnist(experiment_list, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e3d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MNIST/'\n",
    "results_dir_root = results_path + '/MNIST/results/results_Control/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "task = ['Organ','Modality'] \n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "CLASS_NAMES.append(range(0,2))\n",
    "reduced_percentage_vec = [5,10,20,50,75,80,85,90,95,100]\n",
    "vec_eval_mat_control_ood = np.zeros([len(reduced_percentage_vec)])\n",
    "vec_eval_mat_control_id = np.zeros([len(reduced_percentage_vec)])\n",
    "cnt = 0\n",
    "\n",
    "# iterate over reduced percentage\n",
    "for reduced_percentage in reduced_percentage_vec:\n",
    "    # get the current experiment\n",
    "    df_ = df_control[df_control['reduced_percentage'] == reduced_percentage]\n",
    "    print(reduced_percentage)\n",
    "    \n",
    "    # initialize \n",
    "    eval_mat_control_ood = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "    eval_mat_control_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "    \n",
    "    # iterate over modalities\n",
    "    for modality in range(0,5):\n",
    "        \n",
    "        # get the current experiment\n",
    "        df_curr = df_[df_['task2'] == modality]\n",
    "        \n",
    "        # initialize\n",
    "        curr_eval_mat_control_ood = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "        curr_eval_mat_control_id = np.zeros([len(CLASS_NAMES[0]),len(CLASS_NAMES[1])])\n",
    "\n",
    "        # iterate lines\n",
    "        for index, row in df_curr.iterrows():\n",
    "    \n",
    "            # get the removed class names\n",
    "            task1_reduced = row['task1']\n",
    "            task2_reduced = row['task2']\n",
    "        \n",
    "            # check if exists\n",
    "            curr_exp = row['experiment_id']\n",
    "            curr_path = results_path + '/MNIST/results/results_Control/experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):    \n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                    curr_eval_mat = np.array(data['eval_mat'])  \n",
    "                    if task1_reduced > 4:\n",
    "                        curr_eval_mat_control_ood[task1_reduced-5,1] = curr_eval_mat[task1_reduced]\n",
    "                    else:    \n",
    "                        curr_eval_mat_control_ood[task1_reduced,0] = curr_eval_mat[task1_reduced]\n",
    "                    curr_eval_mat[task1_reduced] = float('nan')\n",
    "                    if task1_reduced > 4:\n",
    "                        curr_eval_mat_control_id[task1_reduced-5,1] = np.nanmean(curr_eval_mat)\n",
    "                    else:\n",
    "                        curr_eval_mat_control_id[task1_reduced,0] = np.nanmean(curr_eval_mat)\n",
    "            else:\n",
    "                print('Experiment does not exist.')  \n",
    "\n",
    "        # sum\n",
    "        eval_mat_control_ood = eval_mat_control_ood + curr_eval_mat_control_ood   \n",
    "        eval_mat_control_id = eval_mat_control_id + curr_eval_mat_control_id   \n",
    "    \n",
    "    eval_mat_control_ood = eval_mat_control_ood / 5\n",
    "    eval_mat_control_id = eval_mat_control_id / 5\n",
    "    vec_eval_mat_control_ood[cnt] = np.nanmean(eval_mat_control_ood)\n",
    "    vec_eval_mat_control_id[cnt] = np.nanmean(eval_mat_control_id)\n",
    "    cnt = cnt + 1\n",
    "\n",
    "fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "plt.plot(reduced_percentage_vec,vec_eval_mat_control_ood,linewidth=2.5,marker='o') # ,color=gray_colors[0])\n",
    "plt.plot(reduced_percentage_vec,0.2*np.ones((len(reduced_percentage_vec),1)),'--',color='k')\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('OOD level [%]')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "# plt.title('Specialized Upsampled vs General - ID')\n",
    "# plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "# plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()\n",
    "# plt.savefig('figs/polymnist_control.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/polymnist_control.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea8ab2",
   "metadata": {},
   "source": [
    "## reduced secondary - test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598025ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import set_seeds\n",
    "import matplotlib.colors as mcolors\n",
    "import json\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/MNIST/'\n",
    "results_dir_nbrData_Sec = results_path + '/MNIST/results/results_NbrData_ReducedSecondary_test/'\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES.append(range(0,10))\n",
    "CLASS_NAMES.append(range(0,5))\n",
    "reduced_percentage_mat = [25,50,75,85,95,100]\n",
    "\n",
    "# iterate over secondary experiments\n",
    "eval_mat_nbrData_sec = np.zeros([len(reduced_percentage_mat),len(CLASS_NAMES[1])])\n",
    "eval_mat_nbrData_sec_id = np.zeros([len(reduced_percentage_mat),len(CLASS_NAMES[1])])\n",
    "cnt = 0\n",
    "# iterate lines\n",
    "for reduced_percentage in reduced_percentage_mat:\n",
    "    \n",
    "    for i in range(len(CLASS_NAMES[1])):\n",
    "        df_ = df_nbrData_reduced_secondary_test[(df_nbrData_reduced_secondary_test['id_task_to_test_secondary'] == i) & (df_nbrData_reduced_secondary_test['reduced_percentage'] == reduced_percentage)]\n",
    "        curr_exp = int(df_['experiment_id'])\n",
    "        \n",
    "        # get the current experiment\n",
    "        curr_path = results_dir_nbrData_Sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "        if os.path.exists(curr_path):\n",
    "            with open(curr_path, 'r') as f:\n",
    "                data = json.load(f)     \n",
    "                eval_mat_nbrData_sec[cnt,i] = np.array(data['eval_mat'])[int(df_['task1'])]\n",
    "                eval_mat_= np.array(data['eval_mat'], copy=True)  \n",
    "                eval_mat_[int(df_['task1'])] = float('nan')\n",
    "                eval_mat_nbrData_sec_id[cnt,i] = np.nanmean(eval_mat_)  \n",
    "    cnt = cnt + 1\n",
    "print(eval_mat_nbrData_sec)\n",
    "print('OOD evaluation for modalities: a,b,c,e')  \n",
    "print(np.nanmean(eval_mat_nbrData_sec[:,[0,1,2,4]],axis=1))\n",
    "print('OOD evaluation for modalities: d')  \n",
    "print(eval_mat_nbrData_sec[:,3])\n",
    "print('ID evaluation for modalities: a,b,c,e')  \n",
    "print(np.nanmean(eval_mat_nbrData_sec_id[:,[0,1,2,4]],axis=1))\n",
    "print('ID evaluation for modalities: d')  \n",
    "print(eval_mat_nbrData_sec_id[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bfd1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
