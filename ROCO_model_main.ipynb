{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders\n",
    "data_path = 'xxx' # todo\n",
    "results_path = 'xxx' # todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for hyper experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments import config_experiments\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments(results_path + '/ROCO_ext/results/results_Organ_hyper/',False)\n",
    "with open(results_path + '/ROCO_ext/results/results_Organ_hyper/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - hyper experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main.py --experiment_id=0 --task_to_run='Organ_hyper' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for hyper experiments - secondary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments import config_experiments_hyper_secondary\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_hyper_secondary(results_path + '/ROCO_ext/results/results_Secondary_hyper/',True)\n",
    "with open(results_path + '/ROCO_ext/results/results_Secondary_hyper/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - hyper experiments secondary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main.py --experiment_id=0 --task_to_run='Secondary_hyper' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for seed experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments import config_experiments_seeds\n",
    "import json\n",
    "\n",
    "# seeds configs\n",
    "config_experiments_seeds(results_path + '/ROCO_ext/results/results_Organ/',True)\n",
    "with open(results_path + '/ROCO_ext/results/results_Organ/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - seed experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main.py --experiment_id=0 --task_to_run='Organ' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for secondary experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments import config_experiments_secondary\n",
    "import json\n",
    "# reduced experiment configs        \n",
    "config_experiments_secondary(results_path + '/ROCO_ext/results/results_Secondary/',True)\n",
    "with open(results_path + '/ROCO_ext/results/results_Secondary/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main.py --experiment_id=0 --task_to_run='Secondary' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments import config_experiments_reduced\n",
    "import json        \n",
    "        \n",
    "# reduced experiment configs        \n",
    "config_experiments_reduced(results_path + '/ROCO_ext/results/results_Reduced/',True)\n",
    "with open(results_path + '/ROCO_ext/results/results_Reduced/' + 'configs/' + str(1000) + '.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    print(config)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main.py --experiment_id=0 --task_to_run='Reduced' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs for reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_experiments import config_experiments_reduced_secondary\n",
    "import json\n",
    "\n",
    "# hyperparameter configs\n",
    "config_experiments_reduced_secondary(results_path + '/ROCO_ext/results/results_ReducedSecondary/',True)\n",
    "with open(results_path + '/ROCO_ext/results/results_ReducedSecondary/' + 'configs/' + str(0) + '.json') as config_file:\n",
    "        config = json.load(config_file)\n",
    "        print(config)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run from terminal - reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python main.py --experiment_id=0 --task_to_run='ReducedSecondary' --gpu_id=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - hyper experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check how many experiments are done - hyper experiments\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments import config_experiments\n",
    "from utils import gatherMetrics\n",
    "import json\n",
    "\n",
    "task_list = ['Organ_hyper'] # , 'Modality'] \n",
    "for j in task_list:\n",
    "    # current task\n",
    "    task = j\n",
    "    print('Task: ' + task)\n",
    "    \n",
    "    experiment_list = config_experiments(results_path + '/ROCO_ext/results/results_' + task + '/',False)\n",
    "\n",
    "    cnt = 0\n",
    "    # iterate over experiments\n",
    "    for i in range(len(experiment_list)):\n",
    "        curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "        # check if exists\n",
    "        curr_path = results_path + '/ROCO_ext/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "        if os.path.exists(curr_path):\n",
    "            # print(curr_exp)\n",
    "            cnt = cnt + 1\n",
    "    print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "    # gather all experiments and print best experiment\n",
    "    df = gatherMetrics(experiment_list, task)  \n",
    "\n",
    "# get the evaluation mat\n",
    "curr_exp = 26\n",
    "curr_path = results_path + '/ROCO_ext/results/results_' + task + '/experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "if os.path.exists(curr_path):\n",
    "    with open(curr_path, 'r') as f:\n",
    "        data = json.load(f)       \n",
    "eval_mat_all = np.array(data['eval_mat_sec'])\n",
    "print(eval_mat_all)\n",
    "eval_mat_all_mean_acc = np.nanmean(eval_mat_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check how many experiments are done - hyper experiments\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments import config_experiments_hyper_secondary\n",
    "from utils import gatherMetrics\n",
    "import json\n",
    "\n",
    "# current task\n",
    "task = 'Secondary_hyper'\n",
    "print('Task: ' + task)\n",
    "    \n",
    "experiment_list = config_experiments_hyper_secondary(results_path + '/ROCO_ext/results/results_' + task + '/',False)\n",
    "\n",
    "cnt = 0\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/ROCO_ext/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_secondary_hyper = gatherMetrics(experiment_list, task)  \n",
    "\n",
    "results_dir_sec = results_path + '/ROCO_ext/results/results_Secondary_hyper/'\n",
    "num_classes = [9,6]\n",
    "\n",
    "# learning rate \n",
    "for lr in [1, 1e-1, 5e-1, 1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6]:\n",
    "    df_ = df_secondary_hyper[df_secondary_hyper['learning_rate'] == lr]\n",
    "    eval_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    for i in range(0,6):\n",
    "        \n",
    "        curr_exp = int(df_[df_['task2'] == i]['experiment_id'])\n",
    "        curr_path = results_dir_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "        if os.path.exists(curr_path):\n",
    "            with open(curr_path, 'r') as f:\n",
    "                data = json.load(f) \n",
    "            for j in range(num_classes[0]):\n",
    "                eval_mat[j,i] = np.array(data['eval_mat'])[j]\n",
    "    print('Learning rate: '+str(lr))\n",
    "    print(eval_mat)\n",
    "    print('Mean accuracy: '+str(np.nanmean(eval_mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - seed experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check how many experiments are done - seed experiments\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments import config_experiments_seeds\n",
    "from utils import gatherMetrics\n",
    "import json\n",
    "\n",
    "# current task\n",
    "task = 'Organ'\n",
    "    \n",
    "experiment_list = config_experiments_seeds(results_path + '/ROCO_ext/results/results_' + task + '/',False)\n",
    "\n",
    "cnt = 0\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/ROCO_ext/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df = gatherMetrics(experiment_list, task)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments import config_experiments_secondary\n",
    "from utils import gatherMetrics\n",
    "import json\n",
    "\n",
    "task = 'Secondary'\n",
    "\n",
    "experiment_list = config_experiments_secondary(results_path + '/ROCO_ext/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/ROCO_ext/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        cnt = cnt + 1\n",
    "    # else:\n",
    "    #     print(curr_path)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments\n",
    "df_secondary = gatherMetrics(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments import config_experiments_reduced\n",
    "from utils import gatherMetrics\n",
    "\n",
    "task = 'Reduced'\n",
    "\n",
    "experiment_list = config_experiments_reduced(results_path + '/ROCO_ext/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/ROCO_ext/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        print(curr_exp)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))        \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_reduced = gatherMetrics(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check how many experiments are done - reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many experiments are done\n",
    "import os\n",
    "import numpy as np\n",
    "from config_experiments import config_experiments_reduced_secondary\n",
    "from utils import gatherMetrics\n",
    "import json\n",
    "\n",
    "task = 'ReducedSecondary'\n",
    "\n",
    "experiment_list = config_experiments_reduced_secondary(results_path + '/ROCO_ext/results/results_'+ task +'/',False)\n",
    "\n",
    "cnt = 0\n",
    "missing_vec = []\n",
    "# iterate over experiments\n",
    "for i in range(len(experiment_list)):\n",
    "    curr_exp = experiment_list[i]['experiment_id']\n",
    "    \n",
    "    # check if exists\n",
    "    curr_path = results_path + '/ROCO_ext/results/results_' + task + '/experiment_' + str(curr_exp) + '/checkpoint_last' + str(experiment_list[i]['num_epochs']-1)\n",
    "    if os.path.exists(curr_path):\n",
    "        # print(curr_exp)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        # print(curr_path)\n",
    "        missing_vec.append(curr_exp)\n",
    "print('Current status of done experiments: ' + str(cnt) + '/' + str(len(experiment_list)))  \n",
    "\n",
    "# gather all experiments and print best experiment\n",
    "df_reduced_secondary = gatherMetrics(experiment_list, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot accuracy difference - secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/ROCO_ext/'\n",
    "results_dir = results_path + '/ROCO_ext/results/results_Organ/'\n",
    "results_dir_sec = results_path + '/ROCO_ext/results/results_Secondary/'\n",
    "\n",
    "concept_list = 'concept_names.csv'\n",
    "sample_class = 3\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "    \n",
    "# all concepts\n",
    "df_concepts_all = pd.read_csv(data_dir + concept_list ,sep='\\t')  \n",
    "\n",
    "# read semantic group\n",
    "df_concepts_all_semantic = pd.read_csv(data_dir + 'MostCommonCUIs.csv',sep=',')\n",
    "df_concepts_all_semantic = df_concepts_all_semantic[0:100]\n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "task = ['Body Part, Organ, or Organ Component','Diagnostic Procedure'] # ['Diagnostic Procedure'] # \n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "for i in range(len(task)):\n",
    "    idx = df_concepts_all_semantic['Semantic attribute'] == task[i]\n",
    "    \n",
    "    CLASS_NAMES.append(df_concepts_all_semantic[idx]['CUI'].to_numpy())\n",
    "    CLASS_NAMES_exp.append(df_concepts_all_semantic[idx]['Explanation'].to_numpy())\n",
    "    \n",
    "# get every sample_class class\n",
    "CLASS_NAMES[0] = CLASS_NAMES[0][1::sample_class]\n",
    "CLASS_NAMES_exp[0] = CLASS_NAMES_exp[0][1::sample_class]\n",
    "        \n",
    "# x and y_axis ticks\n",
    "y_list = CLASS_NAMES_exp[0]  \n",
    "x_list = ['CT','X-ray','MRI','US','AG','PET']# CLASS_NAMES_exp[1]  \n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "# plot params\n",
    "plotOOD = True\n",
    "plotMeans = True\n",
    "\n",
    "# iterate over seeds\n",
    "seed_vec = [42,73,666,777,1009]#,1279,1597,1811,1949,2053]\n",
    "sampling_percentage_vec = [100,75,50,35,25,10,5]\n",
    "datapoints_train_val = np.array([[826, 1747, 262,  45,  20, 23],\n",
    "                         [ 23, 1134, 101,   8,   3,  2],\n",
    "                         [492,  313,  14,  63,   6, 24],\n",
    "                         [251,  116, 116, 149,  14, 10],\n",
    "                         [ 70,   36,  59, 507,  28,  0],\n",
    "                         [311,  171,  39,  71,  21,  3],\n",
    "                         [219,   42,  24, 109,  74,  0],\n",
    "                         [ 35,    7,  23,  20, 373,  0],\n",
    "                         [275,   29,  51,  64,   8,  2]])\n",
    "\n",
    "# initialize\n",
    "mean_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "mean_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "cnt_sampling_percentage = 0\n",
    "\n",
    "# iterate over sampling percentage\n",
    "for sampling_percentage in sampling_percentage_vec:\n",
    "    # print\n",
    "    print('Sampling percentage: ' + str(sampling_percentage))\n",
    "    \n",
    "    # initialize\n",
    "    eval_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_sec_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_vec = np.zeros([len(seed_vec),1])\n",
    "    eval_sec_vec = np.zeros([len(seed_vec),1])\n",
    "    cnt_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    cnt_seed = 0\n",
    "\n",
    "    # iterate over random seed\n",
    "    for seed in seed_vec:\n",
    "            \n",
    "        # get the current experiment\n",
    "        df_ = df[(df['sampling_percentage'] == sampling_percentage) & (df['seed'] == seed)]\n",
    "            \n",
    "        # get the current experiment\n",
    "        curr_exp = int(df_['experiment_id'])\n",
    "        curr_path = results_dir + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "        if os.path.exists(curr_path):\n",
    "            with open(curr_path, 'r') as f:\n",
    "                data = json.load(f) \n",
    "    \n",
    "            eval_ = np.array(data['eval_mat_sec'])\n",
    "    \n",
    "        # filter df_nbrData_secondary\n",
    "        eval_sec = np.zeros([num_classes[0],num_classes[1]])\n",
    "    \n",
    "        # iterate over secondary experiments\n",
    "        for i in range(num_classes[1]):\n",
    "        \n",
    "            # get the current experiment\n",
    "            df_secondary_ = df_secondary[(df_secondary['sampling_percentage'] == sampling_percentage) &\n",
    "                                     (df_secondary['task2'] == i) & \n",
    "                                     (df_secondary['seed'] == seed)]\n",
    "            curr_exp = int(df_secondary_['experiment_id'])\n",
    "            curr_path = results_dir_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                \n",
    "                # calculate id accuracy \n",
    "                for j in range(num_classes[0]):\n",
    "                    eval_sec[j,i] = np.array(data['eval_mat'])[j]   \n",
    "                    \n",
    "        # sum for each seed\n",
    "        eval_mat = eval_mat + eval_\n",
    "        eval_sec_mat = eval_sec_mat + eval_sec\n",
    "        eval_vec[cnt_seed] = np.nanmean(eval_)\n",
    "        eval_sec_vec[cnt_seed] = np.nanmean(eval_sec)\n",
    "        cnt_mat = cnt_mat + ((eval_sec - eval_) > 0)\n",
    "        cnt_seed = cnt_seed + 1 \n",
    "               \n",
    "    # average\n",
    "    eval_mat = eval_mat/cnt_seed\n",
    "    eval_sec_mat = eval_sec_mat/cnt_seed\n",
    "    mean_eval_mat[cnt_sampling_percentage] = np.nanmean(eval_vec)\n",
    "    mean_eval_sec_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_vec)\n",
    "    std_eval_mat[cnt_sampling_percentage] = np.nanstd(eval_vec)\n",
    "    std_eval_sec_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_vec)\n",
    "    cnt_sampling_percentage = cnt_sampling_percentage + 1  \n",
    "\n",
    "    # plot detailed\n",
    "    if plotOOD:    \n",
    "        # diff ood\n",
    "        eval_diff = eval_mat - eval_sec_mat\n",
    "\n",
    "        # plot\n",
    "        fig = plt.figure(figsize=(15, 3), dpi=80)\n",
    "        \n",
    "        # number of datapoints\n",
    "        ax1 = fig.add_subplot(1,5,1)\n",
    "        im1 = ax1.imshow(np.round(datapoints_train_val*(sampling_percentage/100)))\n",
    "        ax1.set_xticks(np.arange(len(x_list)), labels=x_list)\n",
    "        ax1.set_yticks(np.arange(len(y_list)), labels=y_list)\n",
    "        plt.setp(ax1.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.setp(ax1.get_yticklabels(), rotation=-45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        # ax1.set_title(\"Number of samples\")\n",
    "        fig.colorbar(im1, orientation='vertical')\n",
    "\n",
    "        # specialized model\n",
    "        ax2 = fig.add_subplot(1,5,2)\n",
    "        im2 = ax2.imshow(eval_sec_mat, vmin=0, vmax=1) \n",
    "        ax2.set_xticks(np.arange(len(x_list)), labels=x_list)\n",
    "        ax2.set_yticks([])\n",
    "        plt.setp(ax2.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.setp(ax2.get_yticklabels(), rotation=-45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        # ax2.set_title(\"Specialized model\")\n",
    "        fig.colorbar(im2, orientation='vertical')\n",
    "\n",
    "        # test\n",
    "        ax3 = fig.add_subplot(1,5,3)\n",
    "        im3 = ax3.imshow(eval_mat, vmin=0, vmax=1) \n",
    "        ax3.set_xticks(np.arange(len(x_list)),labels=x_list)\n",
    "        ax3.set_yticks([])\n",
    "        plt.setp(ax3.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.setp(ax3.get_yticklabels(), rotation=-45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        # ax3.set_title(\"General model\")\n",
    "        fig.colorbar(im3, orientation='vertical')\n",
    "\n",
    "        # difference\n",
    "        ax4 = fig.add_subplot(1,5,4)\n",
    "        im4 = ax4.imshow(eval_diff, vmin=-0.3, vmax=0.3, cmap=cmap) \n",
    "        ax4.set_xticks(np.arange(len(x_list)),labels=x_list)\n",
    "        ax4.set_yticks([])\n",
    "        plt.setp(ax4.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.setp(ax4.get_yticklabels(), rotation=-45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        # ax4.set_title(\"Difference\")\n",
    "        fig.colorbar(im4, orientation='vertical')\n",
    "    \n",
    "        # check how many times specialized better than general\n",
    "        ax5 = fig.add_subplot(1,5,5)\n",
    "        im5 = ax5.imshow(cnt_mat, vmin=0, vmax=len(seed_vec)) \n",
    "        ax5.set_xticks(np.arange(len(x_list)),labels=x_list)\n",
    "        ax5.set_yticks([])\n",
    "        plt.setp(ax5.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        plt.setp(ax5.get_yticklabels(), rotation=-45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        # ax5.set_title(\"Specialized better\")\n",
    "        fig.colorbar(im5, orientation='vertical')\n",
    "\n",
    "        plt.subplots_adjust(wspace=0.25)\n",
    "        # plt.show()\n",
    "        plt.savefig('figs/imageclef_specialized_vs_general_'+str(sampling_percentage)+'.eps', bbox_inches='tight', format='eps')\n",
    "        \n",
    "blue_colors = [mcolors.CSS4_COLORS['darkslateblue'],\n",
    "               mcolors.CSS4_COLORS['midnightblue'],\n",
    "                mcolors.CSS4_COLORS['darkblue'],\n",
    "                mcolors.CSS4_COLORS['mediumblue'],\n",
    "                mcolors.CSS4_COLORS['royalblue'],\n",
    "                mcolors.CSS4_COLORS['cornflowerblue'],\n",
    "                mcolors.CSS4_COLORS['lightblue']]\n",
    "\n",
    "red_colors = [mcolors.CSS4_COLORS['darkred'],\n",
    "                  mcolors.CSS4_COLORS['firebrick'],\n",
    "                  mcolors.CSS4_COLORS['crimson'],\n",
    "                  mcolors.CSS4_COLORS['red'],\n",
    "                  mcolors.CSS4_COLORS['orangered'],\n",
    "                  mcolors.CSS4_COLORS['orange'],\n",
    "                  mcolors.CSS4_COLORS['gold']]        \n",
    "# plot\n",
    "fig = plt.figure(figsize=(4.5, 3), dpi=80)\n",
    "plt.plot(sampling_percentage_vec,mean_eval_sec_mat,label='Specialized',color=blue_colors[0])\n",
    "plt.plot(sampling_percentage_vec,mean_eval_mat,label='General',color=red_colors[0])\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlabel('Sampling percentage [%]')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "plt.title('Specialized vs General')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot accuracy difference - reduced secondary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/ROCO_ext/'\n",
    "results_dir_sec = results_path + '/ROCO_ext/results/results_Secondary/'\n",
    "results_dir_red_sec = results_path + '/ROCO_ext/results/results_ReducedSecondary/'\n",
    "\n",
    "concept_list = 'concept_names.csv'\n",
    "sample_class = 3\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "\n",
    "# all concepts\n",
    "df_concepts_all = pd.read_csv(data_dir + concept_list ,sep='\\t')  \n",
    "\n",
    "# read semantic group\n",
    "df_concepts_all_semantic = pd.read_csv(data_dir + 'MostCommonCUIs.csv',sep=',')\n",
    "df_concepts_all_semantic = df_concepts_all_semantic[0:100]\n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "task = ['Body Part, Organ, or Organ Component','Diagnostic Procedure'] # ['Diagnostic Procedure'] # \n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "for i in range(len(task)):\n",
    "    idx = df_concepts_all_semantic['Semantic attribute'] == task[i]\n",
    "    \n",
    "    CLASS_NAMES.append(df_concepts_all_semantic[idx]['CUI'].to_numpy())\n",
    "    CLASS_NAMES_exp.append(df_concepts_all_semantic[idx]['Explanation'].to_numpy())\n",
    "    \n",
    "# get every sample_class class\n",
    "CLASS_NAMES[0] = CLASS_NAMES[0][1::sample_class]\n",
    "CLASS_NAMES_exp[0] = CLASS_NAMES_exp[0][1::sample_class]\n",
    "        \n",
    "# x and y_axis ticks\n",
    "y_list = CLASS_NAMES_exp[0]  \n",
    "x_list = CLASS_NAMES_exp[1]  \n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "# iterate over seeds\n",
    "seed_vec = [42,73,666,777,1009] # ,1279,1597,1811,1949,2053]\n",
    "sampling_percentage_vec = [100,75,50,35,25,10,5]\n",
    "reduced_percentage_vec = [25,50,75,85,95,100]\n",
    "\n",
    "# initialize\n",
    "mean_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "mean_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "mean_eval_red_sec_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "mean_eval_red_sec_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "std_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_red_sec_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "std_eval_red_sec_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "cnt_sampling_percentage = 0\n",
    "    \n",
    "# iterate over sampling percentage\n",
    "for sampling_percentage in sampling_percentage_vec:\n",
    "    # print\n",
    "    print('Sampling percentage: ' + str(sampling_percentage))\n",
    "    \n",
    "    # initlaize eval_mat\n",
    "    eval_sec_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_sec_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_sec_vec = np.zeros([len(seed_vec),1])\n",
    "    eval_sec_id_vec = np.zeros([len(seed_vec),1])\n",
    "    cnt_seed = 0\n",
    "    \n",
    "    # iterate over random seed\n",
    "    for seed in seed_vec:       \n",
    "    \n",
    "        # filter df_nbrData_secondary\n",
    "        eval_sec = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_sec_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "    \n",
    "        # iterate over secondary experiments\n",
    "        for i in range(num_classes[1]):\n",
    "        \n",
    "            # get the current experiment\n",
    "            df_sec_ = df_secondary[(df_secondary['task2'] == i) & \n",
    "                                   (df_secondary['seed'] == seed) & \n",
    "                                   (df_secondary['sampling_percentage'] == sampling_percentage)]\n",
    "            curr_exp = int(df_sec_['experiment_id'])\n",
    "            curr_path = results_dir_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                \n",
    "                # calculate id accuracy \n",
    "                for j in range(num_classes[0]):\n",
    "                    eval_sec[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    tmp = np.array(data['eval_mat'], copy=True)  \n",
    "                    tmp[j] = float('nan')\n",
    "                    eval_sec_id[j,i] = np.nanmean(tmp) \n",
    "                    \n",
    "        # sum for each seed\n",
    "        eval_sec_mat = eval_sec_mat + eval_sec\n",
    "        eval_sec_id_mat = eval_sec_id_mat + eval_sec_id\n",
    "        eval_sec_vec[cnt_seed] = np.nanmean(eval_sec)\n",
    "        eval_sec_id_vec[cnt_seed] = np.nanmean(eval_sec_id)\n",
    "        cnt_seed = cnt_seed + 1\n",
    "        \n",
    "    # assign for each sampling_percentage\n",
    "    eval_sec_mat = eval_sec_mat/cnt_seed\n",
    "    eval_sec_id_mat = eval_sec_id_mat/cnt_seed\n",
    "    mean_eval_sec_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_vec)\n",
    "    mean_eval_sec_id_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_id_vec)\n",
    "    std_eval_sec_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_vec)\n",
    "    std_eval_sec_id_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_id_vec)\n",
    "    \n",
    "    # iterate over reduced secondary experiments\n",
    "    cnt_reduced_percentage = 0\n",
    "    for reduced_percentage in reduced_percentage_vec:\n",
    "        # initialize\n",
    "        eval_red_sec_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_red_sec_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_red_sec_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_red_sec_id_vec = np.zeros([len(seed_vec),1])\n",
    "        cnt_seed = 0\n",
    "        \n",
    "        # iterate over random seed\n",
    "        for seed in seed_vec: \n",
    "            \n",
    "            # initialize\n",
    "            eval_red_sec = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_red_sec_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "            # get the current experiment\n",
    "            df_red_sec = df_reduced_secondary[(df_reduced_secondary['seed'] == seed) & \n",
    "                                             (df_reduced_secondary['sampling_percentage'] == sampling_percentage) & \n",
    "                                             (df_reduced_secondary['reduced_percentage'] == reduced_percentage)]\n",
    "            \n",
    "            # iterate over tasks\n",
    "            for i in range(num_classes[1]):\n",
    "                # initialize cnt\n",
    "                cnt = 0\n",
    "                for j in range(1,26,3):\n",
    "                    # get the current experiment\n",
    "                    df_red_sec_ = df_red_sec[(df_red_sec['task1'] == j) & (df_red_sec['task2'] == i)]\n",
    "                    curr_exp = int(df_red_sec_['experiment_id'])\n",
    "                    curr_path = results_dir_red_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                    if os.path.exists(curr_path):\n",
    "                        with open(curr_path, 'r') as f:\n",
    "                            data = json.load(f) \n",
    "                \n",
    "                        eval_red_sec[cnt,i] = np.array(data['eval_mat'])[cnt]\n",
    "                        tmp = np.array(data['eval_mat'], copy=True)  \n",
    "                        tmp[cnt] = float('nan')\n",
    "                        eval_red_sec_id[cnt,i] = np.nanmean(tmp) \n",
    "                    cnt = cnt + 1    \n",
    "            # sum for each seed\n",
    "            eval_red_sec_mat = eval_red_sec_mat + eval_red_sec\n",
    "            eval_red_sec_id_mat = eval_red_sec_id_mat + eval_red_sec_id\n",
    "            eval_red_sec_vec[cnt_seed] = np.nanmean(eval_red_sec)\n",
    "            eval_red_sec_id_vec[cnt_seed] = np.nanmean(eval_red_sec_id)\n",
    "            cnt_seed = cnt_seed + 1   \n",
    "            \n",
    "        # assign for each sampling_percentage\n",
    "        eval_red_sec_mat = eval_red_sec_mat/cnt_seed\n",
    "        eval_red_sec_id_mat = eval_red_sec_id_mat/cnt_seed\n",
    "        mean_eval_red_sec_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_sec_vec)\n",
    "        mean_eval_red_sec_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_sec_id_vec)\n",
    "        std_eval_red_sec_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_sec_vec)\n",
    "        std_eval_red_sec_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_sec_id_vec)\n",
    "        cnt_reduced_percentage = cnt_reduced_percentage + 1   \n",
    "    \n",
    "    # increment cnt for sampling percentage\n",
    "    cnt_sampling_percentage = cnt_sampling_percentage + 1   \n",
    "\n",
    "blue_colors = [mcolors.CSS4_COLORS['darkslateblue'],\n",
    "               mcolors.CSS4_COLORS['midnightblue'],\n",
    "                mcolors.CSS4_COLORS['darkblue'],\n",
    "                mcolors.CSS4_COLORS['mediumblue'],\n",
    "                mcolors.CSS4_COLORS['royalblue'],\n",
    "                mcolors.CSS4_COLORS['cornflowerblue'],\n",
    "                mcolors.CSS4_COLORS['lightblue']]\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(11, 3), dpi=80)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(sampling_percentage_vec,mean_eval_sec_mat,label='0%',color=blue_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.plot(sampling_percentage_vec,mean_eval_red_sec_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=blue_colors[i+1])\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlabel('Sampling percentage [%]')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "plt.title('Reduced - Specialized OOD')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sampling_percentage_vec,mean_eval_sec_id_mat,label='0%',color=blue_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.plot(sampling_percentage_vec,mean_eval_red_sec_id_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=blue_colors[i+1])\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlabel('Sampling percentage [%]')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "plt.title('Reduced - Specialized ID')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right',ncol=1)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot accuracy difference - reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/ROCO_ext/'\n",
    "results_dir = results_path + '/ROCO_ext/results/results_Organ/'\n",
    "results_dir_red = results_path + '/ROCO_ext/results/results_Reduced/'\n",
    "\n",
    "concept_list = 'concept_names.csv'\n",
    "sample_class = 3\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "\n",
    "# all concepts\n",
    "df_concepts_all = pd.read_csv(data_dir + concept_list ,sep='\\t')  \n",
    "\n",
    "# read semantic group\n",
    "df_concepts_all_semantic = pd.read_csv(data_dir + 'MostCommonCUIs.csv',sep=',')\n",
    "df_concepts_all_semantic = df_concepts_all_semantic[0:100]\n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "task = ['Body Part, Organ, or Organ Component','Diagnostic Procedure'] # ['Diagnostic Procedure'] # \n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "for i in range(len(task)):\n",
    "    idx = df_concepts_all_semantic['Semantic attribute'] == task[i]\n",
    "    \n",
    "    CLASS_NAMES.append(df_concepts_all_semantic[idx]['CUI'].to_numpy())\n",
    "    CLASS_NAMES_exp.append(df_concepts_all_semantic[idx]['Explanation'].to_numpy())\n",
    "    \n",
    "# get every sample_class class\n",
    "CLASS_NAMES[0] = CLASS_NAMES[0][1::sample_class]\n",
    "CLASS_NAMES_exp[0] = CLASS_NAMES_exp[0][1::sample_class]\n",
    "        \n",
    "# x and y_axis ticks\n",
    "y_list = CLASS_NAMES_exp[0]  \n",
    "x_list = CLASS_NAMES_exp[1]  \n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "# iterate over seeds\n",
    "seed_vec = [42,73,666,777,1009]# ,1279,1597,1811,1949,2053]\n",
    "sampling_percentage_vec = [100,75,50,35,25,10,5]\n",
    "reduced_percentage_vec = [25,50,75,85,95,100]\n",
    "\n",
    "# initialize\n",
    "mean_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "mean_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "mean_eval_red_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "mean_eval_red_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "std_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_red_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "std_eval_red_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "cnt_sampling_percentage = 0\n",
    "    \n",
    "# iterate over sampling percentage\n",
    "for sampling_percentage in sampling_percentage_vec:\n",
    "    # print\n",
    "    print('Sampling percentage: ' + str(sampling_percentage))\n",
    "    \n",
    "    # initlaize eval_mat\n",
    "    eval_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_vec = np.zeros([len(seed_vec),1])\n",
    "    eval_id_vec = np.zeros([len(seed_vec),1])\n",
    "    cnt_seed = 0\n",
    "    \n",
    "    # iterate over random seed\n",
    "    for seed in seed_vec:       \n",
    "    \n",
    "        # get the current experiment\n",
    "        df_ = df[(df['seed'] == seed) & (df['sampling_percentage'] == sampling_percentage)]\n",
    "        curr_exp = int(df_['experiment_id'])\n",
    "        curr_path = results_dir + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "        if os.path.exists(curr_path):\n",
    "            with open(curr_path, 'r') as f:\n",
    "                data = json.load(f) \n",
    "                \n",
    "            eval_ = np.array(data['eval_mat_sec'])\n",
    "            eval_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "            # calculate id accuracy \n",
    "            for j in range(num_classes[0]):\n",
    "                for i in range(num_classes[1]):\n",
    "                    tmp = np.array(data['eval_mat_sec'], copy=True)  \n",
    "                    tmp[j,i] = float('nan')\n",
    "                    eval_id[j,i] = np.nanmean(tmp) \n",
    "                    \n",
    "        # sum for each seed\n",
    "        eval_mat = eval_mat + eval_\n",
    "        eval_id_mat = eval_id_mat + eval_id\n",
    "        eval_vec[cnt_seed] = np.nanmean(eval_)\n",
    "        eval_id_vec[cnt_seed] = np.nanmean(eval_id)\n",
    "        cnt_seed = cnt_seed + 1\n",
    "        \n",
    "    # assign for each sampling_percentage\n",
    "    eval_mat = eval_mat/cnt_seed\n",
    "    eval_id_mat = eval_id_mat/cnt_seed\n",
    "    mean_eval_mat[cnt_sampling_percentage] = np.nanmean(eval_vec)\n",
    "    mean_eval_id_mat[cnt_sampling_percentage] = np.nanmean(eval_id_vec)\n",
    "    std_eval_mat[cnt_sampling_percentage] = np.nanstd(eval_vec)\n",
    "    std_eval_id_mat[cnt_sampling_percentage] = np.nanstd(eval_id_vec)\n",
    "    \n",
    "    # iterate over reduced experiments\n",
    "    cnt_reduced_percentage = 0\n",
    "    for reduced_percentage in reduced_percentage_vec:\n",
    "        # initialize\n",
    "        eval_red_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_red_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_red_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_red_id_vec = np.zeros([len(seed_vec),1])\n",
    "        cnt_seed = 0\n",
    "        \n",
    "        # iterate over random seed\n",
    "        for seed in seed_vec: \n",
    "            \n",
    "            # initialize\n",
    "            eval_red = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_red_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "            # get the current experiment\n",
    "            df_red = df_reduced[(df_reduced['seed'] == seed) & \n",
    "                                (df_reduced['sampling_percentage'] == sampling_percentage) & \n",
    "                                (df_reduced['reduced_percentage'] == reduced_percentage)]\n",
    "            \n",
    "            # iterate over tasks\n",
    "            for i in range(num_classes[1]):\n",
    "                # initialize cnt\n",
    "                cnt = 0\n",
    "                for j in range(1,26,3):\n",
    "                    # get the current experiment\n",
    "                    df_red_ = df_red[(df_red['task1'] == j) & (df_red['task2'] == i)]\n",
    "                    curr_exp = int(df_red_['experiment_id'])\n",
    "                    curr_path = results_dir_red + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                    if os.path.exists(curr_path):\n",
    "                        with open(curr_path, 'r') as f:\n",
    "                            data = json.load(f) \n",
    "                \n",
    "                        eval_red[cnt,i] = np.array(data['eval_mat_sec'])[cnt,i]\n",
    "                        tmp = np.array(data['eval_mat_sec'], copy=True)  \n",
    "                        tmp[cnt,i] = float('nan')\n",
    "                        eval_red_id[cnt,i] = np.nanmean(tmp) \n",
    "                    cnt = cnt + 1    \n",
    "            # sum for each seed\n",
    "            eval_red_mat = eval_red_mat + eval_red\n",
    "            eval_red_id_mat = eval_red_id_mat + eval_red_id\n",
    "            eval_red_vec[cnt_seed] = np.nanmean(eval_red)\n",
    "            eval_red_id_vec[cnt_seed] = np.nanmean(eval_red_id)\n",
    "            cnt_seed = cnt_seed + 1   \n",
    "            \n",
    "        # assign for each sampling_percentage\n",
    "        eval_red_mat = eval_red_mat/cnt_seed\n",
    "        eval_red_id_mat = eval_red_id_mat/cnt_seed\n",
    "        mean_eval_red_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_vec)\n",
    "        mean_eval_red_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_id_vec)\n",
    "        std_eval_red_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_vec)\n",
    "        std_eval_red_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_id_vec)\n",
    "        cnt_reduced_percentage = cnt_reduced_percentage + 1   \n",
    "    \n",
    "    # increment cnt for sampling percentage\n",
    "    cnt_sampling_percentage = cnt_sampling_percentage + 1   \n",
    "\n",
    "red_colors = [mcolors.CSS4_COLORS['darkred'],\n",
    "                  mcolors.CSS4_COLORS['firebrick'],\n",
    "                  mcolors.CSS4_COLORS['crimson'],\n",
    "                  mcolors.CSS4_COLORS['red'],\n",
    "                  mcolors.CSS4_COLORS['orangered'],\n",
    "                  mcolors.CSS4_COLORS['orange'],\n",
    "                  mcolors.CSS4_COLORS['gold']]\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(11, 3), dpi=80)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(sampling_percentage_vec,mean_eval_mat,label='0%',color=red_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.plot(sampling_percentage_vec,mean_eval_red_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=red_colors[i+1])\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlabel('Sampling percentage [%]')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "plt.title('Reduced - General OOD')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sampling_percentage_vec,mean_eval_id_mat,label='0%',color=red_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.plot(sampling_percentage_vec,mean_eval_red_id_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=red_colors[i+1])\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlabel('Sampling percentage [%]')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "plt.title('Reduced - General ID')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right',ncol=1)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot accuracy difference - all reduced experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# plot for config['sample_class']\n",
    "data_dir = data_path + '/Data/ROCO_ext/'\n",
    "results_dir = results_path + '/ROCO_ext/results/results_Organ/'\n",
    "results_dir_red = results_path + '/ROCO_ext/results/results_Reduced/'\n",
    "results_dir_sec = results_path + '/ROCO_ext/results/results_Secondary/'\n",
    "results_dir_red_sec = results_path + '/ROCO_ext/results/results_ReducedSecondary/'\n",
    "\n",
    "concept_list = 'concept_names.csv'\n",
    "sample_class = 3\n",
    "\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "\n",
    "# all concepts\n",
    "df_concepts_all = pd.read_csv(data_dir + concept_list ,sep='\\t')  \n",
    "\n",
    "# read semantic group\n",
    "df_concepts_all_semantic = pd.read_csv(data_dir + 'MostCommonCUIs.csv',sep=',')\n",
    "df_concepts_all_semantic = df_concepts_all_semantic[0:100]\n",
    "    \n",
    "# classes task[0] primary task task[1] to filter\n",
    "task = ['Body Part, Organ, or Organ Component','Diagnostic Procedure'] # ['Diagnostic Procedure'] # \n",
    "CLASS_NAMES = []\n",
    "CLASS_NAMES_exp = []\n",
    "for i in range(len(task)):\n",
    "    idx = df_concepts_all_semantic['Semantic attribute'] == task[i]\n",
    "    \n",
    "    CLASS_NAMES.append(df_concepts_all_semantic[idx]['CUI'].to_numpy())\n",
    "    CLASS_NAMES_exp.append(df_concepts_all_semantic[idx]['Explanation'].to_numpy())\n",
    "    \n",
    "# get every sample_class class\n",
    "CLASS_NAMES[0] = CLASS_NAMES[0][1::sample_class]\n",
    "CLASS_NAMES_exp[0] = CLASS_NAMES_exp[0][1::sample_class]\n",
    "        \n",
    "# x and y_axis ticks\n",
    "y_list = CLASS_NAMES_exp[0]  \n",
    "x_list = CLASS_NAMES_exp[1]  \n",
    "\n",
    "num_classes = np.zeros(len(CLASS_NAMES))\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    num_classes[i] = len(CLASS_NAMES[i])\n",
    "num_classes = num_classes.astype(int)\n",
    "num_classes_total = int(sum(num_classes))\n",
    "\n",
    "# iterate over seeds\n",
    "seed_vec = [42,73,666,777,1009] # ,1279,1597,1811,1949,2053]\n",
    "sampling_percentage_vec = [100,75,50,35,25,10,5]\n",
    "reduced_percentage_vec = [25,50,75,85,95,100] \n",
    "\n",
    "# initialize\n",
    "mean_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "mean_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "mean_eval_red_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "mean_eval_red_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "std_eval_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_red_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "std_eval_red_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "mean_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "mean_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "mean_eval_red_sec_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "mean_eval_red_sec_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "std_eval_sec_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_sec_id_mat = np.zeros([len(sampling_percentage_vec),1])\n",
    "std_eval_red_sec_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "std_eval_red_sec_id_mat = np.zeros([len(sampling_percentage_vec),len(reduced_percentage_vec)])\n",
    "cnt_sampling_percentage = 0\n",
    "    \n",
    "# iterate over sampling percentage\n",
    "for sampling_percentage in sampling_percentage_vec:\n",
    "    # print\n",
    "    print('Sampling percentage: ' + str(sampling_percentage))\n",
    "    \n",
    "    # initlaize eval_mat\n",
    "    eval_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_vec = np.zeros([len(seed_vec),1])\n",
    "    eval_id_vec = np.zeros([len(seed_vec),1])\n",
    "    eval_sec_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_sec_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "    eval_sec_vec = np.zeros([len(seed_vec),1])\n",
    "    eval_sec_id_vec = np.zeros([len(seed_vec),1])\n",
    "    cnt_seed = 0\n",
    "    \n",
    "    # iterate over random seed\n",
    "    for seed in seed_vec:     \n",
    "        \n",
    "        # get the current general experiment\n",
    "        df_ = df[(df['seed'] == seed) & (df['sampling_percentage'] == sampling_percentage)]\n",
    "        curr_exp = int(df_['experiment_id'])\n",
    "        curr_path = results_dir + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "        if os.path.exists(curr_path):\n",
    "            with open(curr_path, 'r') as f:\n",
    "                data = json.load(f) \n",
    "                \n",
    "            eval_ = np.array(data['eval_mat_sec'])\n",
    "            eval_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "            # calculate id accuracy \n",
    "            for j in range(num_classes[0]):\n",
    "                for i in range(num_classes[1]):\n",
    "                    tmp = np.array(data['eval_mat_sec'], copy=True)  \n",
    "                    tmp[j,i] = float('nan')\n",
    "                    eval_id[j,i] = np.nanmean(tmp) \n",
    "                    \n",
    "        # sum for each seed\n",
    "        eval_mat = eval_mat + eval_\n",
    "        eval_id_mat = eval_id_mat + eval_id\n",
    "        eval_vec[cnt_seed] = np.nanmean(eval_)\n",
    "        eval_id_vec[cnt_seed] = np.nanmean(eval_id)\n",
    "    \n",
    "        # filter df_nbrData_secondary\n",
    "        eval_sec = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_sec_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "    \n",
    "        # iterate over secondary experiments\n",
    "        for i in range(num_classes[1]):\n",
    "        \n",
    "            # get the current experiment\n",
    "            df_sec_ = df_secondary[(df_secondary['task2'] == i) & \n",
    "                                   (df_secondary['seed'] == seed) & \n",
    "                                   (df_secondary['sampling_percentage'] == sampling_percentage)]\n",
    "            curr_exp = int(df_sec_['experiment_id'])\n",
    "            curr_path = results_dir_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "            if os.path.exists(curr_path):\n",
    "                with open(curr_path, 'r') as f:\n",
    "                    data = json.load(f) \n",
    "                \n",
    "                # calculate id accuracy \n",
    "                for j in range(num_classes[0]):\n",
    "                    eval_sec[j,i] = np.array(data['eval_mat'])[j]\n",
    "                    tmp = np.array(data['eval_mat'], copy=True)  \n",
    "                    tmp[j] = float('nan')\n",
    "                    eval_sec_id[j,i] = np.nanmean(tmp) \n",
    "                    \n",
    "        # sum for each seed\n",
    "        eval_sec_mat = eval_sec_mat + eval_sec\n",
    "        eval_sec_id_mat = eval_sec_id_mat + eval_sec_id\n",
    "        eval_sec_vec[cnt_seed] = np.nanmean(eval_sec)\n",
    "        eval_sec_id_vec[cnt_seed] = np.nanmean(eval_sec_id)\n",
    "        cnt_seed = cnt_seed + 1\n",
    "        \n",
    "    # assign for each sampling_percentage\n",
    "    # general\n",
    "    eval_mat = eval_mat/cnt_seed\n",
    "    eval_id_mat = eval_id_mat/cnt_seed\n",
    "    mean_eval_mat[cnt_sampling_percentage] = np.nanmean(eval_vec)\n",
    "    mean_eval_id_mat[cnt_sampling_percentage] = np.nanmean(eval_id_vec)\n",
    "    std_eval_mat[cnt_sampling_percentage] = np.nanstd(eval_vec)\n",
    "    std_eval_id_mat[cnt_sampling_percentage] = np.nanstd(eval_id_vec)\n",
    "    # secondary\n",
    "    eval_sec_mat = eval_sec_mat/cnt_seed\n",
    "    eval_sec_id_mat = eval_sec_id_mat/cnt_seed\n",
    "    mean_eval_sec_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_vec)\n",
    "    mean_eval_sec_id_mat[cnt_sampling_percentage] = np.nanmean(eval_sec_id_vec)\n",
    "    std_eval_sec_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_vec)\n",
    "    std_eval_sec_id_mat[cnt_sampling_percentage] = np.nanstd(eval_sec_id_vec)\n",
    "    \n",
    "    # iterate over reduced secondary experiments\n",
    "    cnt_reduced_percentage = 0\n",
    "    \n",
    "    for reduced_percentage in reduced_percentage_vec:\n",
    "        # initialize\n",
    "        eval_red_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_red_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_red_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_red_id_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_red_sec_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_red_sec_id_mat = np.zeros([num_classes[0],num_classes[1]])\n",
    "        eval_red_sec_vec = np.zeros([len(seed_vec),1])\n",
    "        eval_red_sec_id_vec = np.zeros([len(seed_vec),1])\n",
    "        cnt_seed = 0\n",
    "        \n",
    "        # iterate over random seed\n",
    "        for seed in seed_vec: \n",
    "            \n",
    "            # initialize\n",
    "            eval_red = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_red_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "            # get the current experiment\n",
    "            df_red = df_reduced[(df_reduced['seed'] == seed) & \n",
    "                                (df_reduced['sampling_percentage'] == sampling_percentage) & \n",
    "                                (df_reduced['reduced_percentage'] == reduced_percentage)]\n",
    "            \n",
    "            # iterate over tasks\n",
    "            for i in range(num_classes[1]):\n",
    "                # initialize cnt\n",
    "                cnt = 0\n",
    "                for j in range(1,26,3):\n",
    "                    # get the current experiment\n",
    "                    df_red_ = df_red[(df_red['task1'] == j) & (df_red['task2'] == i)]\n",
    "                    curr_exp = int(df_red_['experiment_id'])\n",
    "                    curr_path = results_dir_red + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                    if os.path.exists(curr_path):\n",
    "                        with open(curr_path, 'r') as f:\n",
    "                            data = json.load(f) \n",
    "                \n",
    "                        eval_red[cnt,i] = np.array(data['eval_mat_sec'])[cnt,i]\n",
    "                        tmp = np.array(data['eval_mat_sec'], copy=True)  \n",
    "                        tmp[cnt,i] = float('nan')\n",
    "                        eval_red_id[cnt,i] = np.nanmean(tmp) \n",
    "                    cnt = cnt + 1    \n",
    "            # sum for each seed\n",
    "            eval_red_mat = eval_red_mat + eval_red\n",
    "            eval_red_id_mat = eval_red_id_mat + eval_red_id\n",
    "            eval_red_vec[cnt_seed] = np.nanmean(eval_red)\n",
    "            eval_red_id_vec[cnt_seed] = np.nanmean(eval_red_id)\n",
    "            \n",
    "            # initialize\n",
    "            eval_red_sec = np.zeros([num_classes[0],num_classes[1]])\n",
    "            eval_red_sec_id = np.zeros([num_classes[0],num_classes[1]])\n",
    "            \n",
    "            # get the current experiment\n",
    "            df_red_sec = df_reduced_secondary[(df_reduced_secondary['seed'] == seed) & \n",
    "                                             (df_reduced_secondary['sampling_percentage'] == sampling_percentage) & \n",
    "                                             (df_reduced_secondary['reduced_percentage'] == reduced_percentage)]\n",
    "            \n",
    "            # iterate over tasks\n",
    "            for i in range(num_classes[1]):\n",
    "                # initialize cnt\n",
    "                cnt = 0\n",
    "                for j in range(1,26,3):\n",
    "                    # get the current experiment\n",
    "                    df_red_sec_ = df_red_sec[(df_red_sec['task1'] == j) & (df_red_sec['task2'] == i)]\n",
    "                    curr_exp = int(df_red_sec_['experiment_id'])\n",
    "                    curr_path = results_dir_red_sec + 'experiment_' + str(curr_exp) + '/' + str(curr_exp) + '_results.json'\n",
    "                    if os.path.exists(curr_path):\n",
    "                        with open(curr_path, 'r') as f:\n",
    "                            data = json.load(f) \n",
    "                \n",
    "                        eval_red_sec[cnt,i] = np.array(data['eval_mat'])[cnt]\n",
    "                        tmp = np.array(data['eval_mat'], copy=True)  \n",
    "                        tmp[cnt] = float('nan')\n",
    "                        eval_red_sec_id[cnt,i] = np.nanmean(tmp) \n",
    "                    cnt = cnt + 1 \n",
    "                    \n",
    "            # sum for each seed\n",
    "            eval_red_sec_mat = eval_red_sec_mat + eval_red_sec\n",
    "            eval_red_sec_id_mat = eval_red_sec_id_mat + eval_red_sec_id\n",
    "            eval_red_sec_vec[cnt_seed] = np.nanmean(eval_red_sec)\n",
    "            eval_red_sec_id_vec[cnt_seed] = np.nanmean(eval_red_sec_id)\n",
    "            cnt_seed = cnt_seed + 1   \n",
    "            \n",
    "        # assign for each sampling_percentage\n",
    "        # general\n",
    "        eval_red_mat = eval_red_mat/cnt_seed\n",
    "        eval_red_id_mat = eval_red_id_mat/cnt_seed\n",
    "        mean_eval_red_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_vec)\n",
    "        mean_eval_red_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_id_vec)\n",
    "        std_eval_red_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_vec)\n",
    "        std_eval_red_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_id_vec)\n",
    "        # secondary\n",
    "        eval_red_sec_mat = eval_red_sec_mat/cnt_seed\n",
    "        eval_red_sec_id_mat = eval_red_sec_id_mat/cnt_seed\n",
    "        mean_eval_red_sec_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_sec_vec)\n",
    "        mean_eval_red_sec_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanmean(eval_red_sec_id_vec)\n",
    "        std_eval_red_sec_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_sec_vec)\n",
    "        std_eval_red_sec_id_mat[cnt_sampling_percentage,cnt_reduced_percentage] = np.nanstd(eval_red_sec_id_vec)\n",
    "        cnt_reduced_percentage = cnt_reduced_percentage + 1   \n",
    "    \n",
    "    # increment cnt for sampling percentage\n",
    "    cnt_sampling_percentage = cnt_sampling_percentage + 1   \n",
    "\n",
    "blue_colors = [mcolors.CSS4_COLORS['darkslateblue'],\n",
    "               mcolors.CSS4_COLORS['midnightblue'],\n",
    "                mcolors.CSS4_COLORS['darkblue'],\n",
    "                mcolors.CSS4_COLORS['mediumblue'],\n",
    "                mcolors.CSS4_COLORS['royalblue'],\n",
    "                mcolors.CSS4_COLORS['cornflowerblue'],\n",
    "                mcolors.CSS4_COLORS['lightblue']]\n",
    "\n",
    "red_colors = [mcolors.CSS4_COLORS['darkred'],\n",
    "                  mcolors.CSS4_COLORS['firebrick'],\n",
    "                  mcolors.CSS4_COLORS['crimson'],\n",
    "                  mcolors.CSS4_COLORS['red'],\n",
    "                  mcolors.CSS4_COLORS['orangered'],\n",
    "                  mcolors.CSS4_COLORS['orange'],\n",
    "                  mcolors.CSS4_COLORS['gold']]\n",
    "\n",
    "purple_colors = [mcolors.CSS4_COLORS['indigo'],\n",
    "                mcolors.CSS4_COLORS['purple'],\n",
    "                mcolors.CSS4_COLORS['darkviolet'],\n",
    "                mcolors.CSS4_COLORS['mediumorchid'],\n",
    "                mcolors.CSS4_COLORS['orchid'],\n",
    "                mcolors.CSS4_COLORS['thistle'],\n",
    "                mcolors.CSS4_COLORS['lavender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = plt.figure(figsize=(5.25, 3), dpi=80)\n",
    "# plt.subplot(1,2,1)\n",
    "plt.errorbar(sampling_percentage_vec,mean_eval_sec_mat[:,0],yerr=std_eval_sec_mat[:,0],label='Specialized - '+ '0%',color=blue_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_red_sec_mat[:,i],yerr=std_eval_red_sec_mat[:,i],label='Specialized - ' + str(reduced_percentage_vec[i])+'%',color=blue_colors[i+1])\n",
    "plt.errorbar(sampling_percentage_vec,mean_eval_mat[:,0],yerr=std_eval_mat[:,0],label='Multi-domain - '+ '0%',color=red_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_red_mat[:,i],yerr=std_eval_red_mat[:,i],label='Multi-domain - ' + str(reduced_percentage_vec[i])+'%',color=red_colors[i+1])\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlabel('Sampling percentage [%]')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "# plt.title('Specialized vs General -  OOD')\n",
    "plt.legend(bbox_to_anchor=(1.5, 0.5),loc='right', ncol=1)\n",
    "# plt.savefig('figs/imageclef_specialized_vs_general_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/imageclef_specialized_vs_general_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(5.25, 3), dpi=80)\n",
    "# plt.subplot(1,2,2)\n",
    "plt.errorbar(sampling_percentage_vec,mean_eval_sec_id_mat[:,0],yerr=std_eval_sec_id_mat[:,0],label='Specialized - ' +'0%',color=blue_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_red_sec_id_mat[:,i],yerr=std_eval_red_sec_id_mat[:,i],label='Specialized - ' + str(reduced_percentage_vec[i])+'%',color=blue_colors[i+1])\n",
    "plt.errorbar(sampling_percentage_vec,mean_eval_id_mat[:,0],yerr=std_eval_id_mat[:,0],label='Multi-domain - ' +'0%',color=red_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.errorbar(sampling_percentage_vec,mean_eval_red_id_mat[:,i],yerr=std_eval_red_id_mat[:,i],label='Multi-domain - ' + str(reduced_percentage_vec[i])+'%',color=red_colors[i+1])\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlabel('Sampling percentage [%]')\n",
    "plt.ylabel('Average balanced accuracy')\n",
    "# plt.title('Specialized vs General - ID')\n",
    "plt.legend(bbox_to_anchor=(1.5, 0.5),loc='right',ncol=1)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()  \n",
    "# plt.savefig('figs/imageclef_specialized_vs_general_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/imageclef_specialized_vs_general_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "plt.plot(sampling_percentage_vec,mean_eval_mat-mean_eval_sec_mat,label='0%',color=purple_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.plot(sampling_percentage_vec,mean_eval_red_mat[:,i]-mean_eval_red_sec_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=purple_colors[i+1])\n",
    "plt.ylim([0,0.25])\n",
    "plt.xlabel('Sampling percentage [%]')\n",
    "plt.ylabel('Balanced accuracy difference')\n",
    "# plt.title('ImageCLEF -  OOD')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right', ncol=1)\n",
    "# plt.savefig('figs/imageclef_specialized_vs_general_diff_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/imageclef_specialized_vs_general_diff_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80)\n",
    "plt.plot(sampling_percentage_vec,mean_eval_id_mat-mean_eval_sec_id_mat,label='0%',color=purple_colors[0])\n",
    "for i in range(0,len(reduced_percentage_vec)):\n",
    "    plt.plot(sampling_percentage_vec,mean_eval_red_id_mat[:,i]-mean_eval_red_sec_id_mat[:,i],label=str(reduced_percentage_vec[i])+'%',color=purple_colors[i+1])\n",
    "plt.ylim([0,0.25])\n",
    "plt.xlabel('Sampling percentage [%]')\n",
    "plt.ylabel('Balanced accuracy difference')\n",
    "# plt.title('ImageCLEF - ID')\n",
    "plt.legend(bbox_to_anchor=(1.3, 0.5),loc='right',ncol=1)\n",
    "plt.subplots_adjust(wspace=0.25)\n",
    "# plt.show()  \n",
    "# plt.savefig('figs/imageclef_specialized_vs_general_diff_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/imageclef_specialized_vs_general_diff_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "reduced_percentage_vec = [0,25,50,75,85,95,100]\n",
    "\n",
    "# ood\n",
    "ood_score = np.zeros([len(reduced_percentage_vec),2])\n",
    "ood_score[0,0] = auc(sampling_percentage_vec,mean_eval_mat[:,0])\n",
    "ood_score[0,1] = auc(sampling_percentage_vec,mean_eval_sec_mat[:,0])\n",
    "for i in range(1,len(reduced_percentage_vec)):\n",
    "    ood_score[i,0] = auc(sampling_percentage_vec,mean_eval_red_mat[:,i-1]) \n",
    "    ood_score[i,1] = auc(sampling_percentage_vec,mean_eval_red_sec_mat[:,i-1]) \n",
    "fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "plt.plot(reduced_percentage_vec,ood_score[:,1],color=blue_colors[0],linewidth=2.5,marker='o',label='Specialized')\n",
    "plt.plot(reduced_percentage_vec,ood_score[:,0],color=red_colors[0],linewidth=2.5,marker='o',label='Multi-domain')\n",
    "plt.plot(reduced_percentage_vec,100*np.ones((len(reduced_percentage_vec),1)),'--',color='k')\n",
    "plt.ylim([0,105])\n",
    "plt.xlabel('OOD level [%]')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=2)\n",
    "# plt.show() \n",
    "# plt.savefig('figs/imageclef_auc_ood.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/imageclef_auc_ood.pdf', bbox_inches='tight', format='pdf')\n",
    "\n",
    "# id\n",
    "id_score = np.zeros([len(reduced_percentage_vec),3])\n",
    "id_score[0,0] = auc(sampling_percentage_vec,mean_eval_id_mat[:,0])\n",
    "id_score[0,1] = auc(sampling_percentage_vec,mean_eval_sec_id_mat[:,0])\n",
    "for i in range(1,len(reduced_percentage_vec)):\n",
    "    id_score[i,0] = auc(sampling_percentage_vec,mean_eval_red_id_mat[:,i-1]) \n",
    "    id_score[i,1] = auc(sampling_percentage_vec,mean_eval_red_sec_id_mat[:,i-1])   \n",
    "fig = plt.figure(figsize=(4.3, 3), dpi=80)\n",
    "plt.plot(reduced_percentage_vec,id_score[:,1],color=blue_colors[0],linewidth=2.5,marker='o',label='Specialized')\n",
    "plt.plot(reduced_percentage_vec,id_score[:,0],color=red_colors[0],linewidth=2.5,marker='o',label='Multi-domain')\n",
    "plt.plot(reduced_percentage_vec,100*np.ones((len(reduced_percentage_vec),1)),'--',color='k')\n",
    "plt.ylim([0,105])\n",
    "plt.xlabel('OOD level [%]')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend(bbox_to_anchor=(0.5, 1.2),loc='upper center', ncol=2)\n",
    "# plt.show()\n",
    "# plt.savefig('figs/imageclef_auc_id.eps', bbox_inches='tight', format='eps')\n",
    "plt.savefig('figs/imageclef_auc_id.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
